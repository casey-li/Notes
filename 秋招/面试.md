
- [开场](#开场)
- [项目](#项目)
  - [Webserver](#webserver)
  - [MIT](#mit)
- [论文](#论文)
- [高频点](#高频点)
  - [algorithm 头文件中常用函数](#algorithm-头文件中常用函数)
  - [STL 容器](#stl-容器)
  - [最困难的事情](#最困难的事情)
  - [移动语义，move 的底层实现](#移动语义move-的底层实现)
    - [移动语义](#移动语义)
    - [std::move的实现](#stdmove的实现)
  - [lambda](#lambda)
  - [多态，虚函数表](#多态虚函数表)
  - [智能指针](#智能指针)
    - [sharedPtr和uniquePtr，weakptr](#sharedptr和uniqueptrweakptr)
    - [C++智能指针循环引用如何解决](#c智能指针循环引用如何解决)
    - [多线程下的shared\_ptr的安全问题](#多线程下的shared_ptr的安全问题)
    - [auto\_ptr 被废弃的原因](#auto_ptr-被废弃的原因)
  - [std::bind](#stdbind)
  - [内存越界与内存泄漏问题如何排查](#内存越界与内存泄漏问题如何排查)
  - [vector push\_back 时间复杂度](#vector-push_back-时间复杂度)
  - [四种强制类型转换](#四种强制类型转换)
  - [map和unordered\_map区别（map为啥用红黑树不用avl树？）](#map和unordered_map区别map为啥用红黑树不用avl树)
  - [GDB的相关命令](#gdb的相关命令)
  - [虚拟内存](#虚拟内存)
  - [HTTP 各版本的优化](#http-各版本的优化)
  - [HTTP和HTTPS的区别](#http和https的区别)
  - [HTTPS 是如何保证数据传输的安全，整体的流程是什么？（SSL是怎么工作保证安全的）](#https-是如何保证数据传输的安全整体的流程是什么ssl是怎么工作保证安全的)
  - [Cokkie和Session](#cokkie和session)
  - [TCP 可靠传输](#tcp-可靠传输)
  - [TCP](#tcp)
  - [IP](#ip)
  - [索引](#索引)
  - [事务](#事务)
  - [锁](#锁)
  - [日志](#日志)
  - [虚拟地址](#虚拟地址)
- [八股](#八股)
  - [c++](#c)
  - [计网](#计网)
  - [操作系统](#操作系统)
  - [数据库](#数据库)
  - [Linux](#linux)
  - [Git](#git)
  - [设计模式](#设计模式)
  - [数据结构](#数据结构)
  - [其它](#其它)
- [手撕](#手撕)
- [场景题目](#场景题目)


## 开场

**自我介绍**


尊敬的面试官您好，我是李相前，本科毕业于西安建筑科技大学的计算机科学与技术专业。本科期间，我的专业排名在前5%并多次获得学业奖学金，此外，我还参加了全国大学生数学建模比赛并取得了省一等奖。目前硕士就读于西安电子科技大学，所修专业为计算机技术，专业排名同样在前5%。硕士期间，我的研究方向为智能计算，目前已经以第一作者身份在1区期刊 Applied Soft Computing 上录用论文一篇，以学生一作身份录用EI会议一篇，公开发明专利一项，此外还有一篇1区论文正处于2审阶段。这些科研经历也提升了我发现问题并解决问题的能力。在科研之余，我还积极参加了比赛，拿到了全国研究生数学建模大赛国家三等奖以及华为软件精英挑战赛粤港澳赛区二等奖的成绩。基于本人对于服务器开发以及分布式技术的兴趣，我利用课余时间学习了相关知识。为了巩固所学，我在 Linux 环境下搭建了一个 Web 服务器项目，经过webbench测试工具测试可以实现上万的QPS; 此外，我还基于Raft算法实现了分片键值存储系统，支持键值服务器集群的动态管理以及服务器集群之间的负载均衡处理，完成的所有 Lab 均通过了官方提供的测试用例。我的自我介绍完毕，感谢面试管的聆听。

## 项目

### Webserver

Http服务器项目是在Linux环境下搭建的Web服务器，支持对浏览器客户端发来的GET和POST请求进行解析并生成响应。服务器端利用epoll多路IO复用技术与线程池实现了Reactor高并发模型，其中主线程负责对客户端的连接进行监听，并将具体的任务添加到线程池的任务队列中交由工作线程进行处理，工作线程利用正则表达式与状态机解析HTTP请求报文并生成响应报文。此外，为了减少与数据库建立和关闭连接带来开销，设计了数据库连接池来管理连接；为了实现参数的统一管理，设计了简易的JSON解析器来解析服务器配置文件；为了提高系统性能，设计了基于小根堆的定时器以主动断开长时间没有请求的连接。此外，还增加了同步/异步日志功能以记录服务器的运行状态。服务器搭建完成后使用 webbench 测试工具对服务器的性能进行了测试，在本地虚拟机环境下并发量可以达到1w。

- 目的

练手，熟悉网络编程和io多路复用，把学到的知识运用于实际。熟悉项目从无到有的一整个流程

- 为什么还要选择这个项目？

项目是在学习网络编程的过程中逐步搭建的，这个项目综合性比较强，从中既能学习Linux环境下的一些系统调用，也能熟悉网络编程和一些网络框架，主要目的是为了巩固所学

- IO多路复用技术

I/O多路复用技术是为了解决原始的阻塞IO如果需要支持多个客户端只能使用多进程和多线程的模式，但这样每新到一个TCP连接就需要分配一个进程或者线程，对操作系统的负担很大，**因此想到使用一个进程来维护多个socket**，（一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程），这就是IO多路复用技术（这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用）

- 改进点：采用主从Reactor，添加内存池

- 线程池的数量一般怎么设置？IO密集和CPU密集

- 来了一个新的任务，线程池是怎么工作的？

- 提到了一面的unique_lock，介绍一下unique_lock和lock_guard区别？

- 条件变量的wait

- GET和POST的区别

- 讲一下IO多路复用？epoll有哪些不足之处？

### MIT

该项目基于Multi-Raft架构实现了分片键值存储系统，能在增删Raft组、节点宕机、节点重启和网络分区等情况下仍对外满足线性一致性的要求，支持键值服务器集群的动态管理以及服务器集群间的负载均衡处理。具体来说，本项目实现了Raft算法，支持超时选举、定时心跳、日志复制以及快照生成等核心功能，在实现的Raft算法的基础上实现了分片控制器以管理配置信息，支持添加删除副本组以及在副本组之间移动分片等功能。在分片控制器以及底层Raft算法的支持下，完成了分片键值存储系统，实现了键值服务集群对Get, Put 和 Append 方法的线性一致性处理并支持分片的数据迁移和垃圾回收等功能。所有Lab的代码均通过了1000次的压力测试。


难点：

- **lab2**

存在多种意外情况，包括网络不稳定导致的过期RPC，服务器崩溃，断联。如何在这些情况下仍保证系统达成共识是一个难点。

（测试案例会不断的提交命令, 休眠一段时间后根据概率断开 leader 的连接, 并在连接的节点数少于一半时根据概率重连一个服务器。最后连接所有服务器, 提交命令, 检查是否能达成共识。
跑该测试案例的时候, 会出现最后不能达成共识的情况。检查日志发现问题在于最后选出的 leader 跟其他节点的日志差异过大。最后是优化了RPC的返回结果以快速定位下一次发送的日志

数据竞争的问题，找了很久的bug，最后发现是map的原因，必须先复制一份才能发送

发送的RPC总字节数过多的问题，打印日志后发现问题在于自己的实现中可能会同时存在两个心跳定时器同时运行，主要是锁抢占的问题。因为运行选举超时投票的时候需要给其他节点发起投票请求，并开启新的计时器避免请求失败。但是因为锁的抢占问题，一直到成为leader后才进入了新定时器，此时运行的就是心跳定时器了）

- **Lab3** 

自己对raft的理解不到位，以为若当前请求超时了就可以不再执行了，但是其实只要是raft达成共识的命令必须执行。你不执行其他都执行了就会产生不一致的现象

- **Lab4** 

如何保证GET/PUT/APPEND线性一致性的调用，如何高效的处理分片迁移以保证分片的负载均衡以及分片的一致性，死锁是最常出现的一种问题。

- CAP理论？AP和CP如何取舍？介绍一下如今市面上的AP和CP系统

- 如何实现负载均衡

  1. 轮询（RoundRobin）将请求顺序循环地发到每个服务器。当其中某个服务器发生故障，AX就把其从顺序循环队列中拿出，不参加下一次的轮询，直到其恢复正常。
  2. 比率（Ratio）：给每个服务器分配一个加权值为比例，根椐这个比例，把用户的请求分配到每个服务器。当其中某个服务器发生故障，AX就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
  3. 优先权（Priority）：给所有服务器分组，给每个组定义优先权，将用户的请求分配给优先级最高的服务器组（在同一组内，采用预先设定的轮询或比率算法，分配用户的请求）；当最高优先级中所有服务器或者指定数量的服务器出现故障，AX将把请求送给次优先级的服务器组。这种方式，实际为用户提供一种热备份的方式。
  4. 最少连接数（LeastConnection）：AX会记录当前每台服务器或者服务端口上的连接数，新的连接将传递给连接数最少的服务器。当其中某个服务器发生故障，AX就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
  5. 最快响应时间（Fast Reponse time）：新的连接传递给那些响应最快的服务器。当其中某个服务器发生故障，AX就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。
  6. 哈希算法( hash): 将客户端的源地址，端口进行哈希运算，根据运算的结果转发给一台服务器进行处理，当其中某个服务器发生故障，就把其从服务器队列中拿出，不参加下一次的用户请求的分配，直到其恢复正常。


- 描述一下raft协议

分为领导者选举，日志复制，持久化处理以及快照四大部分

- 实现raft协议遇到的最大困难是什么

- raft日志复制

- follower收到一个日志，有冲突怎么办

- leader 和 follower 的日志 有一个 index 上的 日志 term 相同，那么之前的日志也是相同的吗？

- 基于raft 的 kv引擎如何做？

- raft kv读流程，读优化

- [雪花算法](https://zhuanlan.zhihu.com/p/433690272)

项目注意点

Lab3
Lab3 注意只要是从 applyCh 中取得的命令一定会走到 “执行” 那一步

最开始测试的时候就产生死锁了, 检查代码后发现问题在于读快照部分 (因为是原封不动的拿的 Lab 2 中编码解码代码也没多想 😭) 在 Lab 2 的 Raft 的实现中, 自己想着读取持久化状态会修改共享资源就给加了锁 (这在 Raft 里是没啥问题的, 因为读取持久化状态仅仅发生在 Raft 初始化的时候, 此时不会产生死锁); 但是在 KVServer 的实现流程中, 当从 applyCh 中接收到的 applyMsg 为 Snapshot 时 (此时已经加锁), 就会读取 Snapshot, 在加锁就发生了死锁!!

Lab4
分片结果不一致，问题在于 map 是随机访问保存的键值对的
map 的遍历必须实现确定性的遍历（先获取所有的id，再排序，这样就可以确定性的进行遍历），不然同一个命令的执行结果在不同的 ShardCtrler 上会不一致

死锁，分片无法迁移，彼此等待 (case1)
检查日志后发现问题在于 monitorRequestConfig() 中自己请求新配置时直接请求的最新配置 (kv.manager.Query(-1)), 可能会跳过某些配置 (比如当前配置号为2, 最新的为 5), 而某个服务器处于配置 3, 正在等待当前服务器进入配置 3 并拉取分片。 在最新配置中可能当前服务器又要向其他服务器拉取分片, 但是其他服务器的配置号远远落后于当前服务器的配置号, 因此不会回应。服务器之间的配置信息变更产生了死锁现象，彼此都不能对外提供服务，最终超时。

## 论文

多模态优化问题 (Multimodal optimization problems, MMOPs) 旨在在同时定位多个高精度的最优解。近年来，为了保持种群的多样性，许多小生境策略被用于进化算法以解决MMOPs。然而，大多数多模态算法对于小生境参数（例如小生境的大小/数量）敏感，并且缺乏有效的方法来更新“停滞个体”（陷入局部最优的个体或收敛到相同最优解的个体）。针对上述问题，本文提出了一种基于最小生成树和知识驱动策略的差分进化（TNDE）算法，其中“知识”包括历史进化信息、适应度分布信息和个体分布信息。
在TNDE中，我们首先提出了基于最小生成树的生境策略 (minimum spanning tree niche, MSTN) 以自适应地划分种群并动态地调整小生境的数量。此外，我们还提出了基于知识驱动的更新策略 (knowledge-driven update strategy, KDU) 以定位和更新那些停滞的个体。最后，我们提出了改进的差分进化算法，包括基于局部阶段的变异策略 (local stage-based mutation strategy, LSM) 和方向引导的选择策略 (directional guidance selection strategy, DGS) 分别用于加速收敛并提高解的精度。与16种最先进的算法相比，TNDE在求解高维多模态优化问题上具有显著优势。

**现有方法存在的问题**

- 大多数基于小生境的算法从进化开始时就将种群划分为了多个小生境并且对先验参数敏感。然而，由于种群是随机初始化的，进化早期的个体的分布具有很大的随机性，容易导致种群划分不合理。**因此，如何在进化过程中合理地划分种群是第一个挑战。**

- 种群在进化后期中存在许多“停滞个体”（陷入局部最优的个体和收敛到同一最优解的个体）。然而，这些停滞个体很难被定位并且它们会消耗大量的适应度评价指标(FEs)。**因此，如何定位停滞个体并为其提供新的进化机会是第二个挑战。**

- 现有的基于小生境的算法使用相同的进化算子来进化所有小生境，没有考虑不同小生境之间收敛状态的差异。**因此，如何区分不同的小生境并采用不同的进化算子来加速收敛是第三个挑战。**

**创新点**

- 提出了一种基于最小生成树的生境策略 (minimum spanning tree niche, MSTN)，根据个体的位置构建最小生成树并通过切割其中的边来自适应地划分种群。因为处于同一最优区域的个体之间的关系比处于不同最优区域的个体之间的关系更密切，构建的树中边的长度可以准确地衡量不同个体之间的关系。因此，在构建的树中，前几条最长的边是连接不同最优区域的边。然后，利用从知识中检测到的最优解的数目可以在不同进化阶段动态调整需要截断的边数。这样，每个独立子树形成一个小生境，有效地解决了第一个问题。

- 提出了一基于种知识驱动的更新策略 (knowledge-driven update strategy, KDU) 来检测和更新停滞个体。根据历史进化信息、适应度分布信息和个体分布信息，可以提取出假定的最优值、正常适应度值的分布范围和个体周围的密度。基于上述结果，可以定位这些停滞的个体。然后，通过高斯扰动将这些个体更新到适应度值较好的个体的邻域就可以提高种群的多样性。这样，FEs分配给更新的个体，而不是停滞的个体，有助于定位更多的最优解，从而解决第二个问题。

- 提出了一种结合局部阶段变异策略 (local stage-based mutation strategy, LSM) 和方向引导的选择策略 (directional guidance selection strategy, DGS) 的改进DE，以加快收敛速度并提高找到解的精度。具体而言，LSM策略使每个小生境能够根据该小生境的进化阶段独立选择更关注种群多样性或收敛性的变异算子。同时，如果将父代个体替换为适应度值较优的子代个体，DGS策略可以利用子代个体与父代个体的差向量进一步优化解。这样既保证了种群的收敛能力，又保证了解的精度，从而解决了最后一个问题。

## 高频点

### algorithm 头文件中常用函数

1. 排序算法：
    - `std::sort()`
    - `std::stable_sort()`, 对容器进行稳定排序
    - `std::partial_sort()`, 部分排序，将前 k 个元素排序
2. 查找算法：
    - `std::find()`: 在容器中查找指定元素。
    - `std::binary_search()`: 在有序容器中进行二分查找。
    - `std::lower_bound()`: 在有序容器中查找第一个不小于指定值的元素。
    - `std::upper_bound()`: 在有序容器中查找第一个大于指定值的元素。
    - `std::equal_range()`: 同时查找 lower_bound 和 upper_bound。
3. 合并和拷贝算法：
    - `std::merge()`: 合并两个有序序列到一个目标序列。
    - `std::copy()`: 复制一个容器的内容到另一个容器。
    - `std::copy_if()`: 根据条件复制一个容器的内容到另一个容器。
4. 常用操作算法：
    - `std::for_each()`: 对容器中的每个元素执行指定操作。
    - `std::transform()`: 对容器中的每个元素进行转换，并将结果存储到另一个容器。
    - `std::count()`: 统计容器中满足条件的元素个数。
    - `std::accumulate()`: 对容器中的元素进行累加或累积。
5. 删除和修改算法：
    - `std::remove()`: 删除容器中指定元素。
    - `std::remove_if()`: 根据条件删除容器中的元素。
    - `std::replace()`: 替换容器中指定元素。
    - `std::replace_if()`: 根据条件替换容器中的元素。
    - `std::fill()`: 将容器中的元素设置为指定值。
    - `std::fill_n()`: 将容器中的指定数量的元素设置为指定值

### STL 容器

- `vector`：动态数组，可以动态调整大小。
- `list`：双向链表，支持快速插入和删除操作。
- `deque`：双端队列，类似于动态数组，但支持在头部和尾部快速插入和删除操作。
- `set`：集合，存储唯一元素，并按照升序排序。
- `multiset`：多重集合，存储可重复元素，并按照升序排序。
- `map`：映射表，存储键值对，并按照键的升序排序。
- `multimap`：多重映射表，存储可重复的键值对，并按照键的升序排序。
- `unordered_set`：哈希表实现的集合，存储唯一元素，无序。
- `unordered_multiset`：哈希表实现的多重集合，存储可重复元素，无序。
- `unordered_map`：哈希表实现的映射表，存储键值对，无序。
- `unordered_multimap`：哈希表实现的多重映射表，存储可重复的键值对，无序。


### 最困难的事情


### 移动语义，move 的底层实现

[一文入魂：妈妈再也不担心我不懂C++移动语义了](https://zhuanlan.zhihu.com/p/455848360)

#### 移动语义

**一、为什么要有移动语义？**

移动语义是 C++11 引入的一个重要特性，它的主要目的是**提高代码的效率和性能**。在涉及对象拷贝和资源管理的情况下，移动语义通过将资源（例如堆内存、文件句柄等）从一个对象转移到另一个对象，避免了不必要的数据拷贝，从而减少了资源的重复分配和释放，提高了程序的性能。

移动语义通过引入右值引用和移动构造函数、移动赋值运算符来实现资源的有效转移，而不是进行不必要的数据拷贝。这在以下几种情况下特别有用：

1. 动态内存管理： 在涉及动态内存分配的情况下，移动语义可以避免深拷贝，提高内存使用效率。

2. 容器操作： 在容器中插入、删除元素时，使用移动语义可以减少元素的拷贝和构造，提高容器操作的效率。

3. 资源管理： 在管理资源（如文件句柄、网络连接等）时，移动语义可以有效地将资源从一个对象转移到另一个对象，避免资源的重复释放和分配。

4. 函数返回值： 返回临时对象时，使用移动语义可以避免不必要的拷贝操作，提高函数的性能。

**二、移动语义的实现？**

1. 左值引用和右值引用（能够引用没有名称的临时对象以及使用std::move标记的对象）
    
2. 编译器匹配右值引用的情况（一个在语句执行完毕后就会被自动销毁的临时对象，由std::move标记的非const对象）

3. 移动操作（移动构造和移动赋值），包括转移数据以及清除被转移对象数据两大步骤

4. 移动构造函数和移动赋值运算符的生成规则，默认拥有一切。但若定义了拷贝操作或析构则不会自动生成移动操作（当要调用移动操作时会转而调用拷贝操作）。但若定义了其中一个移动操作，另一个会被定义为删除（此时调用另一个会报错而不是转而调用拷贝操作）。

5. noexcept, 强异常保证

6. 其它注意事项：
    - 编译器生成的移动操作为逐成员的移动语义
    - 被移动对象的状态为有效但未定义（不是很理解），只要保证被移动对象能够被正确的析构即可
    - 避免非必要的 std::move 调用（NRVO，存在命名返回值优化的技术），即如果函数返回一个临时对象，则该对象会直接给函数调用方使用，而不会再创建一个新对象，省去了拷贝构造函数以及析构函数的调用开销。虽然返回 std::move() 也可以避免拷贝操作，但是可能返回对象并没有实现移动语义（此时因为返回值类型非右值，编译器也不会启用 NRVO，只能调用拷贝构造函数）。**当返回局部对象时，直接返回对象即可，编译器会优先使用最佳的NRVO，在没有NRVO的情况下，会尝试执行移动构造函数，最后才是开销最大的拷贝构造函数**

**详细描述**

编译器会给空类默认生成6个函数（构造函数、析构函数、拷贝构造函数、拷贝赋值运算符、移动构造函数和移动赋值运算符）。但若定义了拷贝操作（拷贝构造、拷贝赋值），编译器就不会自动生成移动操作，此时若调用了移动语义的话会转而执行拷贝操作；同理，若定义了析构，也不会自动生成移动操作

特殊的是基类通常会声明虚析构函数，此时需要考虑是否为基类手动定义移动操作，只有子类没有实现自己的析构函数时才能自动生成移动操作。

移动构造函数和移动赋值运算符各自影响，当实现了其中一个的话，编译器就不会自动生成另一个，反而会将另一个定义为已删除。此时**若只定义了移动构造函数并调用移动赋值运算符的话不会转而执行拷贝赋值运算符而是产生编译错误，因为移动赋值会被定义为已经删除的函数**

![](https://pic4.zhimg.com/80/v2-6bb8fd7d310bd3c89b75b81f6f04ef53_720w.webp)

**noexcept 关键字**

**强异常保证**即当我们调用一个函数时，如果发生了异常，那么应用程序的状态能够回滚到函数调用之前

容器的 `push_back` 函数是具备强异常保证的。当 `push_back` 函数在执行操作的过程中（由于内存不足需要申请新的内存、将老的元素放到新内存中等）如果发生了异常（内存空间不足无法申请等），需确保应用程序的状态能够回滚到调用它之前。所以若移动构造函数未使用 `noexcept` 说明符，就会调用拷贝构造函数（因为拷贝构造函数执行之后，被拷贝对象的原始数据是不会丢失的。因此，即使发生异常需要回滚，那些已经被拷贝的对象仍然完整且有效。但移动语义就不同了，被移动对象的原始数据是会被清除的）


#### std::move的实现

[C++引用折叠与std::move和std::forward的实现](https://zhuanlan.zhihu.com/p/580797507)

1. 引用折叠

2. `std::remove_reference` 的实现

3. `std::move` 的实现

4. `std::forward` 的实现


**详细描述**

- **引用折叠**
  
虽然C++对于用户是不允许定义引用的引用这种变量的，但是由于万能引用对左值引用和右值引用的实现细节需要，因此在模版的类型推导中会出现引用的引用这种情况

```c++
// 万能引用，在接收参数时传左值和右值它都能接受
template <typename T> 
void func(T&& t)  { 
    ;
}
```
传右值 `type&&` 时，模版类型参数T会推导为type，这个函数就变成了以右值引用为参数的函数；传左值 `type&` 时，模版类型参数T会推导为`type&`，然后就变成了`type& &&`。**除右值引用的右值引用仍折叠为右值引用外，其他的情况都折叠为左值引用**

除了万能引用模版参数推导中，其他场景也可能出现引用折叠的情况。如 `decltype(obj1)&& obj2 = obj1;` 也可能发生引用折叠

- `std::remove_reference` 的实现

类型提取器，可以把你这个类型里头的引用全部去除掉得到这个类型, 如用 `typename std::remove_reference<int&&>::type a;` 定义变量a，那么这个 a 就是 int 类型

它的实现利用了模板特化和 typedef

```c++
// 这个 T 不论是被推导成了type, type&, type&& 我都能得到你本来的type
namespace scu {

    template <typename T>
    struct remove_reference {
        typedef T type;
    };

    template <typename T>
    struct remove_reference<T&> {
        typedef T type;
    };

    template <typename T>
    struct remove_reference<T&&> {
        typedef T type;
    };
}

// 官方的
template<typename _Tp>
struct remove_reference{ 
    typedef _Tp   type; 
};
// ...
```

- `std::move` 的实现

`std::move` 左值右值都可以接受，因此肯定要用模版的万能引用。因为 `std::move` 的功能是把参数转换成 `type&&` 类型返回，那么我们可以用上面的 `remove_reference<T>::type&&` ，直接用 `static_cast<typename remove_reference<T>::type&&>`

```c++
template <typename T>
typename scu::remove_reference<T>::type&& move(T&& t) noexcept {
    return static_cast<typename scu::remove_reference<T>::type&&>(t);
}

// 官方的
template<typename _Tp>
constexpr typename std::remove_reference<_Tp>::type&& move(_Tp&& __t) noexcept { 
    return static_cast<typename std::remove_reference<_Tp>::type&&>(__t); 
}
```

**typename 关键字主要用于帮助编译器理解模板中的嵌套类型，并明确告诉编译器这是一个类型。**在模板类或模板函数中，有时候嵌套的类型可能是一个依赖于模板参数的类型，编译器可能无法确定它是一个类型还是一个成员变量，这时就需要使用 typename 来明确告诉编译器这是一个类型。常见使用场景有两个

```c++
// 一、在模板类或模板函数中引用嵌套类型
// 当你在模板中引用一个嵌套类型时，编译器可能无法确定这个嵌套类型是否为一个类型。通过使用 typename，你告诉编译器这是一个类型，而不是成员变量或函数
template <typename T>
class MyClass {
public:
    typename T::NestedType nestedVar;  // 嵌套类型，需要使用 typename
};

// 二、在模板类型中使用类型别名
template <typename T>
using MyAlias = typename T::NestedType;  // 使用 typename 来指示是一个类型

```

- `std::forward` 的实现

**完美转发**：就是说是左值引用就传左值引用的类型，是右值引用就传右值引用的类型

一个右值引用变量它本身是一个左值，因为是把这个右值存到了当前函数栈里，然后引用它，它本身可以取地址，因此它是个左值。这就有一个问题，以右值引用为参数的函数，假设是 `fun1(type&& a)`，在这个函数内想要调用重载函数 `fun2(type& a)` 和 `fun2(type&& a)`，会调用 `fun2(type& a)`。为了正确调用应写成 `fun2(std::forward<T>(a));`

注意 `forward` 不能直接写成 `T&& forward(T &&t)`, 如下调用的话会报错。因为在 fun1 中, T 为 int, 但是 t 为左值，所以调用 forward 时会报错，它实例化的函数接收一个右值！！

```c++
template <typename T>
T&& forward(T &&t) {

}

template <typename T>
void fun1(T &&t) {
    fun2(forward<T>(t));
}

fun1(5); // 报错
```

所以，这个函数需要我们自己把左值引用和右值引用的类型表达出来，即左值 `typename scu::remove_reference<T>::type&`，右值 `typename scu::remove_reference<T>::type&&`。函数内利用引用折叠强转为类型T&&，这样左值的T时type&，会保持左值引用，右值的T是type，会变成type&&。

```c++
namespace scu {
    template <typename T>
    T&& forward(typename scu::remove_reference<T>::type& t) {
        return static_cast<T&>(t);
    }

    template <typename T>
    T&& forward(typename scu::remove_reference<T>::type&& t) {
        return static_cast<T&&>(t);
    }
}

// 官方的
template<typename _Tp>
constexpr _Tp&& forward(typename std::remove_reference<_Tp>::type& __t) noexcept { 
    return static_cast<_Tp&&>(__t); 
}

template<typename _Tp>
constexpr _Tp&& forward(typename std::remove_reference<_Tp>::type&& __t) noexcept {
    static_assert(!std::is_lvalue_reference<_Tp>::value, "template argument"
    " substituting _Tp is an lvalue reference type");
    return static_cast<_Tp&&>(__t);
}
```

### lambda 

[揭开lambda的神秘面纱](https://mp.weixin.qq.com/s/oONwCjdrlMbgwMnUWQiLZw)

1. 概念
2. 基本语法（捕获列表）
3. 编译器实现
4. 可被function封装
5. 常用于需要谓词的算法中

**详细描述**

- 概念

Lambda 表达式是一种**匿名函数**的定义方式，它能够**更方便地在代码中创建临时的、局部的函数对象**，适用于许多场景，特别是在函数对象、回调函数等地方。以下是 Lambda 表达式的一些重要特点：

- 匿名函数： Lambda 表达式是一种匿名的、内联的函数定义方式，可以在需要的地方直接定义并使用，而不必显式地声明一个函数。

- 捕获变量： Lambda 表达式可以通过捕获变量（Capturing Variables）来捕获外部作用域中的变量，使得这些变量可以在 Lambda 表达式内部使用。

- 参数列表和函数体： Lambda 表达式可以具有参数列表和函数体，就像普通的函数一样。参数列表在 [] 内指定，函数体在 {} 内。

- 自动类型推导： Lambda 表达式中的参数和返回值可以使用 auto 关键字进行自动类型推导，减少了类型的冗余。

- 可调用对象： Lambda 表达式可以被当作可调用对象（函数对象）来使用，可以作为函数参数、赋值给函数指针、在容器中存储等。

一个 lambda 表达式表示一个可调用的代码单元，可以理解为一个**匿名的内联函数，可以在需要函数对象的任何地方使用**

假设要对一个 vector 进行排序，即调用 `sort(nums.begin(), nums.end(), f)`。在 c++11 之前可以使用普通函数（函数指针作为参数），也可以使用函数对象（即类对象作为参数，类重载了调用运算符）

但是上述两者实现均有其局限性，普通函数的实现方式优点是具有最小的语法开销，但缺点是不能限定作用域（即必须在使用作用域外进行定义）；而函数对象的优点是可以在作用域内进行定义，但缺点是需要有类定义的语法开销。lambda 就是结合了二者的优点

- 基本语法（捕获列表）

**包括捕获列表，函数参数，附加说明符，返回类型，函数体**

参数列表和返回值类型都是可省略部分，而捕获列表和函数体可以为空但不可省略。最简单的 lambda 为 []{}; 不能做任何事情

```c++
[capture](parameters) specifiers exception attr -> return type { /*code; */ }

// [capture]代表捕获列表，括号内为外部变量的传递方式，包括值传递、引用传递等
// (parameters)代表参数列表，其中括号内为形参，和普通函数的形参一样
// specifiers exception attr代表附加说明符，一般为mutable、noexcept等
// ->return type代表lambda函数的返回类型如 -> int、-> string等。在大多数情况下不需要，因为编译器可以推导类型
// {}内为函数主体，和普通函数一样
```

捕获的作用是**捕获** lambda 所在函数的**局部变量**（捕获全局变量或者静态变量编译器会报warning, **无法在 lambda 中捕获带有静态存储持续时间的变量**, 但是可以在函数体内使用甚至修改全局变量）。其中捕获的类型可以分为**值捕获，引用捕获和隐式捕获**。值捕获为只读变量，若要修改的话需加 `mutable`。可以 `[x, &y]` x按照值捕获和y按照引用捕获。c++14 之后还可以捕获初始化表达式，即 `[z = x + y]`, 即生成一个新的成员变量并用 x + y 进行初始化

- 编译器实现

编译器针对lambda会生成一个类__lambda_xxxx，然后调用该类的成员函数

lambda表达式中的捕获列表，对应lambda_xxxx类的 private 成员
lambda表达式中的形参列表，对应lambda_xxxx类成员函数 operator() 的形参列表
lambda表达式中的mutable，对应lambda_xxxx类成员函数 operator() 的常属性 const，即是否是常成员函数
lambda表达式中的返回类型，对应lambda_xxxx类成员函数 operator() 的返回类型
lambda表达式中的函数体，对应lambda_xxxx类成员函数 operator() 的函数体


### 多态，虚函数表

[多态实现-虚函数、函数指针以及变体](https://mp.weixin.qq.com/s?__biz=Mzk0MzI4OTI1Ng==&mid=2247488149&idx=1&sn=4b7718a8798245b3a50e1fc9aebf5dee&chksm=c3377452f440fd44d13a4a99d3e16a2d06de0539b9f8365b7346de9c8037ea91b59f46df934f&cur_album_id=2282345872954933250&scene=190#rd)

[C++ 虚函数表剖析](https://zhuanlan.zhihu.com/p/75172640)

多态是面向对象编程中的一个重要概念，它允许使用统一的接口来操作不同的对象，使得不同类的对象可以以一种统一的方式进行操作，从而增强了代码的灵活性和可扩展性。C++ 中的动态多态主要通过虚函数和动态绑定来实现。

- 虚函数（Virtual Function）： 虚函数是在基类中声明为虚函数的成员函数。它可以在派生类中进行重写（覆盖），从而实现不同类对象对同名函数的多态调用。虚函数通过在基类中使用 virtual 关键字进行声明，在派生类中使用相同的函数名和参数列表进行重写。

- 动态绑定（Dynamic Binding）： 动态绑定是指在运行时根据对象的实际类型来决定调用哪个版本的虚函数。通过指针或引用来访问对象时，实际调用的函数取决于指针或引用所指向的对象的类型，而不是指针或引用本身的类型。

1. 多态的分类（静态，动态）
2. 虚函数
3. 虚继承

**详细介绍**

多态体现在编译时和运行时两个方面。将**编译时多态称之为静态多态**，而将**运行时多态称之为动态多态**。静态多态和动态多态的区别是在什么时候将函数实现和函数调用关联起来，是在编译时还是运行时。

传统上，**静态多态分为函数重载和模板(也称为泛型编程)两种**。而**运行时多态则仅有虚函数一种**。在但还有两种多态-**函数指针多态(静态多态)和variant多态（动态多态）**两种。

虚函数的作用主要是实现运行时多态。在基类中声明一个虚函数，然后在派生类中对其进行重写。基类的引用或者指针指向一个派生类对象，当该基类变量调用该函数时候，会自动调用派生类的函数，这就是所谓的动态多态

虚函数是通过一张虚函数表来实现的。简称为vtbl。在这个表中，主是要一个类的虚函数的地址表，这张表解决了继承、覆盖的问题，保证其容真实反应实际的函数。编译器会为每个存在虚函数的类对象插入一个vtpr指向存放了虚函数地址的虚函数表vtbl，这样对象在调用虚函数的时候，第一步会先根据vptr找到vbtl，然后根据该虚函数在vbtl中的索引（声明顺序）来进行调用，这样就实现了运行时多态功能。

```c++
// 手动调用虚函数
class Base {
public:
    virtual void Print(){ 
        std::cout << "Base::Print" << std::endl;
    }
    virtual void fun() {
      std::cout << "in Base::fun" << std::endl;
    }
};

class Derived : public Base {
public:
    void Print()  { 
        std::cout << "in Derived::Print" << std::endl;
    }
  
    void fun() {
      std::cout << "in Derived::fun" << std::endl;
    }
};

typedef void(*Fun)();

int main() {
    Derived d;
    long address = *(long*)&d; // vptr 通常放在对象首位，获取其地址
    Fun fun= (Fun)(*(long*)address); // 获取函数 Print 的地址并讲指针内容转为 Fun 类型的函数指针
    fun();
    fun = (Fun)(*(((long*)address)+1));
    fun();
    return 0;
}
```

- name mangling

因为允许函数重载，编译器会对函数进行name mangling，说下编译器mangling后函数名的规则，仍然以成员函数Print()优化后的名称_ZN4Base5PrintEv为例(gcc，不同编译器不同)：

    编码后的符号由_Z开头
    如果有作用域符，则在_Z之后加上N
    接着是命名空间名字长度、命名空间名字、类名字长度、类名、成员函数名称、函数名称
    如果有作用域符，则以E结尾
    最后加上函数形参符号，void是v，int是i，char是c，P代表指针，有几个形参就写几个符号


从上述规则我们可以看出，C++中的重载只跟函数名和函数参数有关。

- 效率优化

为了保证运行效率，编译器会将普通成员函数的效率优化成与普通函数一致，而对于虚函数的效率优化，则相较于普通成员函数，仅仅多了一次虚函数寻址

对于成员函数，编译器内部已经将成员函数实体转换为对应的非成员函数实体。改写函数原型以安插一个额外的对象的地址到成员函数中，将成员函数重新写成一个外部函数，对函数名称进行mangling处理，使它在程序中称为独一无二的词汇

对于虚函数，虽然并不知道指针所指对象的具体类型，但是有两点很清楚（无论ptr对应哪种对象，我们总是可以通过ptr找到对应对象的vtbl， 无论ptr对应哪种对象，Print()函数的地址总是在虚函数表的第1位）。因此编译器将会对调用进行优化

```c++
// 源代码
Base *ptr = new Derived;
ptr->Print();
// 优化后的代码，虚函数调用时会将调用该函数的对象的指针作为参数传递给函数
(*ptr->vptr[offset])(ptr); 
// ptr为对象地址，vptr表示由编译器产生的指针，指向虚函数表
```

**内联函数**（内联函数需要在编译阶段展开，而虚函数是运行时动态绑定的，编译时无法展开）、**构造函数**（构造函数在进行调用时还不存在父类和子类的概念，父类只会调用父类的构造函数，子类调用子类的，因此没有动态绑定的效果）、**静态成员函数**（静态成员函数是以类为单位的函数，与具体对象无关，虚函数是与对象动态绑定的）**都不可以是虚函数**

在**构造函数**(父类对象会在子类之前进行构造，此时子类部分的数据成员还未初始化，因此调用子类的虚函数时不安全的，故而C++不会进行动态联编)和**析构函数**(先调用子类的析构函数，然后再调用基类的析构函数。所以在调用基类的析构函数时，派生类对象的数据成员已经销毁，这个时候再调用子类的虚函数没有任何意义)中可以**调用虚函数**，但是没有任何意义并且不安全

- 简述 C++ 中虚继承的作用及底层实现原理？

虚表 vtbl 是属于类的，而不是属于某个具体的对象，一个类只需要一个虚表即可。同一个类的所有对象都使用同一个虚表。为了指定对象的虚表，对象内部包含一个虚表的指针 vptr，来指向自己所使用的虚表。

虚表是一个指针数组，其元素是虚函数的指针，每个元素对应一个虚函数的函数指针，**虚表内的条目即虚函数指针的赋值发生在编译器的编译阶段！！**当类的对象在创建时便拥有了这个指针，且这个指针的值会自动被设置为指向类的虚表。

```c++
class A {
public:
    virtual void vfunc1();
    virtual void vfunc2();
    void func1();
    void func2();
private:
    int m_data1, m_data2;
};

class B : public A {
public:
    virtual void vfunc1();
    void func1();
private:
    int m_data3;
};

class C: public B {
public:
    virtual void vfunc2();
    void func2();
private:
    int m_data1, m_data4;
};
```
![](https://pic2.zhimg.com/80/v2-0fceb07713e411d48b4c361452129585_720w.webp)

![](https://pic3.zhimg.com/80/v2-dfe4aefdee7e06cf3151b57492ed42a2_720w.webp)

一个继承类的基类如果包含虚函数，那个这个继承类也有拥有自己的虚表，故这个继承类的对象也包含一个虚表指针，用来指向它的虚表。**对象的虚表指针用来指向自己所属类的虚表，虚表中的指针会指向其继承的最近的一个类的虚函数**。因此当基类指针指向继承类时，ptr 可以访问到继承类对象的虚表指针进而访问继承类的虚表，实现动态绑定（1.通过指针或引用来调用函数；2.上行转型；3.调用的是虚函数）

在多继承环境下会产生菱形继承的问题，虽然可以利用作用域来直接访问基类数据，但是会存在多个数据，如下的 d.B::a 和 d.C::a 是两个相互独立的变量

```c++
class A {
public:
	int a;
};

class B : public A { // virtual public A
public:
	int b;
};

class C : public A { // virtual public A
public:
	int c;
};

class D : public B, public C {
public:
	int d;
};

int main() {
	D d;
	d.B::a = 5; // 若直接 d.a 会报错，因为不知道通过B还是通过C
	cout << d.B::a << endl;
	return 0;
}
```
**在多继承情况下，有多少个基类就有多少个虚函数表指针，前提是基类要有虚函数。子类虚函数会覆盖每一个父类的每一个同名虚函数**

菱形继承：虚继承是解决C++多重继承问题的一种手段，从不同途径继承来的同一基类，会在子类中存在多份拷贝。这将存在两个问题：其一，浪费存储空间；第二，存在二义性问题

虚继承用于解决多继承条件下的菱形继承问题，一般通过虚基类指针和虚基类表实现，每个虚继承的子类都有一个虚基类指针和虚基类表。虚派生只影响从指定了虚基类的派生类中进一步派生出来的类
虚基类依然会在子类里面存在拷贝。
虚继承的子类被当做父类继承时，虚基类指针也会被继承

**虚继承和虚函数的区别：**虚基类依旧存在继承类中，只占用存储空间；虚函数不占用存储空间；虚基类表存储的是虚基类相对直接继承类的偏移；而虚函数表存储的是虚函数地址。

### 智能指针

智能指针是一种用于管理动态分配的对象的智能工具，它们能够自动处理资源的分配和释放，从而避免内存泄漏等问题。智能指针的主要目的是提供自动化的内存管理。

- 背景：在 C++ 中，手动管理动态分配的内存可能会导致忘记释放内存、多次释放内存、内存泄漏等问题。为了解决这些问题，C++引入了智能指针。

- 作用：智能指针通过封装指针并在适当的时机自动释放内存，从而实现了自动内存管理。它们可以在对象生命周期结束时自动释放内存，而不需要开发人员手动调用delete。

C++11 引入了三种主要类型的智能指针：std::shared_ptr、std::unique_ptr 和 std::weak_ptr

智能指针一个很关键的一个点就是是否拥有一个对象的所有权，当我们通过std::make_xxx或者new一个对象，那么就拥有了这个对象的所有权。**所有权分为独占所有权、共享所有权以及弱共享所有权三种**

#### sharedPtr和uniquePtr，weakptr

- **shared_ptr**采用引用计数器的方法，允许多个智能指针指向同一个对象，每当多一个指针指向该对象时，指向该对象的所有智能指针内部的引用计数加1，每当减少一个智能指针指向对象时，引用计数会减1，当计数为0的时候会自动的释放动态分配的资源
  
  - 将一个计数器与类指向对象相关联，引用计数器跟踪共有多少个类对象共享同一指针
  
  - 每次创建类的新对象时，初始化指针并将引用计数置为1
  
  - 当对象作为另一对象的副本而创建时，拷贝构造函数拷贝指针并增加与之相应的引用计数
  
  - 对一个对象进行赋值时，赋值操作符减少左操作数所指对象的引用计数（如果引用计数为减至0，则删除对象），并增加右操作数所指对象的引用计数
  
  - 调用析构函数时，减少引用计数（如果引用计数减至0，则删除基础对象）

- **unique_ptr**采用的是**独享所有权**，一个非空的unique_ptr总是拥有它所指向的资源。转移一个unique_ptr将会把所有权全部从源指针转移给目标指针，源指针被置空；当 std::unique_ptr 被销毁时，其所拥有的对象也会被自动释放。
  
  - unique_ptr不支持普通的拷贝和赋值操作，**不能用在STL标准容器中**；局部变量的返回值除外（因为编译器知道要返回的对象将要被销毁）；如果拷贝一个unique_ptr，那么拷贝结束后，这两个unique_ptr都会指向相同的资源，造成在结束时对同一内存指针多次释放而导致程序崩溃。
  
  - unique_ptr指针本身的生命周期：从unique_ptr指针创建时开始，直到离开作用域。离开作用域时，若其指向对象，则将其所指对象销毁(默认使用delete操作符，用户可指定其他操作)。
  
  - unique_ptr指针与其所指对象的关系：在智能指针生命周期内，可以改变智能指针所指对象，如创建智能指针时通过构造函数指定、通过reset方法重新指定、通过release方法释放所有权、通过移动语义转移所有权

- **weak_ptr** 是一种不控制对象生命周期的智能指针, 它**指向一个 shared_ptr 管理的对象**. 进行该对象的内存管理的是那个强引用的 shared_ptr. **解决循环 shared_ptr 引用问题**。弱共享所有权，指的是可以使用该对象，但是没有所有权，由真正拥有其所有权的来负责释放
  
  - weak_ptr只是提供了对管理对象的一个访问手段。
  
  - weak_ptr 设计的目的是为配合 shared_ptr 而引入的一种智能指针来协助 shared_ptr 工作, 它只可以从一个 shared_ptr 或另一个 weak_ptr 对象构造, 它的构造和析构不会引起引用记数的增加或减少

#### C++智能指针循环引用如何解决

- 虽然智能指针会减少内存泄漏的可能性，但是如果使用智能指针的方式不对，一样会造成内存泄漏。比较典型的情况是循环引用问题

- shared_ptr改成weak_ptr即可，由于weak_ptr不会增加shared_ptr的引用计数，因此**引用计数对象当ref_count减至zero时会销毁其管理的资源**

#### 多线程下的shared_ptr的安全问题

- shared_ptr引用计数是原子的(shared_ptr底层中在对引用计数进行访问之前，首先对其加锁，当访问完毕之后，在对其进行解锁)，它的析构函数原子地将引用计数减去1，当多个线程对同一对象析构时，也只会出现执行顺序的交错，不会有内存泄露。

- 在我们通过shared_ptr.get()和*解引用获得了指向该内存的原始指针，那么后面都是对原始指针的操作，所以需要自己控制线程的安全

- 如何使多个线程可以对同一个shared_ptr实体进行同时读写？运用weak_ptr这个助手检测指针是否被释放，使用**weak_ptr.lock**函数就可以得到一个shared_ptr的指针，如果该指针已经被其它地方释放，它则返回一个空的shared_ptr，也可以使用weak_ptr.expired()来判断一个指针是否被释放

- **多个shared_ptr对象对其所管理的资源的访问不是线程安全的**。如果不使用锁这会造成线程安全问题


#### auto_ptr 被废弃的原因

auto_ptr采用copy语义来转移所有权，转移之后，其关联的资源指针设置为NULL，而这跟我们理解上copy行为不一致。所以 **auto_ptr被废弃的直接原因是拷贝造成所有权转移**，因此存在如下限制：

- 不能在STL容器中使用，因为复制将导致数据无效
- 一些STL算法也可能导致auto_ptr失效，比如std::sort算法
- 不能作为函数参数，因为这会导致复制，并且在调用后，导致原数据无效
- 如果作为类的成员变量，需要注意在类拷贝时候导致的数据无效

### std::bind

std::bind 是 C++ 标准库中的一个函数模板，用于创建一个函数对象（也称为函数绑定器或函数适配器）。它允许你将一个函数与一些参数绑定，生成一个新的可调用对象，可以用来延迟调用函数，设置默认参数值，改变函数签名等。std::bind 在函数式编程和泛型编程中非常有用，它的功能类似于 lambda 表达式，但更灵活

```c++
// F 表示要绑定的函数或函数指针，Args... 表示需要传递给函数的参数
// std::bind 返回一个函数对象，它可以被调用并执行绑定的函数
template< class F, class... Args >
bind( F&& f, Args&&... args );
```

以下是 std::bind 的一些重要特点和用法：

- 参数绑定： 你可以将一部分参数绑定到函数上，以后再提供剩余的参数。这可以用来设置默认参数值或者改变函数的参数顺序

- 占位符 _1, _2, ...： 在 std::bind 中，你可以使用占位符 _1, _2, ... 来表示要绑定的函数参数的位置。例如，_1 表示第一个参数，_2 表示第二个参数，以此类推

- 传递参数： std::bind 可以传递任意类型的参数，包括值、引用、左值、右值等

- 成员函数绑定： 除了普通函数，你还可以用 std::bind 来绑定类的成员函数

- 返回类型： std::bind 的返回类型是一个函数对象，可以像普通函数一样调用

```c++
void print_values(int a, int b, int c) {
    std::cout << "a: " << a << ", b: " << b << ", c: " << c << std::endl;
}

int main() {
    auto func1 = std::bind(print_values, std::placeholders::_1, 20, 30);
    func1(10); // 输出：a: 10, b: 20, c: 30

    auto func2 = std::bind(print_values, std::placeholders::_3, std::placeholders::_2, std::placeholders::_1);
    func2(10, 20, 30); // 输出：a: 30, b: 20, c: 10

    auto func3 = std::bind(print_values, std::placeholders::_2, std::placeholders::_1, 5);
    func3(10, 20); // 给的参数跟占位符相关，若占位符为 (_3, _2, 30) 就不行，因为这样表示至少提供三个实参
    // 输出：a: 20, b: 10, c: 5
    return 0;
}
```

- 绑定成员函数
  
```c++
class MyClass {
public:
    void print_message(const std::string& message) {
        std::cout << "Message: " << message << std::endl;
    }
};

int main() {
    MyClass obj;
    auto member_func = std::bind(&MyClass::print_message, &obj, std::placeholders::_1);
    member_func("Hello, world!"); // 输出：Message: Hello, world!
    return 0;
}
```

- 传引用

```c++
void foo(int& value) {
    value = 42;
}

int main() {
    int num = 0;
    // 使用 std::bind 传递引用
    auto func = std::bind(foo, std::ref(num));
    func();
    std::cout << "num: " << num << std::endl; // 输出: num: 42
    return 0;
}

```

### 内存越界与内存泄漏问题如何排查

**排查内存越界问题：**

1. **使用工具：** 使用内存检测工具，如 `Valgrind`，`AddressSanitizer` 等，来检查内存越界问题。

2. **断言（assert）：** 在代码中使用断言来检查数组、指针访问是否合法，如 `assert(index >= 0 && index < size)`。

3. **边界检查：** 使用标准库函数（如 `std::vector::at()`）或自行添加边界检查来确保访问数组或容器时不会越界。

4. **遵循指针规则：** 严格遵循指针和数组的使用规则，避免指针算术和越界访问。

**排查内存泄漏问题：**

1. **静态代码分析工具：** 使用静态代码分析工具（如 `Cppcheck`，`Clang Static Analyzer`）来检查代码中的内存泄漏问题。

2. **内存检测工具：** 使用内存检测工具，如 `Valgrind`，`AddressSanitizer` 等，来检查内存泄漏问题。

3. **手动跟踪：** 在内存分配和释放的地方添加日志，手动跟踪内存分配和释放的情况。

4. **RAII（Resource Acquisition Is Initialization）：** 使用智能指针、资源管理类等 RAII 机制来自动管理资源的释放，避免遗漏释放。

5. **注意局部变量：** 确保在不再需要时及时释放局部变量。

6. **使用容器：** 使用标准库的容器（如 `std::vector`，`std::string`）等，它们会自动处理内存分配和释放。

Linux下可以使用**Valgrind工具**；Windows下可以使用**CRT库**

- 检测原理

检测内存泄漏的关键是要能截获住对分配内存和释放内存的函数的调用。截获住这两个函数，我们就能跟踪每一块内存的生命周期，比如，每当成功的分配一块内存后，就把它的指针加入一个全局的list中；每当释放一块内存，再把它的指针从list中删除。这样，当程序结束的时候，list中剩余的指针就是指向那些没有被释放的内存。

如果要检测堆内存的泄漏，那么需要截获住malloc / realloc / free和new/delete就可以了。对于其他的泄漏，可以采用类似的方法，截获住相应的分配和释放函数

要想检测内存泄漏，就必须对程序中的内存分配和释放情况进行记录，所能够采取的办法就是重载所有形式的operator new 和 operator delete，截获 new operator 和 delete operator 执行过程中的内存操作信息。


### vector push_back 时间复杂度

假定有 n 个元素,倍增因子为 m。那么完成这 n 个元素往一个 vector 中的push_back​操作，需要重新分配内存的次数大约为 logm(n)，第 i 次重新分配将会导致复制 m^i (也就是当前的vector.size() 大小)个旧空间中元素，因此 n 次 push_back 扩容操作所花费的总时间为

![](https://pic4.zhimg.com/v2-2bd25ca31097e26a19365115a0e3e813_b.png)

![](https://gss0.baidu.com/7Po3dSag_xI4khGko9WTAnF6hhy/zhidao/wh%3D600%2C800/sign=9c087afd7ef0f736d8ab44073a659f21/fc1f4134970a304e1273ec78d7c8a786c8175cda.jpg)

等比数列，即 m + m^2 + ... + m^(logm(n)) = (m - m ^ (logm(n)) * m)/(1 - m) = m * (n - 1) / (m - 1), 约为 n * m / (m - 1), 均摊下来为 O (1)


### 四种强制类型转换

1. static_cast：

   - 主要用于**基本数据类型**之间的转换，以及**父子类**之间的向上或向下转换（必须具备继承关系）

   - **在编译时进行，不进行运行时类型检查**，因此不适用于多态类型转换

   - 用于执行常见的显式类型转换，比如将浮点数转为整数，将整数转为指针等

2. dynamic_cast：

   - 主要用于在继承关系中进行**安全的向上和向下转换**

   - **仅适用于具有虚函数的类，它会在运行时检查类型信息**，如果类型不匹配则返回空指针（对于指针）或引发 std::bad_cast 异常（对于引用）

   - 用于处理基类指针或引用指向派生类对象的情况，通常在运行时进行类型检查

3. const_cast：

   - 主要用于**去除指针或引用的 const 限定符**

   - 可以添加或移除 const 修饰符，但**不能修改其他类型的限定符，如 volatile**

   - 用于在一些情况下（例如函数参数传递）取消 const 限制，以进行操作。

4. reinterpret_cast：

   - 执行低级别的类型转换，通常用于指针或整数之间的转换，甚至是不同类型之间的转换。

   - 通常不推荐使用，因为它会将数据解释为不同类型，**容易引发未定义行为**

   - 用于**执行底层的强制类型转换**，但在多数情况下不安全，应当避免使用。

### map和unordered_map区别（map为啥用红黑树不用avl树？）

map和unordered_map区别

1. 底层数据结构：

   - std::map 使用红黑树（Red-Black Tree）作为底层数据结构，这保证了元素的有序性。红黑树是一种自平衡的二叉搜索树，保持了 O(log n) 的查找、插入和删除复杂度。

   - std::unordered_map 使用哈希表（Hash Table）作为底层数据结构，这提供了 O(1) 平均复杂度的查找、插入和删除操作，但在某些情况下可能会退化到 O(n)。

2. 查找性能：

   - std::map 在保持有序性的情况下具有更好的查找性能，适用于需要按照键的顺序访问元素的情况。

   - std::unordered_map 具有常数级别的查找性能，适用于快速查找元素的情况，但不保持元素的顺序。

3. 内存消耗：

   - std::map 使用红黑树，相对来说占用较少的内存。
  
   - 由于哈希表需要维护哈希值和桶的结构，std::unordered_map 通常会占用更多的内存空间。

4. 元素顺序：

   - std::map 保持元素的有序性，即按键的顺序进行存储和遍历。
   
   - std::unordered_map 不保持元素的顺序，遍历的顺序可能与插入的顺序不同。

关于为什么 std::map 使用红黑树而不使用 AVL 树，主要有以下几个考虑：

性能和复杂度： 红黑树和 AVL 树都是自平衡二叉搜索树，但红黑树在插入和删除操作时可能需要更少的旋转操作，因此性能相对更好。而 AVL 树为了保持更严格的平衡，可能会有更多的旋转操作，使得操作复杂度增加。

实现复杂度： AVL 树相对于红黑树的实现更复杂，旋转操作较多。红黑树在平衡性和操作复杂度之间达到了一种平衡。

空间开销： AVL 树需要额外的空间存储平衡因子，而红黑树只需要一个额外的比特来表示节点的颜色，从而在空间上更为节省。

综合考虑，红黑树作为一种更简单、性能表现较好且平衡性良好的自平衡二叉搜索树，更适合作为 std::map 的底层数据结构。

### GDB的相关命令

```bash
# 启动 GDB
gdb <可执行文件>

# 设置断点
break <行号>
break <函数名>

# 运行程序
run

# 继续执行
continue

# 单步执行
step
next

# 打印变量值
print <变量名>
p &<变量名>

# 查看堆栈
backtrace
info frame

# 查看变量类型
whatis <变量名>

# 修改变量的值
set var <变量名> = <新值>

# 查看源代码
list
list <起始行号>,<结束行号>

# 跳转到指定行
jump <行号>

# 删除断点
delete <断点号>

# 查看寄存器的值
info registers

# 查看内存内容
x/<格式> <内存地址>

# 查看程序状态
info program

# 退出 GDB
quit
```

- coredump

coredump是程序由于异常或者bug在运行时异常退出或者终止（空指针解引用，内存越界，使用释放的内存），在一定的条件下生成的一个叫做core的文件，这个 core 文件会记录程序在运行时的内存，寄存器状态，内存指针和函数堆栈信息等等。对这个文件进行分析可以定位到程序异常的时候对应的堆栈调用信息。

使用gdb命令对core文件进行调试

```c++
mkdir coredumpTest

vim coredumpTest.cpp

#include<stdio.h>
int main() {
    int i;
    scanf("%d", i); // 正确的应该是 &i,这里使用 i 会导致 segment fault
    printf("%d\n", i);
    return 0;
}
g++ coredumpTest.cpp -g -o coredumpTest // 编译，注意 -g

./coredumpTest // 运行

gdb [可执行文件名] [core文件名] // 使用 gdb 调试 coredump
```

### 虚拟内存

虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页。

**这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。**当程序引用到不在物理内存中的页时，会触发缺页中断，操作系统负责将该页面调入物理内存，如果物理内存已满，操作系统需要选择一个页面进行置换到磁盘上，以腾出空间来放置新的页面。

从上面的描述中可以看出，**虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。**

GPT:

谈论虚拟内存的理解时，可以从以下几个方面进行回答：

1. **基本概念：** 虚拟内存是计算机操作系统中的一种内存管理技术，它将物理内存（RAM）和磁盘空间结合起来，使得程序认为它拥有连续的可用内存，而实际上，部分数据可能存储在磁盘上。

2. **地址空间分割：** 虚拟内存将每个进程的地址空间分为多个页面（或分页），每个页面通常大小固定（比如4KB）。这些页面可以映射到物理内存，也可以暂时存储在磁盘上。

3. **页面调度和置换：** 当进程访问虚拟内存中的某个页面时，操作系统负责将该页面调入物理内存，如果物理内存已满，操作系统需要选择一个页面进行置换到磁盘上，以腾出空间来放置新的页面。

4. **内存映射：** 操作系统通过页表将虚拟地址转换为物理地址，这种映射关系使得进程能够访问虚拟内存，而无需关心数据实际存储在物理内存还是磁盘上。

5. **优势：** 虚拟内存允许多个进程同时运行，不受物理内存大小的限制。它还提供了更高的内存使用效率，因为程序可以请求比实际物理内存更多的内存，而不会导致内存耗尽。

6. **隔离性与保护：** 虚拟内存为每个进程提供了独立的地址空间，使得各个进程彼此隔离，不会相互干扰。此外，操作系统可以使用页面权限位来保护进程的内存空间，防止非法访问。

7. **换页与性能影响：** 当进程频繁访问虚拟内存中的页面时，可能会导致大量的页面置换，这会增加磁盘I/O操作，从而降低性能。操作系统需要智能地管理页面调度，以尽量减少性能损失。

8. **页面错误：** 当进程访问虚拟内存中的页面未加载到物理内存时，会触发页面错误。操作系统会捕获这些错误，并根据需要从磁盘加载相应的页面。

9. **交换空间：** 操作系统通常会为虚拟内存设定一个交换空间，即磁盘上的一部分空间，用于存放暂时不活跃的页面。这有助于在物理内存不足时进行页面置换。

综上所述，通过从基本概念、地址空间分割、页面调度和置换、内存映射、优势、隔离性与保护、换页与性能、页面错误、交换空间以及使用场景等多个方面来回答，可以展现出对虚拟内存理解的全面性和深度。

### HTTP 各版本的优化

**HTTP/1.1 相比 HTTP/1.0 提高了什么性能？**

HTTP/1.1 相比 HTTP/1.0 性能上的改进：

- 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

但 HTTP/1.1 还是有性能瓶颈：

- 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
- 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分；
- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
- 没有请求优先级控制；
- 请求只能从客户端开始，服务器只能被动响应。

**HTTP/2 做了什么优化？**

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

那 HTTP/2 相比 HTTP/1.1 性能上的改进：

- 头部压缩（同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的部分。在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了）
- 二进制格式（头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧（Headers Frame）和数据帧（Data Frame）。因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这增加了数据传输的效率）
- 并发传输（多路复用，但是还是存在队头阻塞问题。HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。）
- 服务器主动推送资源（在响应http时可以主动推送CSS）

主动推送的实现
- 使用 WebSockets，允许客户端和服务器之间建立持久连接。通过WebSocket，服务器可以随时向客户端推送数据，而不需要客户端发起请求。这使得实时聊天、通知和实时数据更新等应用成为可能
- 使用 SSE，SSE是一种基于HTTP的协议，允许服务器向客户端推送事件。客户端通过在浏览器中使用EventSource对象监听事件，服务器可以周期性地将数据发送给客户端。SSE通常用于实时通知和更新

**HTTP/3 做了哪些优化？**

前面我们知道了 HTTP/1.1 和 HTTP/2 都有队头阻塞的问题：

- HTTP/1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是没有解决响应的队头阻塞，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。
- HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是一旦发生丢包，就会阻塞住所有的 HTTP 请求，这属于 TCP 层队头阻塞。

HTTP/2 队头阻塞的问题是因为 TCP，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！

UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。

QUIC 有以下 3 个特点。

- 无队头阻塞
- 更快的连接建立
- 连接迁移

**1.0 和 1.1 的却别**

- 长连接和短连接：

HTTP/1.0：默认使用短连接，即每个请求/响应后关闭连接。
HTTP/1.1：默认使用长连接，即连接在不再需要时保持打开，以支持持久连接。

- 持久连接：

HTTP/1.0：默认情况下，每个 HTTP 请求/响应都会建立一个新的连接。这在多资源获取时效率较低。
HTTP/1.1：支持持久连接，也称为连接复用。在单个连接上可以发送多个请求和响应，减少了建立和关闭连接的开销，提高了性能。

- 流水线化：

HTTP/1.0：不支持请求和响应的流水线化，即一个连接上的请求和响应必须按顺序进行，不能交错发送和接收。
HTTP/1.1：支持请求和响应的流水线化，可以在一个连接上同时发送多个请求，提高了并发性能。

- 缓存控制：

HTTP/1.0：缓存控制有限，主要使用 If-Modified-Since 头来检查资源是否更新。
HTTP/1.1：引入了更多的缓存控制机制，如 Cache-Control、ETag、If-None-Match 等，提供更灵活的缓存策略。

- 管道化（Pipeline）：

HTTP/1.0：不支持请求的管道化，即一个请求必须等待前一个请求完成才能发送。
HTTP/1.1：支持请求的管道化，可以在一个连接上发送多个请求，提高了并发性能。

- 主机头（Host Header）：

HTTP/1.0：未定义 Host 头，因此一个服务器上只能服务一个域名。
HTTP/1.1：引入了 Host 头，使得同一个服务器可以为多个域名提供服务，解决了虚拟主机的问题。

- 块传输编码（Chunked Transfer Encoding）：

HTTP/1.0：不支持分块传输编码，即数据必须完整传输。
HTTP/1.1：支持分块传输编码，可以将响应分割成多个块，逐个发送，适用于大文件下载等场景。

**1.1 和 2.0 的区别**

- 多路复用（Multiplexing）：

HTTP/1.1：使用持久连接，但在一个连接上一次只能处理一个请求/响应，即串行处理。
HTTP/2：引入了多路复用，可以在一个连接上并行处理多个请求/响应，提高了并发性能，减少了连接开销。

- 首部压缩（Header Compression）：

HTTP/1.1：每个请求和响应都带有一组首部，这些首部信息可能重复传输，造成了不必要的带宽消耗。
HTTP/2：使用了 HPACK 压缩算法对首部进行压缩，减少了首部传输的开销，节省了带宽。

- 服务器推送（Server Push）：

HTTP/1.1：客户端请求 HTML 后，需要解析 HTML 文件中的资源链接，然后再单独请求这些资源。
HTTP/2：支持服务器推送，服务器可以在发送响应的同时，将一些预测到客户端需要的资源推送给客户端，减少了往返时间。

- 流量控制（Flow Control）：

HTTP/1.1：没有明确的流量控制机制，容易出现“队头阻塞”问题，一个响应阻塞了后续的响应。
HTTP/2：引入了流量控制机制，可以避免队头阻塞问题，提高了传输效率。

- 优先级（Prioritization）：

HTTP/1.1：没有明确的请求优先级机制，所有请求都是平等的。
HTTP/2：支持请求优先级，可以指定哪些请求优先处理，提高了页面渲染速度。

- 协议升级（Protocol Negotiation）：

HTTP/1.1：协议升级需要使用握手和头部字段等方式，较为复杂。
HTTP/2：通过使用 ALPN 扩展来实现协议升级，更加简化和高效。

### HTTP和HTTPS的区别

HTTP和HTTPS（SSL+HTTP 协议构建的**可进行加密传输、身份认证的网络协议**）都是用于在网络上传输数据的协议，但它们之间有几个重要的区别：

- 安全性：

HTTP：是一种明文传输协议，数据在传输过程中是未加密的，容易被恶意拦截者截取和窃听。 HTTPS：通过使用SSL（Secure Sockets Layer）或TLS（Transport Layer Security）加密协议来保护数据的传输，确保数据在传输过程中是加密的，提供更高的安全性。

- 端口号：

HTTP：默认使用端口号80。 HTTPS：默认使用端口号443。

- URL前缀：

HTTP：URL前缀为"http://" HTTPS：URL前缀为"https://"

- 证书：

HTTPS：为了建立加密连接，服务器需要使用SSL/TLS证书。这个证书由一个受信任的证书颁发机构（CA）签发，用于验证服务器的身份。

- 性能：

由于HTTPS需要加密和解密数据，因此在一些情况下可能会比HTTP略微降低性能。然而，随着计算机硬件和加密技术的不断改进，这种性能差距在许多情况下已经不再明显。

- 搜索引擎排名：

搜索引擎（如Google）在搜索结果排名时更倾向于显示使用HTTPS的网站，因为HTTPS可以提供更好的安全性和隐私保护。

- 信任度：

用户更容易相信使用HTTPS的网站，因为他们可以看到浏览器地址栏中的锁图标，表示连接是加密的，而且网站的身份得到了认证

**HTTP**

- HTTP的状态码

- HTTP的常见字段
  - Host 字段，指定域名
  - Content-Length 字段，表明本次回应的数据长度
  - Connection 字段，设置长连接
  - Content-Type 字段，告知数据格式
  - Content-Encoding 字段，说明数据的压缩方法

- 请求方法 （特别是GET和POST的区别）

- HTTP 缓存技术（强制缓存, 协商缓存）
  - 强制缓存 Cache-Control: 是一个相对时间；Expires: 是一个绝对时间
  - 协商缓存 If-Modified-Since, Last-Modified 和 If-None-Match, ETag

- HTTP 特性
  - 双刃剑：（无状态，明文传输）
  - 缺点（不安全，为了解决这些问题，引入了HTTPS）
    - 窃听风险（通信链路上可以获取通信内容，号容易没）
    - 篡改风险（强制植入垃圾广告，视觉污染）
    - 伪装风险（冒充淘宝网站，用户钱容易没）
- HTTPS

    - 窃听风险：采用信息加密方法（混合加密方式）
    - 篡改风险：采用校验机制（摘要算法来实现完整性）
    - 伪装风险：提供身份证书（数字证书）

**1. 混合加密（对称加密和非对称加密）：**

在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。

在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。

- 两种加密方式各自的优缺点

对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。

非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

**2. 摘要算法 + 数字签名**

用摘要算法（哈希函数）来计算出内容的哈希值，也就是内容的「指纹」，这个哈希值是唯一的，且无法通过哈希值推导出内容。接收方收到信息后计算内容的哈希值并比较哈希值。

**通过哈希算法可以确保内容不会被篡改，但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明。**

为了避免这种情况，计算机里会用**非对称加密算法**来解决，两个密钥可以**双向加解密**的：

- **公钥加密，私钥解密**。这个目的是为了保证**内容传输的安全**，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；

- **私钥加密，公钥解密**。这个目的是为了**保证消息不会被冒充**，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。

因为非对称加密来加密耗时，不会用来加密实际传输内容。主要在于通过「私钥加密，公钥解密」的方式，来确认消息的身份，我们常说的**数字签名算法**，就是用的是这种方式，不过**私钥加密内容不是内容本身，而是对内容的哈希值加密**

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D.png)

**3. 数字证书**

通过摘要算法 + 数字签名的方式：
- 可以通过哈希算法来保证消息的完整性；
- 可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）；

但是这还远远不够，**还缺少身份验证的环节**，万一公钥是被伪造的呢？（可以替换客户端手上的拿到的公钥为自己的公钥，那么就可以伪装成服务器使用自己的私钥加密）

找受信任的第三方机构CA（数字证书认证机构），让它用自己的私钥给我的公钥做数字签名，然后将服务器的「个人信息 + 公钥 + 数字签名」打包成一个**数字证书，也就是说这个数字证书包含服务器的公钥。**

这样客户端就可以通过CA来验证数字证书到合法性，进而就能证明这个公钥就是服务器的

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/22-%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)

数字证书签发和验收流程 (浏览器或者操作系统中会内置很多 CA 公钥)

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E7%9A%84%E6%A0%A1%E9%AA%8C.png)

CA 签发证书的过程，如上图左边部分：

- 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；
- 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；
- 最后将 Certificate Signature 添加在文件证书上，形成数字证书；

客户端校验服务端的数字证书的过程，如上图右边部分：

- 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；
- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；
- 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。

**为什么抓包工具能截取 HTTPS 数据？**

工作原理与中间人一致，对于 HTTPS 连接来说，中间人要满足以下两点，才能实现真正的明文代理:

- 中间人，作为客户端与真实服务端建立连接这一步不会有问题，因为服务端不会校验客户端的身份；
- 中间人，作为服务端与真实客户端建立连接，这里会有客户端信任服务端的问题，也就是服务端必须有对应域名的私钥；

中间人要拿到私钥只能通过如下方式：

- 去网站服务端拿到私钥；
- 去CA处拿域名签发私钥；
- 自己签发证书，切要被浏览器信任；

不用解释，抓包工具只能使用第三种方式取得中间人的身份。使用抓包工具进行 HTTPS 抓包的时候，需要在客户端安装 Fiddler 的根证书，这里实际上起认证中心（CA）的作用。

抓包工具能够抓包的关键是客户端会往系统受信任的根证书列表中导入抓包工具生成的证书，而这个证书会被浏览器信任，也就是抓包工具给自己创建了一个认证中心 CA，客户端拿着中间人签发的证书去中间人自己的 CA 去认证，当然认为这个证书是有效的。

**如何避免被中间人抓取数据？**

- 不要点击任何证书非法的网站，这样 HTTPS 数据就不会被中间人截取到了
- 采用HTTPS 双向认证

GPT 说的缺点
- **缺乏加密**：HTTP通信使用明文传输数据，因此容易被窃听和截取敏感信息。这使得用户的隐私和数据安全容易受到威胁，尤其在不安全的公共网络上使用时更为明显。

- **缺乏数据完整性保护**：HTTP没有提供对传输数据完整性的验证机制，因此在传输过程中可能会被篡改。没有验证数据完整性的保护，可能导致信息损坏或数据不准确。

- **缺乏身份验证**：HTTP没有内置的身份验证机制，任何人都可以伪装成服务器或客户端进行通信。这使得 HTTP 面临身份伪造和冒充的风险。

- **性能较低**：由于 HTTP 协议是无状态的，每次请求都需要重新建立连接，对于频繁的请求和响应，会增加连接建立的开销，影响性能。

- **不支持并发请求**：HTTP/1.1 协议是串行处理请求和响应的，一个连接只能处理一个请求，如果有多个请求需要同时处理，就需要建立多个连接，增加了服务器和客户端的负担。

- **不适合传输大量数据**：HTTP 在传输大量数据时效率较低，因为它没有压缩数据的能力，导致传输时间较长


### HTTPS 是如何保证数据传输的安全，整体的流程是什么？（SSL是怎么工作保证安全的）

SSL/TLS 协议基本流程：

- 客户端向服务器索要并验证服务器的公钥。
- 双方协商生产「会话秘钥」。
- 双方采用「会话秘钥」进行加密通信。

前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。

TLS 的「握手阶段」涉及四次通信，使用不同的密钥交换算法，TLS 握手流程也会不一样的，现在常用的密钥交换算法有两种：**RSA** 算法 (opens new window)和 ECDHE 算法 (opens new window)。

- 握手阶段（Handshake）：

客户端向服务器发送一个连接请求，请求使用HTTPS进行通信。

服务器将自己的SSL证书发送给客户端。证书包含服务器的公钥和数字签名，由受信任的证书颁发机构（CA）签发

客户端验证证书的有效性，包括签名和颁发者。如果验证通过，客户端生成一个随机的加密密钥，然后使用服务器的公钥进行加密，并将其发送给服务器。

- 密钥协商阶段：

服务器使用自己的私钥解密客户端发送的加密密钥，得到共享的对称密钥。

客户端和服务器都使用这个共享的对称密钥来加密和解密通信数据。这种对称密钥加密的方式效率更高。

- 数据传输阶段：

客户端和服务器使用共享的对称密钥来加密和解密数据。数据在传输过程中使用加密算法进行加密，确保数据的保密性和完整性。

服务器将加密的数据发送给客户端，客户端解密并处理数据。

- 断开连接阶段：

客户端和服务器可以选择关闭连接或建立新连接继续通信。
SSL/TLS使用公钥加密（非对称加密）和对称加密的结合，以保证数据传输的安全。公钥加密用于安全地传输共享的对称密钥，而对称加密用于实际的数据传输，因为对称加密在加解密速度上更高效

SSL/TLS证书用于验证服务器的身份。服务器的证书由受信任的CA签发，客户端可以验证证书的有效性来确认服务器的真实性

1. Client给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法。
2. Server确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数（Server random）。
3. Client确认数字证书有效，然后生成一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给Server。
4. Server使用自己的私钥，获取Client发来的随机数（Premaster secret）。
5. Client和Server根据约定的加密方法，使用前面的三个随机数，生成”对话密钥”（session key），用来加密接下来的整个对话过程。

### Cokkie和Session

HTTP作为无状态协议，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务，必然需要在某种方式保持连接状态。（换句话说，服务器记不住你，可能你每刷新一次网页，就要重新输入一次账号密码进行登录。这显然是让人无法接受的，cookie 的作用就好比服务器给你贴个标签，然后你每次向服务器再发请求时，服务器就能够 cookie 认出你）

Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。（作用：会话状态管理，个性化设置，浏览器行为跟踪）

除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。

使用 Session 维护用户登录状态的过程如下：

- 用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
- 服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
- 服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；
- 客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。

**对比**

- Cookie是客户端保持状态的方法

Cookie简单的理解就是存储由服务器发至客户端并由客户端保存的一段字符串。为了保持会话，服务器可以在响应客户端请求时将 Cookie 字符串放在 Set-Cookie 下，客户机收到Cookie之后保存这段字符串，之后再请求时候带上Cookie就可以被识别

除了上面提到的这些，Cookie在客户端的保存形式可以有两种，一种是**会话 Cookie** 一种是**持久Cookie**，会话Cookie 就是将服务器返回的 Cookie 字符串保持在内存中，关闭浏览器之后自动销毁，持久 Cookie 则是存储在客户端磁盘上，其有效时间在服务器响应头中被指定，在有效期内，客户端再次请求服务器时都可以直接从本地取出。需要说明的是，存储在磁盘中的 Cookie 是可以被多个浏览器代理所共享的

- Session是服务器保持状态的方法

首先需要明确的是，Session保存在服务器上，可以保存在数据库、文件或内存中，每个Session文件中记录了用户的操作。我们可以理解为每个用户有一个独一无二的 Session ID 作为 Session文件的 Hash键，通过这个值可以锁定具体的Session结构的数据，这个Session结构中存储了用户操作行为。

**当服务器需要识别客户端时就需要结合 Cookie**。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是用Cookie来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在Cookie里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。**如果客户端的浏览器禁用了Cookie，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxx 这样的参数，服务端据此来识别用户，这样就可以帮用户完成诸如用户名等信息自动填入的操作了**

**区别**

- 1，存储的位置不同

cookie：存放在客户端; session：存放在服务端。Session存储的数据比较安全

- 2，存储的数据类型不同

两者都是key-value的结构，但针对value的类型是有差异的 cookie：value只能是字符串类型， session：value可以是Object类型，因为数据存储在服务器端，不受浏览器限制

- 3，存储的数据大小限制不同

cookie：大小受浏览器的限制，很多是是4K的大小， session：理论上受服务器内存的限制，可以存储更多的数据。

- 4，生命周期的控制

cookie：可以设置一个过期时间，可以在浏览器关闭后仍然保留（持久性Cookies）或在浏览器关闭后自动删除（会话性Cookies）

Session：会话性的，它的生命周期通常由用户会话控制。当用户关闭浏览器或超过一段时间没有活动时，会话会过期，服务器会清除Session数据

### TCP 可靠传输

为了实现可靠性传输，需要考虑很多事情，例如数据的破坏、丢包、重复以及分片顺序混乱等问题。TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。

[TCP 重传、滑动窗口、流量控制、拥塞控制](https://xiaolincoding.com/network/3_tcp/tcp_feature.html#%E9%87%8D%E4%BC%A0%E6%9C%BA%E5%88%B6)

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/3.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

查看TCP 的连接状态: `netstat -napt`
查看路由表（根据目标IP找网关以及端口）: `route -n`
查看ARP 缓存（根据IP找MAC）: `arp -a`

- 交换机的端口不具有 MAC 地址：首先检查FCS（帧校验序列），没问题放入到缓冲区，检查接收方的 MAC 地址是否已经在 MAC 地址表中有记录（会保存发送方的MAC以及端口），没有的话转发给除源端口的所有端口（若为广播地址同理）

- 路由器的各个端口都具有 MAC 地址和 IP 地址：首先检查FCS（帧校验序列），没问题再检查 MAC 头部中的接收方 MAC 地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。随后去掉 MAC 头部，根据 IP 确定包的转发，查询路由表，根据路由表的网关列判断对方的地址，若网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址(还需继续需要路由器转发); 如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明已抵达终点。再根据 IP 通过 ARP 查询 MAC 地址

**在网络包传输的过程中，源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址，因为需要 MAC 地址在以太网内进行两个设备之间的包传输**


### TCP

![](https://cdn.xiaolincoding.com//mysql/other/1310bf5ed78e4c8186481c47719e0793.png)

TCP 头格式：序列号用来解决网络包乱序问题；确认应答号用来解决丢包的问题

> 为什么需要 TCP 协议？

IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性

> 什么是 TCP 连接？

用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 Socket、序列号和窗口大小称为连接

Socket：由 IP 地址和端口号组成; 序列号：用来解决乱序问题等; 窗口大小：用来做流量控制

TCP 四元组（源IP，源端口，目的IP，目的端口）可以唯一的确定一个连接

> 有一个 IP 的服务端监听了一个端口，它的 TCP 的最大连接数是多少？

理论上最大的 TCP 连接数 = 客户端 IP 数 * 客户端端口数 （IPV4 : 2^32 * 2 ^16 = 2 ^ 48）

但是会受到文件描述符（系统级，用户级和进程级的限制）和内存的限制（每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM）

> TCP 和 UDP 可以使用同一个端口吗？

可以，「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。

> 为什么是三次握手？不是两次、四次？

1. 三次握手才能保证双方具有接收和发送的能力
2. 三次握手才可以阻止重复历史连接的初始化
3. 三次握手才可以同步双方的初始序列号
4. 三次握手才可以避免资源浪费

> 为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？

1. 为了防止历史报文被下一个相同四元组的连接接收（主要方面，恰好在接收方的接收窗口内）；
2. 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；

初始序列号 ISN 是根据一个计时器和哈希算法生成的

> 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

如果只交给 IP 层进行分片的话，那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。

当某一个 IP 分片丢失后，接收方的 IP 层就无法组装成一个完整的 TCP 报文（头部 + 数据），也就无法将数据报文送到 TCP 层，所以接收方不会响应 ACK 给发送方，因为发送方迟迟收不到 ACK 确认报文，所以会触发超时重传，就会重发「整个 TCP 报文（头部 + 数据）」。

所以，为了达到最佳的传输效能 TCP 协议在建立连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。

> 三次握手过程中某次握手数据丢失了会发生什么

1. 第一次握手丢失了：触发「超时重传」机制，重传 SYN 报文。客户端的 SYN 报文最大重传次数由  `tcp_syn_retries` 内核参数控制。每次超时的时间是上一次的 2 倍。总耗时大概在 1 min左右，当重传次数大于设定的值时，客户端会断开连接
2. 第二次握手丢失了：客户端会触发超时重传机制，重传 SYN 报文；服务端这边也会触发超时重传机制，重传 SYN-ACK 报文。SYN-ACK 报文的最大重传次数由 `tcp_synack_retries` 内核参数决定。超过重传次数后断开连接
3. 第三次握手丢失了：**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**，只有服务端触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。
   
> 什么是 SYN 攻击？如何避免 SYN 攻击？

Linux 内核维护 SYN 队列（半连接队列）与 Accpet 队列（全连接队列）

正常流程：

- 当服务端接收到客户端的 SYN 报文时，会创建一个半连接的对象，然后将其加入到内核的「 SYN 队列」；
- 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；
- 服务端接收到 ACK 报文后，从「 SYN 队列」取出一个半连接对象，然后创建一个新的连接对象放入到「 Accept 队列」；
- 应用通过调用 accpet() socket 接口，从「 Accept 队列」取出连接对象。

SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。

避免 SYN 攻击方式，可以有以下四种方法：

- 调大 netdev_max_backlog；
- 增大 TCP 半连接队列；
- 开启 tcp_syncookies；
- 减少 SYN+ACK 重传次数

> 四次挥手过程中某次挥手数据丢失了会发生什么

1. 第一次挥手丢失了：触发「超时重传」机制，重传 FIN 报文。重发次数由 tcp_orphan_retries 参数控制，重传次数超过设定的值后断开连接
2. 第二次挥手丢失了：ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。注意若客户端调用 close() 关闭连接并且收到了 ACK 进入 FIN_WAIT2，由于无法再发送和接收数据，所以 FIN_WAIT2 状态不可以持续太久，而 tcp_fin_timeout 控制了这个状态下连接的持续时长，默认值是 60 秒。这意味着对于调用 close 关闭的连接，如果在 60 秒后还没有收到 FIN 报文，客户端（主动关闭方）的连接就会直接关闭！！如果主动关闭方使用 shutdown 函数关闭连接，指定了只关闭发送方向，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的，如果主动关闭方一直没收到第三次挥手，那么主动关闭方的连接将会一直处于 FIN_WAIT2 状态
3. 第三次挥手丢失了：服务端就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的，超过次数后服务端断开连接；客户端因为是通过 close 函数关闭连接的，处于 FIN_WAIT_2 状态是有时长限制的，如果 tcp_fin_timeout 时间内还是没能收到服务端的第三次挥手（FIN 报文），那么客户端就会断开连接。
4. 第四次挥手丢失了：客户端 TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态；服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制，每次重发后会更新客户端的定时器，直到服务端关闭后客户端才会等待一段时间后关闭

2MSL时长 这其实是相当于至少允许报文丢失一次

> 为什么需要 TIME_WAIT 状态？

主动发起关闭连接的一方，才会有 TIME-WAIT 状态。

- 防止历史连接中的数据，被后面相同四元组的连接错误的接收；
- 保证「被动关闭连接」的一方，能被正确的关闭；

> TIME_WAIT 过多有什么危害？

- 占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；
- 占用端口资源，端口资源也是有限的，一般可以开启的端口为 32768～61000，也可以通过 net.ipv4.ip_local_port_range参数指定范围。

客户端和服务端 TIME_WAIT 过多，造成的影响是不同的。

- 如果客户端（主动发起关闭连接方）的 TIME_WAIT 状态过多，占满了所有端口资源，那么就无法对「目的 IP+ 目的 PORT」都一样的服务端发起连接了，但是被使用的端口，还是可以继续对另外一个服务端发起连接的。

- 如果服务端（主动发起关闭连接方）的 TIME_WAIT 状态过多，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。

如何优化 TIME_WAIT？

- 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项（可以复用处于 TIME_WAIT 的 socket 为新的连接所用）
- net.ipv4.tcp_max_tw_buckets（当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置）
- 程序中使用 SO_LINGER ，应用强制使用 RST 关闭（调用close后，会立该发送一个RST标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT状态，直接关闭）

> 服务器出现大量 TIME_WAIT 状态的原因有哪些？

TIME_WAIT 状态是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接，什么场景下服务端会主动断开连接呢？

- HTTP 没有使用长连接（只要客户端和服务端任意一方的 HTTP header 中有 Connection:close 信息，那么就无法使用 HTTP 长连接的机制）
- HTTP 长连接超时（HTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。为了避免资源浪费的情况，web 服务软件一般都会提供一个参数，用来指定 HTTP 长连接的超时时间，触发回调函数来关闭该连接）
- HTTP 长连接的请求数量达到上限（Web 服务端通常会有个参数，来定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接）

> 服务器出现大量 CLOSE_WAIT 状态的原因有哪些？

当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态

我们先来分析一个普通的 TCP 服务端的流程：

- 创建服务端 socket，bind 绑定端口、listen 监听端口
- 将服务端 socket 注册到 epoll
- epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket
- 将已连接的 socket 注册到 epoll
- epoll_wait 等待事件发生
- 对方连接关闭时，我方调用 close

可能导致服务端没有调用 close 函数的原因，如下。

第一个原因：第 2 步没有做，没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个事件，也就无法获取到已连接的 socket，那服务端自然就没机会对 socket 调用 close 函数了。

第二个原因： 第 3 步没有做，有新连接到来时没有调用 accpet 获取该连接的 socket，导致当有大量的客户端主动断开了连接，而服务端没机会对这些 socket 调用 close 函数，从而导致服务端出现大量 CLOSE_WAIT 状态的连接。

发生这种情况可能是因为服务端在执行 accpet 函数之前，代码卡在某一个逻辑或者提前抛出了异常。

第三个原因：第 4 步没有做，通过 accpet 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，那服务端就没机会调用 close 函数了。

发生这种情况可能是因为服务端在将已连接的 socket 注册到 epoll 之前，代码卡在某一个逻辑或者提前抛出了异常。之前看到过别人解决 close_wait 问题的实践文章，感兴趣的可以看看：一次 Netty 代码不健壮导致的大量 CLOSE_WAIT 连接原因分析(opens new window)

第四个原因：第 6 步没有做，当发现客户端关闭连接后，服务端没有执行 close 函数，可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑，比如发生死锁等等。

> 如果已经建立了连接，但是客户端突然出现故障了怎么办？

TCP 搞了个保活机制。定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序

Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔

如果开启了 TCP 保活，需要考虑以下几种情况：

- 第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。

- 第二种，对端主机宕机并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产生一个 RST 报文，这样很快就会发现 TCP 连接已经被重置。

- 第三种，是对端主机宕机（注意不是进程崩溃，进程崩溃后操作系统在回收进程资源的时候，会发送 FIN 报文，而主机宕机则是无法感知的，所以需要 TCP 保活机制来探测对方是不是发生了主机宕机），或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。

TCP 保活的这个机制检测的时间是有点长，web 服务软件一般都会提供 keepalive_timeout 参数，用来指定 HTTP 长连接的超时时间。

> 如果已经建立了连接，但是服务端的进程崩溃会发生什么？

TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程

### IP

- DNS
- ARP
- RARP
- DHCP

使用 UDP，过程分为四次
1. 客户端首先广播发起 DHCP 发现报文
2. DHCP 服务器广播响应 DHCP 提供报文（DHCP OFFER），携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 IP 地址租用期；
3. 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 DHCP 请求报文（DHCP REQUEST进行响应，回显配置的参数。
4. 服务端用 DHCP ACK 报文对 DHCP 请求报文进行响应，应答所要求的参数。

**DHCP 交互中，全程都是使用 UDP 广播通信**

> 用的是广播，那如果 DHCP 服务器和客户端不是在同一个局域网内，路由器又不会转发广播包，那不是每个网络都要配一个 DHCP 服务器？

所以，为了解决这一问题，就出现了 DHCP 中继代理。有了 DHCP 中继代理以后，对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。

DHCP 客户端会向 DHCP 中继代理广播 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以单播的形式发给 DHCP 服务器。服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包广播给 DHCP 客户端 。

一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址

如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址。

- NAT (网络地址转换)

缓解 IPv4 地址耗尽的问题。简单的来说 NAT 就是同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。普通的 NAT 转换如果有 N 个私有 IP 地址就要 N 个公有 IP 地址，没啥用

由于绝大多数的网络应用都是使用传输层协议 TCP 或 UDP 来传输数据的。因此，可以把 IP 地址 + 端口号一起进行转换。这样，就用一个全球 IP 地址就可以了，这种转换技术就叫网络地址与端口转换 NAPT。

NAPT 可以把多个 私有 IP 地址都转换成公有地址，但是以不同的端口号作为区分（哪怕两个本地主机的端口一样也可以转成不一样的）。通过生成一个 NAPT 路由器的转换表，就可以正确地转换地址跟端口的组合，令多个客户端能同时与服务器进行通信

> NAT 那么牛逼，难道就没缺点了吗？

由于 NAT/NAPT 都依赖于自己的转换表，因此会有以下的问题：

1. 外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。
2. 转换表的生成与转换操作都会产生性能开销。
3. 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。

> 如何解决 NAT 潜在的问题呢？

第一种就是改用 IPv6: IPv6 可用范围非常大，以至于每台设备都可以配置一个公有 IP 地址
第二种 NAT 穿透技术: 它能够让网络应用程序主动发现自己位于 NAT 设备之后，会主动获得 NAT 设备的公有 IP，并为自己建立端口映射条目，注意这些都是 NAT设备后的应用程序自动完成的。也就是说，在 NAT 穿透技术中，NAT设备后的应用程序处于主动地位（客户端主动从 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了）

- ICMP（互联网控制报文协议）

ICMP 主要的功能包括：确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。ICMP 的通知消息会使用 IP 进行发送

ICMP 大致可以分为两大类：

一类是用于诊断的查询消息，也就是「查询报文类型」（回送请求和回送应答）
另一类是通知出错原因的错误消息，也就是「差错报文类型」（目标不可达，原点抑制，超时，重定向或改变路由）

查询报文类型的使用 - ping
差错报文类型的使用 - traceroute

traceroute 的第一个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器（发送 UDP，填入一个不可能的端口号，当差错报文类型是端口不可达时，说明发送方发出的 UDP 包到达了目的主机）
traceroute 还有一个作用是故意设置不分片，从而确定路径的 MTU （UDP，将 IP 包首部的分片禁止标志位设置为 1，通过一个 ICMP 的不可达消息将数据链路上 MTU 的值一起给发送主机，不可达消息的类型为「需要进行分片但设置了不分片位」。发送主机端每次收到 ICMP 差错报文时就减少包的大小，以此来定位一个合适的 MTU 值）


- IGMP

IGMP 是因特网组管理协议，工作在主机（组播成员）和最后一跳路由之间

- IGMP 报文向路由器申请加入和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除非主机通过 IGMP 加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转发组播包到对应的主机了。
- IGMP 报文采用 IP 封装，IP 头部的协议号为 2，而且 TTL 字段值通常为 1，因为 IGMP 是工作在主机与连接的路由器之间。

IGMP 分为了三个版本分别是，IGMPv1、IGMPv2、IGMPv3。有常规查询与响应和离开组播组这两个工作机制。

以 IGMPv2 作为例子，

- 常规查询

  1. 路由器会周期性发送目的地址为 224.0.0.1（表示同一网段内所有主机和路由器） IGMP 常规查询报文。
  2. 主机1 和 主机 3 收到这个查询，随后会启动「报告延迟计时器」，计时器的时间是随机的，通常是 0~10 秒，计时器超时后主机就会发送 IGMP 成员关系报告报文（源 IP 地址为自己主机的 IP 地址，目的 IP 地址为组播地址）。如果在定时器超时之前，收到同一个组内的其他主机发送的成员关系报告报文，则自己不再发送，这样可以减少网络中多余的 IGMP 报文数量。
  3. 路由器收到主机的成员关系报文后，就会在 IGMP 路由表中加入该组播组，后续网络中一旦该组播地址的数据到达路由器，它会把数据包转发出去。

- 离开组播组工作机制

  1. 主机 1 要离开组 224.1.1.1，发送 IGMPv2 离组报文，报文的目的地址是 224.0.0.2（表示发向网段内的所有路由器）
  2. 路由器 收到该报文后，以 1 秒为间隔连续发送 IGMP 特定组查询报文（共计发送 2 个），以便确认该网络是否还有 224.1.1.1 组的其他成员。
  3. 主机 3 仍然是组 224.1.1.1 的成员，因此它立即响应这个特定组查询。路由器知道该网络中仍然存在该组播组的成员，于是继续向该网络转发 224.1.1.1 的组播数据包。（若无其它组成员的话就没有主机会响应这个查询，一定时间后，路由器认为该网段中已经没有 224.1.1.1 组播组成员了，将不会再向这个网段转发该组播地址的数据包）

### 索引

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/%E7%B4%A2%E5%BC%95/%E7%B4%A2%E5%BC%95%E6%8F%90%E7%BA%B2.png)
‘
- **从数据页的角度看 B+ 树**

InnoDB 的数据是按「数据页」为单位来读写的，默认数据页大小为 16 KB。每个数据页之间通过**双向链表**的形式组织起来，物理上不连续，但是逻辑上连续。

数据页内包含用户记录，**每个记录之间用单向链表的方式组织起来**，为了加快在数据页内高效查询记录，设计了一个页目录，**页目录存储各个槽（分组）**，且主键值是有序的，于是可以通过二分查找法的方式进行检索从而提高效率。

为了高效查询记录所在的数据页，InnoDB 采用 b+ 树作为索引，每个节点都是一个数据页。

如果**叶子节点存储的是实际数据的就是聚簇索引，一个表只能有一个聚簇索引**（因为实际数据只有一份）；**如果叶子节点存储的不是实际数据，而是主键值则就是二级索引，一个表中可以有多个二级索引**。

在使用二级索引进行查找数据时，如果查询的数据能在二级索引找到，那么就是「索引覆盖」操作，如果查询的数据不在二级索引里，就需要先在二级索引找到主键值，需要去聚簇索引中获得数据行，这个过程就叫作「回表」。

MySQL 使用哪种数据结构作为索引，实际上是在讨论存储引使用哪种数据结构作为索引，InnoDB 是 MySQL 默认的存储引擎，它就是采用了 B+ 树作为索引的数据结构

要设计一个 MySQL 的索引数据结构，**不仅仅考虑数据结构增删改的时间复杂度，更重要的是要考虑磁盘 I/0 的操作次数以及MYSQL的范围查询**。因为索引和记录都是存放在硬盘，硬盘是一个非常慢的存储设备，我们在查询数据的时候，最好能在尽可能少的磁盘 I/0 的操作次数内完成。

- **索引失效的情况**

![](https://cdn.xiaolincoding.com//mysql/other/a9e6a9708a6dbbcc65906d1338d2ae70.png)


- 索引**按照「索引值」有序排列存储**的，只能根据前缀进行比较（左或左右模糊匹配不行就无法走索引）

- 索引**保存的是索引字段的原始值**（经过函数计算后的值以及表达式计算后的值就无法走索引）

- MySQL 在遇到字符串和数字比较的时候，会**自动把字符串转为数字**，然后再进行比较（select “10” > 9 的结果为1）,所以如索引类型为varchar的电话号码而查询使用数字的话会走全表扫描；若索引为int而使用字符串判断条件的话会走索引

- 多个普通字段组合在一起创建的索引就叫做**联合索引**（数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序），联合索引要能正确使用需要遵循**最左匹配原则**（因为有查询优化器，所以字段在 where 子句的顺序并不重要），若不遵循最左匹配原则的话就会索引失效，比如查询的是b, c字段而无 a 字段。但是存在一种特殊的查询条件，如查询a,c字段（**索引截断**），不同版本处理方式也不一样
  - MySQL 5.5 的话，前面 a 会走索引，在联合索引找到主键值后，开始回表，到主键索引读取数据行，Server 层从存储引擎层获取到数据行后，然后在 Server 层再比对 c 字段的值。
  - 从 MySQL 5.6 之后，有一个**索引下推**功能，可以在存储引擎层进行索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，再返还给 Server 层，从而减少回表次数。

- WHERE 子句中的 OR（若存在条件列不是索引列，那么只能全表扫描）

**count 性能对比**

> count(*) = count(1) > count(主键字段) > count(字段)

count(1)、 count(*)、 count(主键字段)在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描。

所以，如果要执行 count(1)、 count(*)、 count(主键字段) 时，尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。

再来，就是不要使用 count(字段) 来统计记录个数，因为它的效率是最差的，会采用全表扫描的方式来统计。如果你非要统计表中该字段不为 NULL 的记录个数，建议给这个字段建立一个二级索引

### 事务

![](https://cdn.xiaolincoding.com//mysql/other/eb15d4b6a9d543c1be4f7090479d969c.png)

事务是由 MySQL 的引擎来实现的，我们常见的 InnoDB 引擎它是支持事务的

**ACID四大特性**

- 原子性（Atomicity）：一个事务中的所有操作，要么全部完成，要么全部不完成
- 一致性（Consistency）：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态
- 隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致
- 持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失

**InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？**

- 原子性是通过 undo log（回滚日志） 来保证的；
- 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；
- 持久性是通过 redo log （重做日志）来保证的；
- 一致性则是通过持久性+原子性+隔离性来保证；

**并行事务会引发什么问题？**

- 脏读：如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。若事务 A 发生了回滚，那么事务 B 刚才得到的数据就是过期的数据，这种现象就被称为脏读。
- 不可重复读：在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象（读到的都是已提交的数据）
- 幻读：在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。

**事务的隔离级别有哪些？**

三个问题的严重程度：脏读 > 不可重复读 > 幻读

- 脏读：读到其他事务未提交的数据；
- 不可重复读：前后读取的数据不一致；
- 幻读：前后读取的记录数量不一致。

提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低

- 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到；
- 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到；
- 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；
- 串行化（serializable ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；

![](https://cdn.xiaolincoding.com//mysql/other/4e98ea2e60923b969790898565b4d643.png)

**MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象**（并不是完全解决了），解决的方案有两种：

- 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。
- 针对当前读（select ... for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。

**四种隔离级别的实现：**

- 对于「读未提交」隔离级别的事务来说，因为可以读到未提交事务修改的数据，所以直接读取最新的数据就好了；
- 对于「串行化」隔离级别的事务来说，通过加读写锁的方式来避免并行访问；
- 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。

**在 MySQL 有两种开启事务的命令：**

- begin/start transaction 命令（只有在执行这个命令后，执行了增删查改操作的 SQL 语句，才是事务真正启动的时机）
- start transaction with consistent snapshot 命令（执行了该命令后，就会马上启动事务）

**Read View 在 MVCC 里的工作方式（读提交和可重复读）**

- Read View (四个字段)

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/mysql/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/readview%E7%BB%93%E6%9E%84.drawio.png)

- 聚簇索引 (两个隐藏列)

![](https://cdn.xiaolincoding.com//mysql/other/f595d13450878acd04affa82731f76c5.png)

- trx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里；
- roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。

一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：

- 如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。
- 如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。
- 如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中：
  - 如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。
  - 如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。

**这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）**

- **读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View**

- **可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View**


**总结**

事务是在 MySQL 引擎层实现的，我们常见的 InnoDB 引擎是支持事务的，事务的四大特性是原子性、一致性、隔离性、持久性，我们这次主要讲的是隔离性。

当多个事务并发执行的时候，会引发脏读、不可重复读、幻读这些问题，那为了避免这些问题，SQL 提出了四种隔离级别，分别是读未提交、读已提交、可重复读、串行化，从左往右隔离级别顺序递增，隔离级别越高，意味着性能越差，InnoDB 引擎的默认隔离级别是可重复读。

要解决脏读现象，就要将隔离级别升级到读已提交以上的隔离级别，要解决不可重复读现象，就要将隔离级别升级到可重复读以上的隔离级别。

而对于幻读现象，不建议将隔离级别升级为串行化，因为这会导致数据库并发时性能很差。MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象，解决的方案有两种：

- 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。
- 针对当前读（select ... for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。

对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同：

- 「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。
- 「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。

这两个隔离级别实现是通过「事务的 Read View 里的字段」和「记录中的两个隐藏列」的比对，来控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）。

在可重复读隔离级别中，普通的 select 语句就是基于 MVCC 实现的快照读，也就是不会加锁的。而 select .. for update 语句就不是快照读了，而是当前读了，也就是每次读都是拿到最新版本的数据，但是它会对读到的记录加上 next-key lock 锁。

### 锁

在 MySQL 里，根据加锁的范围，可以分为全局锁、表级锁和行锁三类

![](https://cdn.xiaolincoding.com//mysql/other/1e37f6994ef44714aba03b8046b1ace2.png)

**全局锁**

```sql
-- 执行后，整个数据库就处于只读状态了，这时其他线程执行以下操作，都会被阻塞
-- 对数据的增删改操作，比如 insert、delete、update等语句；
-- 对数据的增删改操作，比如 insert、delete、update等语句；
flush tables with read lock
unlock tables
-- 当会话断开了，全局锁会被自动释放
```

全局锁主要应用于做**全库逻辑备份**，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。但是加上全局锁，意味着整个数据库都是**只读状态**，会造成**业务停滞**。

优化：如果数据库的引擎支持的事务支持**可重复读的隔离级别**，那么**在备份数据库之前先开启事务，会先创建 Read View**，然后整个事务执行期间都在用这个 Read View，而且由于 **MVCC** 的支持，备份期间业务依然可以对数据进行更新操作。

**表级锁**

- **表锁**
  
```sql
-- 表级别的共享锁，也就是读锁；
lock tables t_student read;

-- 表级别的独占锁，也就是写锁；
lock tables t_stuent write;

-- 释放表锁，可以使用下面这条命令，会释放当前会话的所有表锁
unlock tables
-- 当会话退出后，也会释放所有表锁
```

表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作

尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能，**InnoDB 牛逼的地方在于实现了颗粒度更细的行级锁**

- **元数据锁（MDL）**

我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：

- 对一张表进行 CRUD 操作时，加的是 MDL 读锁；
- 对一张表做结构变更操作的时候，加的是 MDL 写锁；

**MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。MDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的**

MDL 会导致一个问题：如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那另一个事务B对表结构做变更操作会被阻塞，随后即使后续的申请读锁的查询操作也会被阻塞！大量的线程被阻塞住，这时数据库的线程很快就会爆满了！

**因为申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作**

所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更

- **意向锁**

意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，**只会和共享表锁（lock tables ... read）和独占表锁（lock tables ... write）发生冲突**

- 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；
- 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；

如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢

**意向锁的目的是为了快速判断表里是否有记录被加锁**

- **AUTO-INC 锁**

表里的主键通常都会设置成自增的，这是通过对主键字段声明 AUTO_INCREMENT 属性实现的。

之后可以在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值，这主要是通过 AUTO-INC 锁实现的。

AUTO-INC 锁是特殊的表锁机制，**锁不是在一个事务提交后才释放，而是在执行完插入语句后就会立即释放**

**在插入数据时，会加一个表级别的 AUTO-INC 锁**，然后为被 AUTO_INCREMENT 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉

但是， AUTO-INC 锁在对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞

因此， 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种**轻量级的锁**来实现自增

一样也是在插入数据的时候，会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，然后**给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁**

InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。

- 当 innodb_autoinc_lock_mode = 0，就采用 AUTO-INC 锁，语句执行结束后才释放锁；
- 当 innodb_autoinc_lock_mode = 2，就采用轻量级锁，申请自增主键后就释放锁，并不需要等语句执行后才释放。
- 当 innodb_autoinc_lock_mode = 1：
  - 普通 insert 语句，自增锁在申请之后就马上释放；
  - 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；

当 innodb_autoinc_lock_mode = 2 是性能最高的方式，但是当搭配 binlog 的日志格式是 statement 一起使用的时候，在「主从复制的场景」中会发生数据不一致的问题（生成的id不连续）。

**当 innodb_autoinc_lock_mode = 2 时，并且 binlog_format = row，既能提升并发性，又不会出现数据一致性问题**

**行级锁**

InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。

普通的 select 语句是不会对记录加锁的，因为它属于快照读。如果要在查询时对记录加行锁，可以使用下面这两个方式，这种查询会加锁的语句称为**锁定读**

```sql
//对读取的记录加共享锁
select ... lock in share mode;

//对读取的记录加独占锁
select ... for update;
```

上面这两条语句必须在一个事务中，因为当事务提交了，锁就会被释放，所以在使用这两条语句的时候，要加上 begin、start transaction 或者 set autocommit = 0

共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥

- **Record Lock (记录锁)**

锁住的是一条记录。而且记录锁是有 S 锁和 X 锁之分的：

- 当一个事务对一条记录加了 S 型记录锁后，其他事务也可以继续对该记录加 S 型记录锁（S 型与 S 锁兼容），但是不可以对该记录加 X 型记录锁（S 型与 X 锁不兼容）;
- 当一个事务对一条记录加了 X 型记录锁后，其他事务既不可以对该记录加 S 型记录锁（S 型与 X 锁不兼容），也不可以对该记录加 X 型记录锁（X 型与 X 锁不兼容）。

- **Gap Lock (间隙锁)**

**只存在于可重复读隔离级别，目的是为了解决可重复读隔离级别下幻读的现象**。假设，表中有一个范围 id 为（3，5）间隙锁，那么其他事务就无法插入 id = 4 这条记录了，这样就有效的防止幻读现象的发生

间隙锁虽然存在 X 型间隙锁和 S 型间隙锁，但是并没有什么区别，间隙锁之间是兼容的，即两个事务可以同时持有包含共同间隙范围的间隙锁，并不存在互斥关系，因为间隙锁的目的是防止插入幻影记录而提出的

- **Next-Key Lock (临键锁)**

**是 Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身**。假设，表中有一个范围 id 为（3，5] 的 next-key lock，那么其他事务即不能插入 id = 4 记录，也不能修改 id = 5 这条记录

next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的

- **插入意向锁**

一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。

如果有的话，插入操作就会发生**阻塞**，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个**插入意向锁**，表明有事务想在某个区间插入新记录，但是现在处于等待状态

*PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁*

**插入意向锁名字虽然有意向锁，但是它并不是意向锁，它是一种特殊的间隙锁，属于行级别锁**

如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。

插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）

### 日志

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/mysql/how_update/%E6%8F%90%E7%BA%B2.png)


### 虚拟地址

虚拟地址的好处：

1. **内存隔离：** 使用虚拟地址和物理地址可以隔离不同进程的内存，确保一个进程无法直接访问另一个进程的内存空间。这提供了安全性和隔离性，防止进程之间相互干扰或窥视彼此的内存。

2. **内存管理：** 虚拟地址允许操作系统在物理内存有限的情况下更有效地管理内存。操作系统可以通过内存分页、内存映射等技术来实现虚拟内存管理，使多个进程共享有限的物理内存，而不会相互干扰。

3. **地址空间扩展：** 虚拟地址空间通常比物理内存空间大得多。这允许操作系统和应用程序使用虚拟内存来处理大型数据集和程序，而无需关心物理内存的大小。虚拟地址空间的扩展为应用程序提供了更大的灵活性。

4. **内存保护：** 使用虚拟地址可以实现内存保护机制。操作系统可以标记虚拟地址上的页面为只读或不可访问，以保护操作系统内核和应用程序不受非法访问。

5. **地址重定位：** 虚拟地址允许操作系统在不同的物理地址上加载相同的程序，从而实现地址重定位。这在进程加载和卸载时非常有用。

6. **高效的共享：** 多个进程可以共享相同的虚拟地址空间，这在共享库和动态链接等方面非常有用。多个进程可以同时使用相同的虚拟内存，而不需要复制数据。

7. **交换空间：** 虚拟地址允许操作系统将部分进程数据交换到磁盘等外部存储介质，以释放物理内存供其他进程使用。这有助于避免内存耗尽。

总之，虚拟地址和物理地址的分离为计算机系统提供了更好的管理、隔离、安全性和灵活性，从而提高了操作系统和应用程序的效率和稳定性。这些优势在多任务操作系统中尤为重要，允许多个进程共享硬件资源而不会相互干扰。

## 八股

### c++

> 什么是线程安全，什么是线程不安全？

线程安全和线程不安全的区别在于对多线程并发访问的处理方式。线程安全的代码已经考虑了多线程环境，而线程不安全的代码可能需要额外的措施来确保正确性。线程不安全的代码可能在多线程环境中表现出不一致的行为，如竞态条件（Race Condition）、死锁（Deadlock）、数据竞争等。

线程安全的设计通常要求使用同步机制，如互斥锁、条件变量或原子操作，来确保多个线程之间对共享资源的访问是有序的和可控的。在多线程编程中，编写线程安全的代码是至关重要的，以避免潜在的问题和错误。

> static 作用，存储在哪。静态成员函数的作用。那const？

> 封装特性、封装整体的目的是？

C++中的封装是面向对象编程的核心概念之一，它将数据和操作封装在一个单元内部，隐藏了内部实现细节，只暴露对外必要的接口。
封装的主要目的是实现信息隐藏、模块化、代码复用和降低耦合度，从而提高代码的可维护性和可扩展性。

封装的特性包括：

访问控制： C++中的类可以使用public、private和protected关键字来指定成员的访问级别。public成员可以在类的外部访问，private成员只能在类内部访问，protected成员类似于private，但对派生类是可访问的。

成员函数： 类中的成员函数可以访问类的私有成员，它们可以被用来实现封装的操作。通过公共成员函数，外部可以通过限定接口来访问类的数据。

数据隐藏： 封装隐藏了类的内部数据实现细节，外部只能通过公共接口来操作数据，无法直接访问数据。

代码复用： 封装可以将数据和操作封装成类，提供一致的接口，可以在不同的程序中重复使用这些类，实现代码复用。

隔离变化： 如果类的内部实现发生变化，只需要修改类的内部，不会影响到外部调用者。这种隔离使得修改变得更加容易，不会影响外部代码。


> 多态如何实现（底层原理，函数重载，虚函数，虚函数表）？虚函数表存在哪里？多个虚函数会影响对象的大小吗？可以在析构函数和构造函数中使用虚函数吗？

> 内存对齐？为什么要有内存对齐

内存对齐要求数据的存储地址是某个特定值（通常是数据大小或者其倍数）的整数倍。这样做的目的是为了提高计算机的性能和访问效率。

内存对齐的原因和优势包括：

硬件要求： 许多计算机体系结构对于访问内存的操作要求数据在特定地址上对齐。如果数据没有按照正确的对齐方式存储，可能导致硬件错误，性能下降，甚至系统崩溃。

访问效率： 内存对齐可以提高数据访问的效率。在大多数计算机体系结构中，访问对齐数据的速度要比访问不对齐数据的速度快，因为硬件可以更高效地读取对齐的数据。

缓存行优化： 内存对齐有助于缓存的有效使用。现代计算机中通常存在多级缓存，缓存以缓存行为单位进行读取。如果数据在同一个缓存行内，读取一个对齐的数据可能会同时读取其他相关数据，从而提高访问速度。

跨平台兼容性： 一些平台或编译器可能对内存对齐有不同的要求。通过进行内存对齐，可以提高代码在不同平台上的兼容性。


> 重载和重写区别

重载（Overloading）：
重载指的是在同一个作用域内，使用相同的函数名，但是参数列表不同的多个函数。重载函数可以具有不同的参数类型、个数或者参数顺序。编译器根据调用时传递的参数类型来决定调用哪个重载函数。

重写（Overriding）：
重写指的是在派生类中重新定义基类中已有的虚函数，以实现多态的特性。当一个派生类重写一个虚函数时，它提供了自己的实现，而不是继承基类的实现。重写函数的函数签名必须和基类中的虚函数一致，包括函数名、参数列表和返回类型。

以下是重载和重写的主要区别：

概念不同： 重载是在同一作用域内使用相同函数名但不同参数列表定义多个函数，而重写是在派生类中重新定义基类的虚函数。

基类和派生类： 重载可以在同一类中定义，也可以在不同的类中定义，但是重写只发生在派生类中。

函数签名： 重载函数的函数签名必须不同，即参数类型、个数或者顺序至少有一个不同。重写函数的函数签名必须与基类中的虚函数相同。

多态： 重载不涉及多态，而重写是多态的基础，通过调用基类指针或引用时，实际调用的是派生类中重写的函数。

静态绑定 vs 动态绑定： 重载在编译时确定调用哪个函数，属于静态绑定；重写在运行时根据实际对象的类型确定调用哪个函数，属于动态绑定。

总的来说，重载用于定义同名但不同参数的函数，而重写用于在派生类中重新定义基类的虚函数，实现多态性。

> C++内存分配方式有哪几个区、堆区和栈区使用场景

栈区（Stack）：

- 存放函数的局部变量和参数。
- 使用栈结构，后进先出。
- 自动分配和释放，函数结束时自动回收。
- 空间有限，分配速度快，不易产生碎片。
- 适合存放相对小的、生命周期短的变量。

堆区（Heap）：

- 用于存放动态分配的内存，如通过 new 和 malloc 分配的内存。
- 不同于栈，需要手动释放（使用 delete 或 free）。
- 空间较大，分配速度较慢，可能会产生碎片。
- 适合存放对象的生命周期较长，大小不确定的数据

全局/静态区（Global/Static）：

- 存放全局变量、静态变量和静态成员变量。
- 生命周期与程序运行周期一致。
- 全局变量存放在全局数据区，静态变量存放在静态数据区。

常量区（Constant）：

- 存放字符串常量、const 常量等。
- 生命周期与程序运行周期一致，不允许修改。

代码区（Code）：

- 存放程序的可执行代码。
- 通常是只读的，不允许修改。

使用场景：

- 栈区适合存放函数局部变量和参数，生命周期短暂、大小可知的数据。
- 堆区适合存放动态分配的、生命周期较长、大小不确定的数据，如动态创建的对象。
- 全局/静态区适合存放全局变量、静态变量和静态成员变量，这些数据在整个程序生命周期内有效。
- 常量区存放不会被修改的常量数据。
- 代码区存放程序的可执行代码。

> new和malloc区别

> delete完后怎么避免野指针（置空，智能指针）

> C++11 auto关键字

auto 关键字是 C++11 引入的一项特性，用于自动推导变量的类型。它的原理是编译器在编译时根据变量初始化的表达式来推断变量的实际类型。换句话说，编译器会根据初始化的值来确定变量的数据类型，从而避免了显式指定变量类型的繁琐。

当使用 auto 声明变量时，编译器会在初始化表达式的基础上进行类型推导。以下是 auto 关键字的一些工作原理：

类型推导规则： 编译器会根据初始化表达式的类型来确定变量的类型。如果初始化表达式是一个整数，那么推导的变量类型就是整数。如果是一个类对象，那么推导的变量类型就是该类的类型。

引用和顶层 const： 在类型推导时，编译器会保留引用和顶层 const，但会忽略底层 const。例如，对于 const int x = 42;，使用 auto 推导出的类型仍然是 const int。

表达式中的类型： 如果初始化表达式中含有多个不同类型的子表达式，编译器会根据一组规则来推导一个合适的共同类型。

函数返回类型： 当使用 auto 推导函数的返回类型时，编译器会考虑函数返回值的类型来确定函数的返回类型。

auto 只适用于编译时已知的信息，对于在运行时才能确定的类型，是无法使用 auto 进行类型推导的。

> vector push_back和emplace_back的区别

push_back 接受一个已构造的对象作为参数，并将其拷贝（通过拷贝构造函数）到容器的末尾。
当你有一个已经构造的对象，希望将其拷贝到容器中时，可以使用 push_back。

emplace_back 接受构造元素所需的参数，并在容器的末尾直接构造对象（通过移动构造函数或参数构造函数）。
emplace_back 可以避免额外的拷贝操作，因为它直接在容器内部进行构造。

当你希望在容器中构造新的对象，而不是在外部构造后再拷贝到容器中时，可以使用 emplace_back。


> 迭代器使用注意事项，迭代器失效（使用迭代器循环，安全删除vector中满足条件的元素怎么写）

注意事项：

1. 范围限制： 迭代器只能在其有效范围内使用，不要在超出容器范围的迭代器上执行操作。避免访问越界或非法的内存。

2. 迭代器类型： 使用正确类型的迭代器，例如 begin() 返回的迭代器应该与容器类型相匹配。

3. 容器可能修改： 在使用迭代器的同时，要注意容器可能会被其他操作修改，可能会影响迭代器的有效性。

4. 递增和递减： 在使用迭代器时，要正确使用递增和递减操作，避免超越容器的边界。

5. 算法库： 尽可能使用标准库的算法而不是手动操作迭代器，因为算法库提供了对迭代器的安全封装。

迭代器失效：

1. 插入和删除操作： 在容器插入或删除元素后，原来的迭代器可能会失效。因为这些操作可能导致内存重新分配，使之前的迭代器指向无效的内存。

2. vector 和 string 的内存重新分配： 在向 std::vector 或 std::string 中插入元素时，当容量不足时会发生内存重新分配，导致已有迭代器失效。

3. deque 的中间插入和删除： 在 std::deque 中间插入或删除元素时，会导致迭代器失效，因为 deque 通常由多个缓冲区组成。

4. map 和 set 的插入操作： 在 std::map 和 std::set 中插入元素时，不会使迭代器失效，因为它们使用红黑树作为底层数据结构。

5. unordered_map 和 unordered_set： 在 std::unordered_map 和 std::unordered_set 中插入元素时，可能会导致哈希表的重新哈希，使得迭代器失效。

```c++
// 删除所有元素
for (auto it = numbers.begin(); it != numbers.end();) {
    it = numbers.erase(it);  // 删除元素，erase() 返回指向下一个元素的迭代器
}

// 也可以利用 std::remove_if, 会将不满足条件的元素移动到容器的前面，然后返回一个迭代器，指向移动后的范围的尾部
// 因此，下面的代码先将奇数移动到了前面然后返回指向第一个偶数的迭代器，随后erase删除该迭代器到end()迭代器之间的元素
numbers.erase(std::remove_if(numbers.begin(), numbers.end(), [](int num) {
  return num % 2 == 0; }), numbers.end());
```

> 如何做C++内存管理、内存泄漏解决和经验

1. 使用智能指针： 使用智能指针（如 std::shared_ptr、std::unique_ptr、std::weak_ptr）来管理动态分配的内存。智能指针可以自动管理资源的释放，减少内存泄漏的可能性。

2. RAII（资源获取即初始化）： 使用 RAII 原则，即在对象构造时获取资源，在析构时释放资源。这种方法可以确保资源的正确释放，即使发生异常也能正常处理。

3. 避免裸指针： 尽量避免使用裸指针管理内存，因为需要手动释放内存，容易出现忘记释放或释放多次的情况。

4. 使用容器： 使用标准库提供的容器，如 std::vector、std::map、std::set 等，它们能够自动管理内存，避免手动分配和释放内存。

5. 清理资源： 在不再需要资源的时候，手动释放内存、关闭文件句柄、释放数据库连接等，避免资源的长时间占用。

6. 内存泄漏检测工具： 使用工具如 Valgrind（在 Linux 环境中）、AddressSanitizer 等进行内存泄漏检测和分析。

7. 编写稳定的代码： 编写稳定的代码可以避免不正常的程序终止，从而确保析构函数被正确调用。

8. 注意循环引用： 在使用智能指针时，注意避免循环引用，它可能导致对象无法正确释放。

9. RAII 设计模式： 将资源的获取和释放封装在类的构造函数和析构函数中，使得对象的生命周期与资源管理紧密相关，从而提高内存管理的可靠性。

10. 内存池： 对于频繁分配和释放内存的场景，可以考虑实现内存池来管理内存，减少内存分配和释放的开销。

> 多进程与多线程的优缺点及适应场景

多进程：

优点：

1. 独立性高： 不同进程之间拥有独立的内存空间和系统资源，一个进程的崩溃不会影响其他进程。
2. 稳定性强： 进程之间互不影响，一个进程的问题通常不会导致整个程序的崩溃。
3. 适用于多核： 多进程天然适合于多核处理器，每个进程可以在不同核心上独立运行，充分利用硬件资源。
4. 安全性高： 进程之间的内存独立性保证了数据的安全性。

缺点：

1. 资源开销大： 创建和销毁进程的开销相对较大，每个进程都需要独立的内存空间和系统资源。
2. 通信复杂： 不同进程之间的通信需要使用特殊的机制，如进程间通信（IPC），这增加了编程的复杂性。
3. 启动时间长： 由于需要分配独立的资源，进程的启动时间通常比线程长。

适应场景：

1. 需要充分利用多核处理器的计算密集型任务。
2. 需要高度的隔离性，以防止一个任务影响其他任务。
3. 需要稳定性较高，不容易受到单个任务的影响。

多线程：

优点：

1. 轻量级： 线程相对于进程来说更轻量，创建和销毁线程的开销较小。
2. 共享内存： 线程之间可以共享相同的内存空间，因此数据交换相对容易。
3. 通信简单： 相比进程间通信，线程之间的通信更加直接简单，可以使用共享变量等方法。
4. 启动时间快： 由于共享资源，线程的启动时间通常比进程快。

缺点：

1. 不稳定性： 一个线程的崩溃可能导致整个进程崩溃，因为它们共享进程的内存空间。
2. 竞态条件： 多个线程同时访问共享资源时，可能会导致竞态条件和数据不一致问题。
3. 难以调试： 多线程程序中的 bug 可能更难以调试和复现。

适应场景：

1. 需要处理大量 I/O 操作的任务，如网络通信、文件操作等。
2. 需要提高程序的响应速度，比如 GUI 应用程序。
3. 需要在单个进程内实现多个相关的任务，以便共享数据和状态。

总之，选择多进程还是多线程取决于任务的性质和要求。对于计算密集型任务和需要隔离性的场景，多进程可能更合适；而对于 I/O 密集型任务和需要更高的响应速度的场景，多线程可能更适用。实际中，也可以将多进程和多线程结合起来，以充分利用不同的优势。


> 共享内存原理、在虚存空间位置

共享内存是一种进程间通信的机制，允许多个进程共享同一块物理内存区域，从而实现高效的数据交换和通信。共享内存通常用于需要频繁交换大量数据的情况，因为它避免了数据的复制和拷贝，提高了数据传输的效率。

共享内存的工作原理如下：

内核空间创建共享内存区域： 在内核空间中，通过系统调用（例如 shmget）创建一个共享内存区域。这个区域有一个唯一的标识符（共享内存标识符），其他进程可以通过这个标识符访问这块共享内存。

进程映射共享内存： 想要使用共享内存的进程需要将这块共享内存映射到自己的虚拟地址空间中。这样，每个进程都可以通过读写映射的内存来实现数据的交换。

共享内存区域的物理内存： 实际的共享内存区域在物理内存中只有一份，所有映射到不同进程的虚拟地址空间中的映射都指向同一块物理内存。

在虚拟内存空间中，共享内存通常被映射到每个进程的一块相同的虚拟地址范围中，以便进程能够访问相同的数据。具体映射的位置是由操作系统管理的，开发者不需要过多关注。

> extern的作用

为了能够正确的在C++代码中调用C语言的代码：在程序中加上 extern "C" 后，相当于告诉编译器这部分代码是C语言写的，因此要按照C语言进行编译，而不是C++。使用extern "C" 的情况

在C语言的头文件中，对其外部函数只能指定为 extern 类型，C语言中不支持extern "C"声明，在 .c 文件中包含了 extern "C" 时会出现编译语法错误。所以使用 extern "C" 必须全部都放在于cpp程序相关文件或其头文件中

1. C++ 调用 C 函数
```c++
//xx.h
extern int add(...)

//xx.c
int add(){
    
}

//xx.cpp
extern "C" {
    #include "xx.h"
}
```

1. C 调用 C++ 函数

```c++
//xx.h
extern "C"{
    int add();
}

//xx.cpp
int add(){    
}

//xx.c
extern int add();
```

> 普通模板函数定义在哪里，为什么？普通模板函数定义在头文件里为什么链接器不报符号重定义？如果源文件a和b中都使用了模板函数，为什么不报重定义的错误

普通模板函数的定义和声明通常都放在头文件中。因为模板函数的定义需要在每个调用处进行实例化，而编译器需要能够看到模板函数的定义以生成相应的实例化代码。

将模板函数的定义放在头文件中可以确保在每个需要使用模板函数的地方都能够进行实例化。

编译器在每个源文件中都会根据需要对模板函数进行实例化，生成相应的函数定义。但是链接器会对这些不同源文件中生成的函数定义进行合并，以消除符号重定义，确保最终只有一个实际的函数定义。

需要注意的是，如果在模板函数的定义放在源文件（而不是头文件）中，并且这些源文件被多个源文件包含，可能会导致重定义错误。这是因为每个源文件中的模板函数定义是独立的，链接器无法自动合并不同源文件中的实例化。

> 无锁队列的实现原理

无锁队列是一种数据结构，用于实现多线程环境下的并发操作，而不需要使用传统的互斥锁来保护共享资源。无锁队列的设计目标是在高并发情况下提供高效的操作，并尽量避免线程间的竞争和阻塞。

实现无锁队列的关键是使用原子操作和一些特定的算法来确保多线程访问共享资源时的一致性和正确性。以下是一种常见的无锁队列实现原理，即基于 CAS（Compare-and-Swap）操作的 Michael-Scott 队列：

数据结构： 使用一个带有头节点和尾节点的链表作为基本数据结构。每个节点都包含一个值和一个指向下一个节点的指针。

入队操作： 对于入队操作，需要首先创建一个新节点，然后将新节点的指针指向队尾，并尝试通过 CAS 操作将队尾指针更新为新节点。如果 CAS 操作失败，说明其他线程已经插入了一个新节点，需要重试或采取其他策略。

出队操作： 对于出队操作，需要首先读取队头节点，然后将队头指针指向队头节点的下一个节点。在这个过程中，需要使用 CAS 操作来更新队头指针，以确保只有一个线程能够成功出队。

内存回收： 由于队列中的节点可能会被出队后变得无效，需要考虑内存回收的问题。一种常见的方法是使用延迟回收策略，即等到没有线程使用某个节点时再进行回收。

需要注意的是，无锁队列的实现比较复杂，涉及到原子操作的正确使用、ABA 问题的解决、内存回收等方面的考虑。虽然无锁队列可以在高并发环境下提供较好的性能，但其实现和调试也相对复杂，需要考虑多种情况和竞争条件。

> 函数调用过程中栈帧的变化过程

> 为什么系统调用比较消耗CPU

涉及到从用户态切换到内核态，这个切换过程会引起一些额外的开销，导致系统调用相对较为消耗CPU资源。以下是一些导致系统调用消耗CPU的主要因素:

1. 上下文切换： 在进行系统调用时，操作系统需要切换当前运行的进程或线程的上下文，从用户态切换到内核态。这涉及到保存用户态的寄存器状态、加载内核态的寄存器状态以及切换内核栈等操作，这些切换过程会引起一定的开销。

2. 模式切换： 用户程序在用户态执行，而系统调用需要在内核态执行。因此，从用户态切换到内核态涉及到特权级别的切换，这会导致CPU模式切换，增加了一定的开销。

3. 内存访问： 在内核态执行时，操作系统可能需要访问用户程序的内存空间以及内核自身的数据结构，这可能导致内存访问的开销，特别是如果涉及到缓存失效等情况。

4. 内核操作： 系统调用可能需要执行一些内核操作，如文件的打开、读写等。这些操作可能涉及到锁竞争、内核数据结构的访问等，从而增加了系统调用的开销。

5. 上下文保存与恢复： 在进行系统调用时，操作系统需要保存当前进程的上下文状态，以便在系统调用完成后能够正确地恢复到调用前的状态。这涉及到寄存器、程序计数器等信息的保存与恢复。


> malloc申请100B和申请100MB的区别，释放100MB呢

> 内存管理器tcmalloc

tcmalloc（Thread-Caching Malloc）是一个由Google开发的高性能内存分配器，专门用于多线程环境下的内存分配。它的设计目标是提供高效的内存分配和释放，以减少内存碎片和减轻多线程环境下的锁竞争，从而提高程序的性能。

以下是 tcmalloc 的一些主要特点和设计原理：

1. 线程本地缓存： tcmalloc 使用线程本地缓存（Thread-Caching）的方式，每个线程都有一个私有的内存缓存池，用于快速分配和释放小块内存，减少锁竞争。

2. 中心缓存： 除了线程本地缓存外，tcmalloc 还维护了一个中心缓存（Central-Caching），用于存储大块内存。当线程需要分配较大内存时，可以从中心缓存中获取。

3. 内存分配策略： tcmalloc 使用分级的内存分配策略，根据内存块的大小选择合适的缓存池。这有助于减少内存碎片，并提高内存分配的效率。

4. 空闲内存回收： tcmalloc 会定期回收线程本地缓存和中心缓存中的空闲内存，以便将内存重新回收到操作系统。

5. 定期释放： 为了避免内存过度集中在某一个线程上，tcmalloc 会周期性地重新分配一部分内存，以平衡不同线程的内存使用。

> 异步IO与同步IO的区别

同步IO模型要求用户代码自行将数据从内核区读入到用户区，或者从用户区写入到内核区，而异步IO是由内核完成IO操作，内核帮你完成数据在用户区和内核区之间的移动.

简单说就是同步IO向应用程序通知的是IO就绪事件，异步IO向应用程序通知的是IO完成事件

(以我们项目为例，我们用的同步IO来实现Reactor模型，所以主线程检测到客户端有数据到达时，它把任务加入到工作队列，某个空闲的子线程从队列中取这个任务，它需要先自己读数据，然后再去做业务逻辑)。

> 编译动态库的命令？C++动态库需要提高给第三方，头文件中需要注意什么？

```c++
g++ -c -fPIC mylib.cpp -o mylib.o
g++ -shared -o libmylib.so mylib.o

需要注意：避免全局命名污染避免全局命名污染，类和函数的声明，多平台支持
```


> 函数入参出参使用char * 和string的区别及优缺点

- char*

优点：

1. 直接传递字符串的指针，节省内存开销，特别是对于大量字符串操作。
2. 可以与C语言兼容。

缺点：

1. 容易出现内存安全问题，需要确保传入的指针有效，并且需要自行处理内存分配和释放。
2. 字符串长度需要额外传递或使用约定的终止字符（如 '\0'），可能会引发越界问题。
3. 不具备字符串的高级功能，如自动拷贝、动态分配和释放内存、字符串操作等。

- std::string：

优点：

1. 提供了高级的字符串操作方法，如自动拷贝、连接、截取、查找等。
2. 自动管理内存分配和释放，避免了内存泄漏和越界访问问题。
3. 安全性更高，不容易出现常见的内存错误。

缺点：

1. 相对于 char*，传递 std::string 对象会引入一定的内存开销。
2. 与C语言不太兼容，需要进行类型转换，不同编译器可能有不同实现。

根据具体情况，选择合适的方式：

使用 char* 主要适用于对内存占用要求较高的场景，以及需要与C语言库进行交互的情况。
使用 std::string 则更推荐，因为它提供了更多功能和更高的安全性，尤其在C++中使用更加方便。在多数情况下，使用 std::string 能够简化代码、减少错误，并提高代码的可维护性。


> 哈希表实现原理

哈希表是一种常用的数据结构，它可以快速地实现数据的插入、查找和删除操作，其核心思想是通过哈希函数将键映射到数组的索引位置，从而达到高效的数据操作

哈希表的实现原理可以总结为以下几个关键点：

1. **哈希函数：** 哈希函数是将键映射到哈希表数组中的索引位置的关键。一个好的哈希函数应该将键均匀地分布在数组中，最大程度地减少冲突（多个键映射到同一个位置）的发生。常见的哈希函数包括除留余数法（将键除以一个素数），乘法散列法

2. **哈希冲突处理：** 由于哈希函数的映射可能会导致多个键映射到同一个索引位置，这就产生了哈希冲突。常见的处理方法包括：
   - **开放地址法（Open Addressing）：** 在冲突的位置继续探测下一个可用的位置，例如线性探测、二次探测等。
   - **链式地址法（Chaining）：** 在哈希表的每个位置维护一个链表，冲突的键会插入到对应位置的链表中。

3. **数组容量和负载因子：** 哈希表通常会预先分配一定大小的数组作为存储空间。负载因子是指哈希表中实际存储的键值对数量与数组容量之间的比率。合理的负载因子可以保持哈希表的性能良好，一般来说，负载因子过高会导致冲突增加，而负载因子过低则会浪费空间。

4. **动态扩容：** 当负载因子达到一定阈值时，哈希表会触发动态扩容，即重新分配更大的数组，并将已有的键值对重新插入到新的数组中。这样可以保持负载因子在合理范围内，避免过多的冲突。

> 什么是拷贝构造函数，什么是赋值构造函数？这两个是为了解决一个什么问题？拷贝构造函数和赋值构造函数时干什么用的，可以告诉我你都知道什么吗？

这两个概念解决了对象的复制和赋值问题，确保在对象操作中不会出现资源泄漏、内存错误等问题。通过正确实现拷贝构造函数和赋值构造函数，可以实现对象的深拷贝，避免共享资源造成的问题，同时也保证对象的行为一致性

它们解决了对象拷贝和赋值时可能出现的问题，确保对象在复制或赋值时能够正确地进行资源管理和行为

拷贝构造函数：拷贝构造函数是一个特殊的构造函数，它用于创建一个对象的副本，其参数是同类型的另一个对象的引用。在对象创建时，如果提供了另一个同类型的对象作为参数，编译器会自动调用拷贝构造函数来创建新对象。拷贝构造函数通常用于对象传递、返回值返回等情况，确保不同对象间的独立性。

赋值构造函数：赋值构造函数是一个特殊的成员函数，用于将一个对象的值赋给另一个对象，以实现对象之间的赋值操作。赋值构造函数被调用时，已经存在的对象会被赋予新的值。它通常用于对象赋值，如将一个对象的值赋给另一个已经存在的对象。

需要注意的是，C++11 引入了移动构造函数和移动赋值运算符，用于在对象间进行资源转移，以提高性能。移动语义在处理临时对象时能够减少不必要的拷贝开销，提高效率。

> 什么是纯虚函数，纯虚函数是如何实现的？虚函数和纯虚函数的区别

纯虚函数是在基类中声明的虚函数 (= 0)，但没有提供实际的函数定义。它的目的是要求派生类必须实现这个函数，从而达到强制派生类实现某种行为的目的。

纯虚函数实际上是一个特殊的虚函数，它没有提供实际的实现，只是定义了接口。派生类如果不重写纯虚函数，则派生类也会变成抽象类。

虚函数和纯虚函数的区别在于：

1. 实现方式： 虚函数有默认的实现，可以在基类中提供实现，而纯虚函数没有实际的函数体，只是声明接口。

2. 强制实现： 派生类如果继承了一个含有纯虚函数的基类，必须实现这个纯虚函数，否则它自己也会成为抽象类，无法实例化。

3. 实例化： 基类中含有纯虚函数的类是抽象类，不能被实例化。而含有虚函数的基类可以被实例化，但它们的虚函数可能被派生类重写。


> RAII指？在C++11中有什么用了RAII

RAII 指的是 "Resource Acquisition Is Initialization"，即资源获取即初始化。它是一种C++编程范式，通过在对象的构造函数中获取资源，在析构函数中释放资源，从而实现资源的自动管理。

RAII 的核心思想是将资源的生命周期与对象的生命周期绑定在一起，确保资源在不再需要时会被正确释放，从而避免资源泄漏和错误。

在 C++11 中，引入了一些新特性来加强和扩展 RAII 的应用：

1. **智能指针：** 它们可以管理动态分配的内存和其他资源。这些智能指针利用 RAII 的原理，在对象的析构函数中自动释放资源，从而避免了内存泄漏和资源泄漏。

2. **移动语义：** C++11 引入了移动构造函数和移动赋值运算符，使得资源可以在对象之间高效地移动，而不是进行深拷贝。这对于管理资源更加高效，例如在容器中存储智能指针等情况下，能够减少资源的复制开销。

3. **Lambda 表达式：** C++11 中引入了 Lambda 表达式，使得资源管理更加方便。可以在需要时，将资源的释放操作通过 Lambda 表达式传递给 RAII 对象的构造函数，从而在对象的生命周期结束时执行资源释放。

总之，RAII 是一种重要的编程理念，它通过将资源的管理与对象的生命周期关联起来，能够在 C++11 中通过智能指针、移动语义和 Lambda 表达式等特性更加灵活地实现资源的自动管理，避免资源泄漏和错误，提高代码的可维护性和健壮性。


> C代码中引用C++代码有时候会报错为什么？

在C代码中引用C++代码时，可能会出现以下几种情况导致报错：

1. **编译器不同**: C++和C编译器可能存在一些差异，特别是在处理C++特有的特性时。因此，C代码中可能无法直接引用C++代码，而需要进行一些适当的处理

2. **命名空间问题**: C++代码通常会使用命名空间来组织代码，而C代码并不支持命名空间。如果C++代码中使用了命名空间，而C代码没有正确处理命名空间，就会导致编译错误

3. **C++特有的语法和特性**: C++引入了一些新的语法和特性，例如类、模板、重载等。这些特性在C代码中是无法识别和处理的，因此在引用C++代码时可能会报错

4. **编译方式不同**: C和C++有不同的编译方式和编译选项。如果在将C++代码链接到C代码时，编译选项不匹配，也会导致错误。

- 提供C接口: 在C++代码中定义C接口函数，这些函数使用C语言的编译方式，然后在C代码中调用这些C接口函数。

- 使用纯C接口: 如果要在C代码中调用C++代码，最好将C++代码封装成纯C接口，提供一组C函数供C代码调用，避免C++特有的特性和语法问题。

需要根据具体情况来选择合适的方法，以确保C代码能够正确地引用C++代码而不出现错误。


> 函数指针和指针函数 (分别用于描述指向函数的指针和返回指针的函数)

> C++string字符串怎么拷贝到一个char的buf里面（string 和 char之间的相互转换？）

```c++
// 使用strcpy函数，需要确保目标缓冲区足够大以容纳字符串，避免缓冲区溢出
int main() {
    std::string str = "Hello, world!";
    char buffer[50];
    strcpy(buffer, str.c_str()); // 将string拷贝到char数组中
    std::cout << "Buffer: " << buffer << std::endl;
    return 0;
}

// 使用std::copy函数，需要确保在缓冲区末尾添加一个终止字符\0，以标识字符串的结束
int main() {
    std::string str = "Hello, world!";
    char buffer[50];
    std::copy(str.begin(), str.end(), buffer); // 将string拷贝到char数组中
    buffer[str.size()] = '\0'; // 添加终止字符
    std::cout << "Buffer: " << buffer << std::endl;
    return 0;
}
```

> 32位系统下int,float,long 占多少字节?

```c++
在32位系统和64位系统下只有指针类型和长整型 (long 和 unsigned long)字节数有所差别，其余全部相同
32位    指针   ：4个字节    long    ：4个字节
64位    指针   ：8个字节    long    ：4 / 8个字节
```
> STL使用过那些容器，说说各自查询时间复杂度

```c++
1. **vector：** 动态数组，下标查询时间复杂度为O(1)，元素查询为O(n)。

2. **list：** 双向链表，查询时间复杂度为O(n)。

3. **deque：** 双端队列，同vector

4. **set 和 multiset：** 基于红黑树的有序集合，查询时间复杂度为O(log n)。

5. **map 和 multimap：** 基于红黑树的有序映射，查询时间复杂度为O(log n)。

6. **unordered_set 和 unordered_multiset：** 基于哈希表的无序集合，查询时间复杂度平均为O(1)，但最坏情况下可能为O(n)。

7. **unordered_map 和 unordered_multimap：** 基于哈希表的无序映射，查询时间复杂度平均为O(1)，但最坏情况下可能为O(n)。

8. **stack：** 栈，查询时间复杂度为O(n)。

9. **queue：** 队列，查询时间复杂度为O(n)。

10. **priority_queue：** 优先队列，查询时间复杂度为O(1)（常数时间），但在最坏情况下可能为O(log n)。
```

> C++新特性 tuple和vector区别

1. **存储不同类型的数据：**
   - `std::tuple`：`std::tuple` 是一个用于存储不同类型元素的数据结构，类似于一个固定大小的不可变数组。元素可以是不同的类型，如整数、浮点数、字符串等。
   - `std::vector`：`std::vector` 是一个动态数组，用于存储相同类型的元素。它可以在运行时动态增长或缩小，并且所有元素的类型必须相同。

2. **元素数量：**
   - `std::tuple`：`std::tuple` 中的元素数量是固定的，并且在创建后不能改变。
   - `std::vector`：`std::vector` 中的元素数量可以根据需要动态增加或减少。

3. **访问元素：**
   - `std::tuple`：可以通过 `std::get` 函数来访问元素。
   - `std::vector`：元素可以通过索引来访问。

4. **性能和内存开销：**
   - `std::tuple`：由于元素类型可以不同，因此 `std::tuple` 在一些情况下可能会引入更多的开销，如内存占用和访问速度较慢。
   - `std::vector`：由于元素类型相同，`std::vector` 在某些情况下可能更为紧凑且访问更快。

5. **用途：**
   - `std::tuple`：通常用于存储不同类型的元素，例如作为函数的多返回值，或者在元组中存储多种类型的配置项等。
   - `std::vector`：通常用于存储相同类型的元素，并且可以方便地进行动态增加、删除等操作。

需要根据实际需求来选择使用哪种数据结构，考虑到元素的类型、数量、性能要求等因素。
```c++
int main() {
    // 创建一个包含不同类型元素的 tuple
    std::tuple<int, double, std::string> myTuple(10, 3.14, "Hello");

    // 访问 tuple 中的元素
    int intValue = std::get<0>(myTuple);
    double doubleValue = std::get<1>(myTuple);

    // 打印元素值
    std::cout << "int value: " << intValue << std::endl;

    // 修改元素值
    std::get<0>(myTuple) = 20;

    // 创建一个 tuple 并进行结构化绑定
    auto anotherTuple = std::make_tuple("C++", 2023);
    std::string language;
    int year;
    std::tie(language, year) = anotherTuple;

    // 打印结构化绑定的值
    std::cout << "Language: " << language << std::endl;
    std::cout << "Year: " << year << std::endl;

    return 0;
}
```

> [进程分配内存的两种方式——brk()和mmap()](https://zhuanlan.zhihu.com/p/311527161)

> 动态链接的原理是什么?

动态链接是一种将程序的可执行文件与其依赖的库（如共享库或动态链接库）解耦的机制。其原理涉及以下几个关键概念：

1. **共享库（Shared Library）：** 共享库是包含一组可重用代码的二进制文件，它们可以被多个程序共享。这些库包含了函数和符号的定义，程序可以在运行时链接到这些库以使用其中的函数和数据。

2. **动态链接器（Dynamic Linker）：** 动态链接器是操作系统的一部分，负责在程序运行时加载和链接共享库。动态链接器查找程序所需的共享库，将它们加载到进程的地址空间中，并解析程序与库之间的符号引用。

3. **符号解析和重定位：** 当程序引用共享库中的函数或变量时，动态链接器需要解析这些符号引用，找到对应的符号在共享库中的地址。然后，它执行重定位，将符号引用的地址更新为正确的地址。

4. **延迟绑定（Lazy Binding）：** 动态链接器通常采用延迟绑定的策略。这意味着只有在程序首次执行到引用某个共享库的函数或变量时，才会执行符号解析和重定位。这有助于提高程序启动速度。

5. **PLT和GOT：** Procedure Linkage Table（PLT）和 Global Offset Table（GOT）是用于实现动态链接的数据结构。PLT包含一系列跳转指令，用于延迟绑定，而GOT包含了全局变量的地址。

怎么查看可执行程序依赖哪些动态库：`ldd`


> 析构函数里能不能抛异常?为什么？

在C++中，析构函数（Destructor）理论上是可以抛出异常的，但通常不建议在析构函数中抛出异常，因为这可能导致不可预测的行为和资源泄漏。以下是一些关于在析构函数中抛出异常的注意事项：

1. **资源泄漏：** 如果在析构函数中抛出异常，析构函数可能无法完成清理工作，导致资源泄漏，例如内存泄漏或文件句柄未关闭。这是因为当异常被抛出时，程序会跳转到异常处理代码，而不会继续执行析构函数中的清理操作。

2. **无法捕获异常：** 如果在析构函数中抛出异常，通常很难捕获并处理该异常，因为大多数情况下析构函数是由C++运行时系统自动调用的，而不是由程序员显式调用。因此，程序员可能无法有效地捕获析构函数中的异常。

3. **不稳定性：** 抛出异常会引入不稳定性，可能导致程序无法预测的行为。在析构函数中抛出异常会破坏了对异常的处理机制，使程序变得不可靠。

虽然在一些特殊情况下，你可能需要在析构函数中抛出异常，但通常的做法是在析构函数中避免抛出异常，确保它可以正常完成资源的释放和清理工作。如果有必要，在析构函数中使用异常安全的编程技巧，例如RAII（Resource Acquisition Is Initialization）模式，以确保资源的安全释放。最好将析构函数保持简单，可预测，避免引入不必要的复杂性和风险。

> 拷贝构造函数形参不是引用的话会发生什么？

如果拷贝构造函数的形参不是引用（即按值传递），那么会触发拷贝构造函数的调用，从而可能导致无限递归和栈溢出。

> STL 萃取器

STL（标准模板库）中的"萃取器"通常是指"类型萃取器"，用于从模板参数中提取类型信息，以便在模板编程中进行类型相关的操作。类型萃取器通常通过元编程技术（即在编译时进行的编程）来获取类型信息，从而允许模板在不同类型上进行通用操作。

在STL中，有两种主要的类型萃取器：

1. **`std::iterator_traits`：** 这是一个类型萃取器，用于从迭代器类型中提取有关迭代器的信息，例如其指向的数据类型。这对于泛型算法和容器非常有用，因为它允许算法知道如何处理不同类型的迭代器。

2. **`std::remove_reference`、`std::remove_pointer`等类型变换元函数：** 这些元函数用于从给定类型中去掉引用、指针等，从而获得原始类型。这在元编程中用于进行类型变换和类型推断。

```cpp
#include <iostream>
#include <iterator>
#include <type_traits>

int main() {
    // 使用 iterator_traits 萃取迭代器的值类型
    typedef std::iterator_traits<int*>::value_type ValueType;
    static_assert(std::is_same<ValueType, int>::value, "Value type must be int");

    // 使用 remove_reference 萃取类型并去掉引用
    typedef std::remove_reference<int&>::type NoRefType;
    static_assert(std::is_same<NoRefType, int>::value, "No reference type must be int");

    return 0;
}
```

在C++标准库中，有一个类型特征（type trait）叫做 `std::is_trivial`，用于判断一个类型是否是“平凡的”（trivial）。在C++中，“平凡的”类型通常指的是具有平凡的默认构造函数、拷贝构造函数、拷贝赋值运算符和析构函数的类型。平凡类型通常是POD（Plain Old Data）类型的一种。

你可以使用 `std::is_trivial` 类型特征来检查一个类型是否是平凡的。以下是一个示例：

```cpp
#include <iostream>
#include <type_traits>

struct MyType {
    int x;
    float y;
};

int main() {
    bool isTrivial = std::is_trivial<MyType>::value;

    if (isTrivial) {
        std::cout << "MyType is a trivial type." << std::endl;
    } else {
        std::cout << "MyType is not a trivial type." << std::endl;
    }

    return 0;
}
```

在上面的示例中，`std::is_trivial<MyType>::value` 将返回 `true`，因为 `MyType` 是一个平凡类型。

请注意，C++标准库中还有其他类型特征，用于检查类型的各种特征，例如 `std::is_pod` 用于检查是否是POD类型， `std::is_standard_layout` 用于检查是否是标准布局类型等。这些特征可用于进行元编程和编写通用模板代码。

> STL 里的set算法都有哪些

`find`, `insert`, `erase`, `lower_bound`, `upper_bound`, `equal_range`, `count`

### 计网

> http1.0和2.0的区别？http和https协议的区别？https怎么进行加密认证？http是在哪一层工作的

> OSI七层模型每层的职责 路由器工作在哪一层

1. **物理层（Physical Layer）** 这是最底层，负责定义物理媒体的特性，如电压、电流、传输速率等。物理层的主要任务是**实现比特流的传输，不涉及数据包的解析**
2. **数据链路层（Data Link Layer）：** 数据链路层**负责将比特流分组成帧，并管理帧的传输。它还提供了一些错误检测和纠正功能**，以确保数据在物理媒体上可靠传输。在局域网中，以太网协议是数据链路层的常见示例。
3. **网络层（Network Layer）：** 网络层的主要职责是**路由和转发数据包**。它负责确定数据包的最佳路径，以便在源和目标之间进行通信。路由器通常工作在网络层，因为它们是网络的关键组件，用于连接不同的子网。
4. **传输层（Transport Layer）：** 传输层负责**端到端的通信**，提供可靠的数据传输和错误检测。常见的传输层协议包括TCP（传输控制协议）和UDP（用户数据报协议）。
5. **会话层（Session Layer）：** 会话层**管理会话或连接**，确保数据的正确流动。它处理会话的建立、维护和终止，以及数据的同步和检查点。
6. **表示层（Presentation Layer）：** 表示层负责**数据的编码、压缩和加密**，以确保数据在不同系统之间的兼容性和安全性。它还处理数据格式的转换，如将数据从ASCII编码转换为EBCDIC编码。
7. **应用层（Application Layer）：** 应用层包含**应用程序和用户接口**，负责处理特定于应用程序的通信，如电子邮件、Web浏览器、文件传输等。应用层协议如HTTP、SMTP和FTP位于这一层。

> 在浏览器输入一个URL后，解释这个过程发生了什么？涉及到了哪些层？

1. **应用层（Application Layer）：** 这是整个过程的起点。在应用层，浏览器使用 HTTP 或 HTTPS 协议与目标服务器通信。HTTP（超文本传输协议）用于传输Web页面，而HTTPS（HTTP安全）通过加密数据来提供安全性。
    - **协议：** HTTP、HTTPS
    - **任务：** 发送HTTP请求，接收HTTP响应，定义数据传输的语法和语义。
2. **传输层（Transport Layer）：** 浏览器使用传输层协议，通常是 TCP（传输控制协议），来建立与目标服务器的连接，并确保数据的可靠传输。
    - **协议：** TCP
    - **任务：** 建立连接，可靠的数据传输，错误检测和纠正，数据分段和重组。
3. **网络层（Network Layer）：** 网络层负责寻址和路由数据包，以确定数据包如何从源传输到目标。
    - **协议：** IP（Internet Protocol）
    - **任务：** 寻址，路由，跨网络传输。
4. **数据链路层（Data Link Layer）：** 数据链路层在物理媒体上传输数据帧，并提供了物理媒体的控制和管理。
    - **协议：** 以太网（Ethernet）通常用于有线连接，Wi-Fi协议用于无线连接。
    - **任务：** 数据帧封装，物理媒体访问，错误检测。
5. **物理层（Physical Layer）：** 这是最底层，定义了物理媒体的特性，如电压、电流和传输速率。
    - **协议：** 无特定协议，定义了物理连接的特性。
    - **任务：** 以比特流的形式在物理媒体上传输数据。

整体流程以及 HTML 的渲染和解析是否会被阻塞

1. **DNS解析：** 浏览器首先会进行DNS解析，将输入的URL转换为服务器的IP地址，以确定要访问的服务器。

2. **建立TCP连接：** 浏览器与服务器之间建立TCP连接，这是通过三次握手过程完成的。

3. **发送HTTP请求：** 浏览器向服务器发送HTTP请求，请求页面的HTML内容以及相关资源，如CSS、JavaScript、图像等。

4. **服务器响应：** 服务器接收到请求后，会返回相应的HTTP响应，其中包括HTML内容和资源的链接。

5. **HTML解析：** 浏览器开始解析HTML文档，构建文档对象模型（DOM）。

6. **资源预加载：** 当浏览器解析HTML时，如果遇到CSS文件的链接（通常在`<link>`标签中）或JavaScript文件的引用（通常在`<script>`标签中），它会开始下载这些资源。CSS文件通常不会阻塞HTML解析，但JavaScript文件会。

   - **CSS下载和解析：** CSS文件的下载是异步的，并且不会阻塞HTML解析。但是，CSS文件下载完成后，浏览器会阻塞HTML渲染，直到CSS文件解析完毕，以确保样式能够应用到HTML元素上。

   - **JavaScript下载和执行：** 默认情况下，JavaScript文件的下载和执行是同步的，它们会阻塞HTML解析和渲染。这是因为JavaScript可以修改DOM结构，所以浏览器希望在执行JavaScript之前完全构建DOM。

7. **HTML渲染：** 一旦HTML文档被解析，并且所有CSS文件被下载和解析完成，浏览器开始将页面渲染到屏幕上。这包括布局（计算元素的位置和大小）和绘制（将元素绘制到屏幕上）等过程。

8. **JavaScript执行：** 当浏览器遇到`<script>`标签时，它通常会停止HTML解析，下载并执行JavaScript。这可能会阻塞HTML渲染，特别是如果JavaScript代码是在文档末尾或DOM元素的底部引用的。为了减少阻塞，可以将JavaScript代码异步加载或延迟执行。

总结：
- CSS下载不会阻塞HTML解析，但会阻塞HTML渲染。
- 默认情况下，JavaScript下载和执行会阻塞HTML解析和渲染。可使用异步加载或延迟加载等技术来改善性能。


> TCP传输滑动窗口主要解决什么问题

1. 提升效率：解决传统的 “请求应答” 处理方式效率低下的问题（往返时间越长，通信的效率就越低），引入了窗口，窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值
2. 流量控制： 滑动窗口机制允许发送方和接收方之间协调数据的传输速率，以防止发送方发送速度过快，从而导致接收方无法处理所有的数据，造成数据丢失或缓冲区溢出。
3. 可靠性： 滑动窗口机制也用于确保数据的可靠传输。通过维护一个滑动窗口，发送方可以跟踪哪些数据已经被成功接收，哪些数据需要被重新发送。接收方可以通过确认已经接收到的数据来指示发送方继续发送未接收到的数据。这确保了数据在传输过程中不会丢失或乱序。

> 细说TCP, HTTP, DNS, ARP？tcp可靠传输？


1. **TCP（传输控制协议）：**
   - **用途：** TCP是一种面向连接的、可靠的协议，用于在计算机之间建立可靠的数据传输连接。它用于确保数据按顺序到达，没有丢失，没有重复，以及处理拥塞控制。
   - **工作原理：** TCP通过三次握手建立连接，确保双方都准备好进行通信。它使用序列号来跟踪数据包的顺序，并通过应答确认（ACK）来确认已接收的数据。如果数据包丢失或损坏，TCP会进行重传，确保数据的可靠性。TCP还具有流量控制机制，以避免过多的数据流入接收方。
2. **HTTP（超文本传输协议）：**
   - **用途：** HTTP是一种应用层协议，用于在Web浏览器和Web服务器之间传输超文本文档，通常用于网页的加载和浏览。HTTP也被用于传输其他类型的数据，如图像、音频和视频。
   - **工作原理：** 客户端（通常是浏览器）向服务器发送HTTP请求，服务器接收请求并返回HTTP响应。HTTP请求包括请求方法（GET、POST等）、请求头和可选的请求体，而HTTP响应包括状态码、响应头和响应体。HTTP通信是无状态的，每个请求和响应之间是相互独立的。
3. **DNS（域名系统）：**
   - **用途：** DNS是一种用于将人类可读的域名（例如www.example.com）映射到计算机网络中的IP地址的分布式命名系统。它使我们能够通过域名访问互联网资源，而无需记住复杂的IP地址。
   - **工作原理：** 当用户在浏览器中输入一个域名时，浏览器将向本地DNS解析器发出请求。本地DNS解析器会首先查看本地缓存中是否有域名对应的IP地址。如果没有，它将向根DNS服务器发出查询请求，然后逐级向下查找，直到找到域名对应的IP地址。一旦找到，IP地址将返回给浏览器，浏览器可以使用它来建立连接。
4. **ARP（地址解析协议）：**
   - **用途：** ARP是一种用于将IP地址映射到物理MAC地址的协议。它通常用于在局域网中查找目标设备的物理地址。
   - **工作原理：** 当一台计算机在局域网上需要与另一台计算机通信时，它首先查看本地ARP缓存，如果找到目标IP地址对应的MAC地址，则可以直接通信。如果没有找到，它将向局域网中的其他计算机发送ARP请求，询问目标IP地址的MAC地址。目标计算机将回复ARP响应，提供其MAC地址。一旦请求方知道了MAC地址，它可以直接与目标计算机通信，而无需进行广播。

ARP通常在局域网中用于解决以下问题：

1. 当一台计算机需要与另一台计算机通信时，它首先检查本地ARP缓存，看是否已知目标IP地址对应的MAC地址。如果缓存中有对应项，通信可以直接进行。
2. 如果本地ARP缓存中没有对应项，计算机将发送ARP请求广播，询问局域网中是否有其他计算机知道目标IP地址对应的MAC地址。目标计算机将会回复ARP响应，提供它的MAC地址。
3. 一旦发送方知道了目标MAC地址，它可以直接与目标计算机通信，而不必广播请求。 
因此，ARP通常用于解决局域网内部的设备通信问题。在互联网上，特别是当客户端与远程服务器通信时，ARP协议通常不涉及，因为通信跨越不同的网络，并且在互联网上的路由器等设备会处理目标IP地址到物理MAC地址的映射。ARP主要用于解决同一局域网内部的设备寻址问题。

> TCP 是如何保证可靠性的（校验和，确认应答，确认序号，重传机制，流量控制，拥塞控制连接管理（3+4）），tcp如何保证发送顺序？（确认序号）

> SSL/TLS握手过程？CA 电子签名怎么实现的？

> 服务器把自己的公钥注册到CA，CA用自己的私钥将服务器的公钥数字签名并颁发数字证书（服务器 + 公钥 + 数字签名 打包成一个数字证书）
  
> 一个请求从客户端发起到服务器接收的过程

**客户端输入URL** -> **DNS解析** -> **建立TCP连接** -> **发送HTTP请求** ->  **服务器处理请求** -> **服务器发送HTTP响应** -> **客户端接收响应** -> **渲染页面** -> **关闭连接** 

> get和post的区别？post传输密码也不加密吗？你知道哪些加密算法

- **用途：** GET请求用于从服务器请求数据，通常用于获取资源。它应该是幂等的。POST请求用于向服务器提交数据，通常用于提交表单数据或执行某些操作。它不一定是幂等的
- **数据传输：** GET请求的数据参数附在URL的查询字符串中，可见于URL中，因此不适合传输敏感信息。由于URL长度的限制，传输的数据量有限。POST请求的数据参数包含在请求体中，不可见于URL中，因此更适合传输敏感信息。由于请求体的存在，POST请求可以传输更多数据，没有URL长度限制。
- **缓存：** GET请求可以被浏览器缓存，可以被书签保存，并且可以被历史记录保存。POST请求通常不会被浏览器缓存，也不会被保存在书签或历史记录中。
HTTP本身不提供加密机制，明文传输。为了加密敏感信息的传输，通常会使用HTTPS，HTTPS使用SSL/TLS协议来加密HTTP通信，确保数据在传输过程中的机密性和完整性。

- **对称加密算法** 使用相同的密钥来加密和解密数据。AES（高级加密标准）是目前最常用的对称加密算法之一。
- **非对称加密算法** 使用一对公钥和私钥，公钥用于加密数据，私钥用于解密数据。RSA和ECC是常见的非对称加密算法。
- **哈希算法** 用于生成固定长度的哈希值，通常用于验证数据的完整性。SHA-256是一种常用的哈希算法。

> 对称加密和非对称加密的区别？

**对称加密（Symmetric Encryption）：**

1. **密钥：** 对称加密使用相同的密钥来加密和解密数据。这意味着发送方和接收方都必须共享相同的密钥。
2. **加密速度：** 对称加密通常比非对称加密快速，因为加密和解密使用相同的密钥，算法相对简单。
3. **优点：**
    - 高效：对称加密速度快，适用于大数据流加密。
    - 简单：算法相对简单，实现容易。
4. **缺点：**
    - 密钥分发：密钥的安全分发是一个挑战，特别是在网络上。
    - 缺乏身份验证：对称加密不能提供通信方身份验证的机制，可能容易受到中间人攻击。

**非对称加密（Asymmetric Encryption）：**
1. **密钥：** 非对称加密使用一对密钥，即公钥和私钥。公钥用于加密数据，私钥用于解密数据。
2. **加密速度：** 非对称加密通常比对称加密慢，因为使用不同的密钥进行加密和解密，算法复杂。
3. **优点：**
    - 密钥分发：公钥可以自由分发，而私钥需要保密。这样，不需要在通信前共享密钥。
    - 身份验证：非对称加密可以用于数字签名和身份验证，确保通信方的身份。
4. **缺点：**
    - 速度：相对较慢，不适用于大数据流加密。
    - 复杂性：算法相对复杂，实现相对困难。

通常情况下，对称加密用于加密大量数据，而非对称加密用于密钥交换和身份验证。一种常见的做法是使用非对称加密来安全地交换对称加密的密钥，然后使用对称加密来保护实际的通信数据。这种结合使用对称和非对称加密的方法称为混合加密。这样，可以兼顾非对称加密的密钥分发和身份验证优势，同时又能够保持对称加密的高效性。

> 文件下载，如果响应时间太慢，客户等待太久，怎么解决。

当文件下载的响应时间较慢，导致客户等待时间过长时，可以考虑以下几种解决方法：

1. **分块传输：** 支持HTTP分块传输（HTTP Chunked Transfer Encoding），允许服务器在生成文件响应时，分成小块逐个发送给客户端。这样，客户端可以逐块接收文件，而不需要等待整个文件下载完成。这在大文件的情况下特别有用。

2. **使用压缩：** 在服务器和客户端之间启用文件压缩，以减小文件大小，从而加速下载。通常，可以使用gzip或Brotli等压缩算法。

3. **使用多线程或并行下载：** 允许客户端使用多个并行的连接来下载文件，以提高下载速度。

4. **减小文件大小：** 如果可能的话，减小文件的大小，例如通过减少文件的分辨率或质量，以改善下载速度。

5. **使用断点续传：** 支持断点续传功能，允许客户端在下载中断后恢复下载，而不需要重新下载整个文件。

6.  **监控和优化网络带宽：** 定期监控网络带宽和流量，确保服务器具有足够的带宽来满足客户端的需求。

> TCP 有几个定时器

- 重传计时器：超时重传
- 延迟定时器(Delayed ACK)：ACK延滞算法思想是：TCP在接收到数据后并不立即发送ACK，而是等待一小段时间（典型值为50-200ms，即延迟定时器），然后才发送ACK。
- 坚持计时器：为对付零窗口通知而设立的，发送探测报文段。探测报文段有序号，但序号永远不需要确认
- 保活计时器：TCP 保活机制，每当服务器收到客户的信息，就将keeplive timer复位，超时通常设置2小时，发送探测报文
- FIN_WAIT2 定时器：避免对端一直不发送 FIN，进入 FIN_WAIT2 状态后启动该定时器，超时后关闭连接
- TIME_WAIT 计时器：2MSL

### 操作系统

> 进程线程协程

概念，拥有资源，调度开销，通信方式，隔离性（一个崩溃是否会影响其他的）

> 手撕生产者消费者 (为什么条件变量要用 while 包裹)

因为条件变量在某些情况下可能会经历虚假唤醒，使用while循环来包裹条件变量的等待部分是一种防御性的编程方式，可以在虚假唤醒发生时重新检查条件，确保条件满足后才继续执行。这样可以防止线程在条件未真正满足时错误地继续执行

```c++
// 锁+条件变量
#include <iostream>
#include <thread>
#include <vector>
#include <queue>
#include <mutex>
#include <condition_variable>

const int BUFFER_SIZE = 5;

std::queue<int> buffer;
std::mutex mtx;
std::condition_variable buffer_empty, buffer_full;

void producer(int id) {
    for (int i = 0; i < 10; ++i) {
        std::unique_lock<std::mutex> lock(mtx);

        // 如果缓冲区已满，等待消费者消费数据
        while (buffer.size() >= BUFFER_SIZE) {
            buffer_full.wait(lock);
        }

        int item = rand() % 100;
        buffer.push(item);
        std::cout << "Producer " << id << " produced: " << item << std::endl;

        // 通知消费者可以消费数据了
        buffer_empty.notify_all();
    }
}

void consumer(int id) {
    for (int i = 0; i < 10; ++i) {
        std::unique_lock<std::mutex> lock(mtx);

        // 如果缓冲区为空，等待生产者生产数据
        while (buffer.empty()) {
            buffer_empty.wait(lock);
        }

        int item = buffer.front();
        buffer.pop();
        std::cout << "Consumer " << id << " consumed: " << item << std::endl;

        // 通知生产者可以继续生产数据了
        buffer_full.notify_all();
    }
}

int main() {
    std::vector<std::thread> producers, consumers;
    for (int i = 0; i < 3; ++i) {
        producers.emplace_back(producer, i);
        consumers.emplace_back(consumer, i);
    }
    for (int i = 0; i < 3; ++i) {
        producers[i].join();
        consumers[i].join();
    }
    return 0;
}

// 信号量，注意 "semaphore.h"
#include <iostream>
#include <thread>
#include <vector>
#include <queue>
#include <mutex>
#include <condition_variable>
#include "semaphore.h"

const int BUFFER_SIZE = 5;

std::queue<int> buffer;
std::mutex mtx;
std::condition_variable buffer_empty, buffer_full;
sem_t empty_semaphore, full_semaphore;

void producer(int id) {
    for (int i = 0; i < 10; ++i) {
        int item = rand() % 100;
        
        sem_wait(&empty_semaphore); // 等待空位
        std::unique_lock<std::mutex> lock(mtx);

        buffer.push(item);
        std::cout << "Producer " << id << " produced: " << item << std::endl;
        
        lock.unlock();
        sem_post(&full_semaphore); // 通知缓冲区已满
    }
}

void consumer(int id) {
    for (int i = 0; i < 10; ++i) {
        sem_wait(&full_semaphore); // 等待数据
        std::unique_lock<std::mutex> lock(mtx);

        int item = buffer.front();
        buffer.pop();
        std::cout << "Consumer " << id << " consumed: " << item << std::endl;

        lock.unlock();
        sem_post(&empty_semaphore); // 通知缓冲区已空
    }
}

int main() {
    sem_init(&empty_semaphore, 0, BUFFER_SIZE); // 初始化空位信号量
    sem_init(&full_semaphore, 0, 0); // 初始化满位信号量
    std::vector<std::thread> producers, consumers;
    for (int i = 0; i < 3; ++i) {
        producers.emplace_back(producer, i);
        consumers.emplace_back(consumer, i);
    }
    for (int i = 0; i < 3; ++i) {
        producers[i].join();
        consumers[i].join();
    }
    sem_destroy(&empty_semaphore); // 销毁信号量
    sem_destroy(&full_semaphore);
    return 0;
}
```

> 概念：多个进程都链接同一个so动态库,代码段共享，数据段不共享!!

> 操作系统虚拟地址和物理地址区别

1. **定义**：
   - **虚拟地址（Virtual Address）：** 虚拟地址是由进程或程序看到的地址空间，它是在程序运行时由操作系统分配的。虚拟地址空间通常比物理地址空间大，允许操作系统使用虚拟内存技术将数据从磁盘加载到物理内存中，并管理多个进程的内存分配。
   - **物理地址（Physical Address）：** 物理地址是硬件内存中的实际地址，它对应着计算机内存芯片上的存储单元。
2. **访问权限**：
   - **虚拟地址：** 进程只能访问其分配的虚拟地址空间，无法直接访问其他进程的虚拟地址空间。
   - **物理地址：** 物理地址通常只能由操作系统内核访问，用户程序无法直接访问物理地址。
3. **映射关系**：
   - **虚拟地址到物理地址映射：** 操作系统负责将进程的虚拟地址映射到物理地址。这个映射关系是动态管理的，允许多个进程共享物理内存，并且允许操作系统灵活地分配和回收物理内存。
4. **虚拟内存**：
   - **虚拟地址支持虚拟内存：** 虚拟内存是一种技术，允许操作系统将数据从磁盘加载到物理内存中，从而扩展了可用的虚拟地址空间。这使得进程可以处理比物理内存更大的数据集。
   - **物理地址没有虚拟内存：** 物理地址直接映射到硬件内存，不支持虚拟内存技术。
5. **地址空间大小**：
   - **虚拟地址空间通常较大：** 虚拟地址空间的大小取决于操作系统和硬件的架构，通常比物理内存大得多。
   - **物理地址空间大小受限：** 物理地址空间的大小受到硬件限制，通常小于虚拟地址空间。

总的来说，虚拟地址提供了一种抽象层，使得操作系统可以更好地管理内存和进程之间的隔离，同时支持虚拟内存技术，而物理地址则表示实际的硬件内存位置。虚拟地址和物理地址之间的映射关系是操作系统的核心功能之一，它允许操作系统有效地管理内存资源和多任务处理。

> 进程同步机制有哪些

![](https://img-blog.csdnimg.cn/20201227102635850.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80OTM0MzE5MA==,size_16,color_FFFFFF,t_70)

- 信号量
- 管程: (管程是由一个或多个过程、一个初始化序列和局部数据组成的软件模块)
- 消息传递

进程互斥的软件实现方法：单标志法，双标志先检查，双标志后检查，Peterson算法（都有问题，不能满足空闲让进，忙则等待，有限等待或让权等待）

> linux查进程cpu和内存占用？如何查看文件的大小

top 指令，`shift+p` 按cpu排序，`shift+m` 按内存排序，`shift+t` 按启动时间排序,默认降序，`shift+r` 可以更改排序顺序
`ls -l` / `ll`, `stat` 文件名 都可以查看文件大小

> 线程池哪些参数？怎么优化？

线程数量, 任务队列大小, 任务执行超时时间;

> 进程开辟虚拟空间 有哪些段 都用什么用？

> ls指令如何实现

`stat()` 函数，格式化输出结果
1. 通过stat函数获取用户传入的文件的信息 `stat(argv[1], &st);`
2. 获取文件类型和文件权限 `switch(st.st_mode & S_IFMT) {}`
3. 判断文件的访问权限(所有者, 所有者, 其他人) `(st.st_mode & S_IRUSR) ? 'r' : '-';`
4. 硬连接数 `st.st_nlink`
5. 文件所有者 `getpwuid(st.st_uid)->pw_name;`
6. 文件所在组 `getgrgid(st.st_gid)->gr_name;`
7. 文件大小 `st.st_size;`
8. 获取修改的时间 `ctime(&st.st_mtime);`

> 深入讲一下 page cache？

Page Cache（页面缓存）是操作系统中用于加速文件系统性能的关键组成部分之一。它是一种内存中的缓存，用于存储磁盘上的文件数据的部分内容，以减少读写操作对物理磁盘的访问次数，从而提高磁盘I/O性能。

1. **工作原理：** Page Cache的工作原理是将最近读取的文件数据块（页）缓存到物理内存中。当应用程序请求读取文件时，操作系统首先检查Page Cache是否包含所需的数据。如果数据已经在Page Cache中，系统将直接从内存中提供数据，而不必从磁盘读取。这极大地提高了读取文件数据的速度。

2. **延迟写入（Lazy Write）：** Page Cache还实现了一种延迟写入策略。当应用程序对文件进行写入时，操作系统不会立即将数据写回磁盘，而是将数据标记为"脏页"，并在后台进行延迟写入操作。这可以降低写入操作的开销，提高系统的性能。

3. **文件系统层面：** Page Cache是文件系统的一部分，而不是独立的缓存系统。它由操作系统内核管理，与文件系统密切相关。不同的文件系统可能有不同的Page Cache实现方式。

4. **缓存替换策略：** Page Cache通常使用LRU（Least Recently Used）或其变种来确定哪些页应该保留在内存中，哪些应该被替换出去。这有助于优化内存的利用。

总之，Page Cache是一种强大的技术，可以显著提高文件系统性能，减少对物理磁盘的频繁访问。通过将磁盘上的数据部分缓存到内存中，Page Cache可以加速文件的读取操作，减少写入延迟，从而提高整个系统的效率。

> 进程调度算法
  
周转时间 = 完成时间 - 到达时间
带权周转时间 = 周转时间 / 运行时间
等待时间 = 周转时间 - 运行时间

> 操作系统中的原子操作是怎么实现的？

操作系统中的原子操作是通过硬件支持和操作系统提供的原子指令或原子操作库函数来实现的。原子操作是不可分割的操作，要么完全执行，要么完全不执行，不会被中断或并发执行。这对于实现并发和多线程编程非常重要，可以确保共享数据的一致性和避免竞态条件。

以下是原子操作实现的一些方式：

1. **硬件指令：** 许多现代处理器提供硬件支持的原子操作指令。这些指令通常包括原子加法、原子比较和交换（CAS）等。CAS指令允许将一个值与内存中的值进行比较，如果相等，则用新值替换旧值，所有这些操作是原子的。

2. **锁：** 操作系统和编程语言提供了各种锁机制，如互斥锁（Mutex）和自旋锁（Spinlock）。这些锁可以用来保护临界区域，确保只有一个线程能够访问共享资源。当一个线程持有锁时，其他线程会被阻塞或自旋等待，直到锁被释放。

3. **原子操作库函数：** 操作系统和编程语言通常提供原子操作的库函数，这些函数内部使用硬件原子指令或锁来实现原子性。例如，C++中的`std::atomic`和Java中的`java.util.concurrent.atomic`包提供了原子操作的抽象。

4. **事务内存（Transactional Memory）：** 一些现代处理器和编程语言支持事务内存，它允许程序员将一组操作包装在一个事务中，要么全部成功执行，要么全部失败。如果失败，系统会自动回滚事务，以确保原子性。

5. **特殊硬件支持：** 一些特殊硬件，如处理器中的多处理器支持或协处理器，可以用于执行原子操作。

原子操作在并发编程中非常重要，因为它们可以确保共享数据的一致性，避免数据竞争和并发问题。程序员可以根据需要选择适当的原子操作机制，以确保程序的正确性和性能。

> 共享内存是如何确定物理地址的？

共享内存是一种多个进程之间共享数据的机制，通常通过内存映射（Memory Mapping）来实现。在共享内存中，多个进程将同一块物理内存区域映射到它们各自的虚拟地址空间中，以便它们可以直接访问和共享这块内存。

物理地址的确定在共享内存中不由用户程序来管理，而是由操作系统负责。以下是共享内存中物理地址的确定过程：

1. **创建共享内存：** 在创建共享内存时，操作系统会分配一块物理内存区域来存储共享的数据。这块物理内存区域通常在内核地址空间中，不直接暴露给用户程序。

2. **内存映射：** 每个进程通过内存映射操作将共享内存区域映射到其自己的虚拟地址空间中。每个进程会获得一个虚拟地址，通过这个虚拟地址可以访问共享内存。

3. **虚拟地址到物理地址的转换：** 当进程访问共享内存时，操作系统会负责将进程的虚拟地址映射到物理地址。这个映射是通过页表和内存管理单元（MMU）来实现的。

   - 每个进程有自己的页表，将虚拟地址映射到物理地址。
   - 页表的一部分是用于共享内存的映射，这部分虚拟地址在不同进程中是相同的。
   - 操作系统确保不同进程访问相同虚拟地址时，最终映射到相同的物理地址，从而实现数据的共享。

4. **物理地址的保护：** 操作系统通过访问权限设置来确保不同进程对共享内存的访问是安全的。它可以控制读写权限，以防止进程非法访问共享内存。

总之，共享内存的物理地址由操作系统管理，用户程序只需关心虚拟地址。操作系统通过页表和MMU来确保不同进程之间共享内存的物理地址映射是正确的，并且实现了数据的共享和保护。这使得多个进程可以高效地共享数据，而不需要显式的数据传输。

### 数据库

> 讲一下mysql的mvcc，undolog包含哪些内容 ，幻读的概念，mvcc如何处理幻读和不可重复读

MVCC 是MySQL数据库管理系统中用于实现并发控制的一种技术。MVCC 允许多个事务同时访问数据库，每个事务看到的数据版本是一致的，同时也保持了事务的隔离性，以避免数据异常或冲突。以下是有关MySQL MVCC 的详细解释：

**MVCC 的核心概念：**

1. **版本号：** 在MVCC中，每个数据行都有一个版本号或时间戳，用于表示该数据行的状态。这个版本号是在数据行发生变化时自动更新的。
2. **快照事务：** 每个事务都有一个自己的时间戳，用于表示事务启动的时间。这个时间戳用于确定事务可以看到哪个数据版本。
3. **可见性规则：** MVCC 使用可见性规则来确定事务可以看到哪些数据版本。一般来说，事务只能看到早于或等于它自己时间戳的数据版本，这确保了事务之间的隔离性。

**MVCC 如何工作：**

在MVCC中，当一个事务开始时，它会获取一个快照事务时间戳，表示事务启动时的时间。然后，事务只能看到早于或等于这个时间戳的数据版本。以下是MVCC的一些关键步骤：

1. **读取操作：** 当一个事务执行读取操作时，它只能看到那些时间戳早于或等于事务自己的时间戳的数据版本。这确保了事务读取到一致的数据。
2. **写入操作：** 当一个事务执行写入操作时，它会生成一个新的数据版本，并且使用自己的时间戳作为新版本的时间戳。原始数据行的旧版本保留在数据库中，以便其他事务可以继续读取它。
3. **事务隔离性：** MVCC 遵循SQL标准中的隔离级别，如读未提交、读已提交、可重复读和串行化。不同的隔离级别决定了事务如何看待其他事务的数据修改。

**MVCC 的优点：**

1. **高并发性：** MVCC 允许多个事务同时访问数据库，提高了数据库的并发性能，避免了大部分锁竞争问题。
2. **读-写分离：** MVCC 在读取和写入操作之间提供了明显的分离，这使得读取操作不会被写入操作阻塞。
3. **数据一致性：** MVCC 确保了事务之间的数据一致性，每个事务看到的数据版本都是一致的，避免了脏读、不可重复读和幻读等问题。

尽管MVCC提供了很多优点，但它也需要更多的存储空间来维护不同版本的数据。此外，需要确保数据库引擎和事务管理器正确实现MVCC机制，以保持数据的一致性和隔离性。MySQL的InnoDB存储引擎就是一个使用MVCC实现事务隔离的例子。

在MySQL中，Undo Log（也称为回滚日志）是用于实现事务的持久性和回滚能力的关键组成部分。Undo Log 包含以下重要内容：

1. **事务ID（Transaction ID）：** Undo Log 记录了正在进行的事务的唯一标识符或事务ID。每个事务都有一个唯一的事务ID，用于跟踪和标识事务的起始和结束。
2. **回滚指针（Rollback Pointer）：** Undo Log 中包含了回滚指针，它指向了生成这个 Undo Log 记录的操作，通常是一个数据修改操作，如插入、更新或删除。回滚指针用于在回滚事务时撤销对数据的修改。
3. **旧值（Old Value）：** Undo Log 记录了被修改的数据的旧值。这是因为在回滚事务时，需要将数据恢复到事务之前的状态，因此需要记录旧值。
4. **新值（New Value）：** 如果事务是一个更新操作，Undo Log 也可能包含新值，以便在回滚时将数据恢复到更新之前的状态。
5. **页号和偏移量：** Undo Log 还包含了受影响数据的页号和偏移量信息。这些信息用于定位和恢复
6. 数据页上的修改。

Undo Log 的作用是在事务需要回滚或系统崩溃时，提供了一种恢复数据到一致状态的机制。当事务需要回滚时，数据库引擎使用 Undo Log 中的信息将数据还原到之前的状态，以确保数据库的一致性和可靠性。
MySQL InnoDB 引擎的**可重复读隔离级别**（默认隔离级），根据不同的查询方式，分别提出了**避免幻读的方案**：

- 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读。
- 针对当前读（select ... for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读。
  
**MySQL 可重复读隔离级别并没有彻底解决幻读，只是很大程度上避免了幻读现象的发生**

> mysql中有哪些索引，哈希索引和b+树索引各自的优缺点，为什么用b+树而不是b树（各自特点）？b+树的查询复杂度

> 聚簇索引和非聚簇索引是什么，主键索引是哪种索引，讲一下回表查询，讲一下覆盖索引

> 数据库的四大特征，索引的底层原理

索引的作用：加速数据检索；索引的底层数据结构：B+树、哈希索引等；维护成本；索引失效

> mysql有哪些存储引擎？MyISAM 和InnoDB的区别

两个常见的存储引擎是 MyISAM 和 InnoDB，还有 MEMORY (将数据存储在内存中)

- **1. 事务支持：**
  - MyISAM：不支持事务。这意味着在MyISAM表上不能执行像BEGIN、COMMIT和ROLLBACK这样的事务控制语句。
  - InnoDB：支持事务。InnoDB是MySQL的事务性存储引擎，它支持ACID（原子性、一致性、隔离性、持久性）属性，允许你执行事务控制操作。
- **2. 行级锁定：**
  - MyISAM：采用表级锁定。这意味着在执行写操作（如INSERT、UPDATE、DELETE）时，会锁定整个表，其他操作将被阻塞。
  - InnoDB：采用行级锁定。这允许多个事务同时访问同一表的不同行，从而提高了并发性能。
- **3. 外键支持：**
  - MyISAM：不支持外键约束。你可以在表上定义外键，但MySQL不会强制执行它们。
  - InnoDB：支持外键约束。你可以定义外键，并且InnoDB将强制执行外键约束，以维护数据的完整性。
- **4. 性能：**
  - MyISAM：在读密集型工作负载下表现较好，特别是对于查询操作。但在写密集型工作负载下可能性能下降，因为它使用表级锁定。
  - InnoDB：更适合多种工作负载，特别是在需要事务支持和数据完整性的应用程序中。由于使用行级锁定，它在并发写入方面表现较好。
- **5. 数据完整性：**
  - MyISAM：不支持数据完整性约束，例如外键和检查约束。
  - InnoDB：支持数据完整性约束，允许你定义外键、检查约束等来确保数据的一致性。
- **6. 崩溃恢复：**
  - MyISAM：在崩溃时恢复通常较快，因为它的表格结构相对简单。
  - InnoDB：在崩溃时恢复可能需要更长的时间，因为它具有更复杂的事务日志和数据结构。

综上所述，选择使用哪个存储引擎取决于你的应用程序需求。如果你需要事务支持、数据完整性和更好的并发性能，InnoDB通常是更好的选择。但如果你的应用程序主要是读取操作，而且对事务和数据完整性没有要求，那么MyISAM可能在某些情况下更适合。在某些情况下，也可以使用不同的存储引擎来适应不同的表。

> 数据库用的什么ORM？为什么用？有什么好处？

> 事务隔离级别及其实现？

> mvcc是什么？间隙锁？

> mysql里有哪些锁？悲观锁乐观锁？乐观锁怎么实现？使用乐观锁机制实现并发控制存在什么问题？如何解决

> mysql表在磁盘上是如何存储的？

> mysql增删查改都是那几个关键字？改变表结构关键字？

```sql
1. 增加（Insert）： 用于将新的数据行插入到表中。

INSERT INTO table_name (column1, column2, ...) 
VALUES (value1, value2, ...);

2. 删除（Delete）： 用于从表中删除数据行。

DELETE FROM table_name WHERE condition;

3. 查询（Select）： 用于从表中检索数据。

SELECT column1, column2, ... 
FROM table_name WHERE condition;

4. 更新（Update）： 用于修改表中的数据行。

UPDATE table_name 
SET column1 = value1, column2 = value2, ... 
WHERE condition;

关于改变表结构（如添加、修改或删除表的列），可以使用以下SQL关键字：

1. 创建表（Create Table）： 用于创建一个新的数据库表。

CREATE TABLE table_name 
(column1 datatype, 
column2 datatype, ...);

2. 修改表（Alter Table）： 用于修改现有的表结构，包括添加、修改和删除列等操作。

添加列：ALTER TABLE table_name ADD column_name datatype;
修改列：ALTER TABLE table_name MODIFY column_name new_datatype;
删除列：ALTER TABLE table_name DROP COLUMN column_name;

3. 删除表（Drop Table）： 用于删除整个表及其数据。

DROP TABLE table_name;
```

### Linux

> 对文件描述符fd的理解

> 查看打开文件的命令, 查看当前网络连接的命令, 查看当前进程的命令, 查看磁盘

> gdb打断点，查看堆栈情况什么命令？

```shell
1. **常用的Linux命令：**
   - `cd`: 切换目录。
   - `pwd`: 显示当前工作目录。
   - `cat`: 查看文件内容。
   - `grep`: 在文件中搜索指定的字符串。
   - `find`: 查找文件或目录。
   - `mv`: 移动或重命名文件。
   - `cp`: 复制文件或目录。
   - `rm`: 删除文件或目录。
   - `mkdir`: 创建目录。
   - `touch`: 创建空文件或更新文件的时间戳。
   - `vi` 或 `nano`: 文本编辑器。

2. **显示文件的第二行和最后一行：**
   - 若要显示文件的第二行，可以使用`head`命令：
     head -n 2 文件名

   - 若要显示文件的最后一行，可以使用`tail`命令：
     tail -n 1 文件名

3. **查找以.c结尾的文件：**
   - 使用`find`命令来查找以.c结尾的文件，例如在当前目录及其子目录中查找：
     find . -type f -name "*.c"
   - 这将列出所有以.c结尾的文件及其路径。

# 把文件中的 "apple" 替换成 "orange"
awk '{gsub("apple", "orange")} 1' filename.txt > newfile.txt

- gsub("apple", "orange")：这是 awk 的内置函数 gsub，用于全局替换字符串。它将 "apple" 替换为 "orange"
- {}：用来包裹 awk 的操作。
- 1：这是一个条件，它会打印每一行。在这种情况下，它打印了经过替换后的每一行。
```

> 查看内存的命令

```bash
# 1. free
free -h

               total        used        free      shared  buff/cache   available
内存：    4004768     1877856      140144       31792     1986768     1815552
交换：    3297276        1036     3296240

`free` 命令用于查看系统的内存使用情况，包括物理内存和交换空间（虚拟内存）的统计信息
`-h` 选项将内存使用信息以人类可读的方式显示（以 MB 或 GB 为单位）

# 2. top
`top` 命令是一个交互式的系统监视工具，它可以实时显示系统的性能统计信息，包括内存使用情况
在 `top` 命令界面中，你可以按下 `Shift` + `M` 键来按内存使用率排序进程

# 3. vmstat

procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b 交换 空闲 缓冲 缓存   si   so    bi    bo   in   cs us sy id wa st
 1  0   1036 131480 257852 1738188    0    0     2     2   39   14  0  0 100  0  0

`vmstat` 命令用于查看系统的虚拟内存统计信息，包括内存、交换空间、CPU 等的使用情况。

```

### Git

```shell

1. **常用的Git命令：**
   - `git init`: 在目录中初始化一个新的Git仓库。
   - `git clone`: 克隆现有的Git仓库。
   - `git add`: 将文件或更改添加到暂存区。
   - `git commit`: 提交暂存区的更改到本地仓库。
   - `git status`: 查看工作目录和暂存区的状态。
   - `git log`: 查看提交日志。
   - `git diff`: 查看工作目录中的更改。
   - `git branch`: 查看分支信息。
   - `git checkout`: 切换分支或恢复文件。
   - `git merge`: 合并分支。
   - `git pull`: 从远程仓库拉取更改。
   - `git push`: 推送本地更改到远程仓库。
   - `git remote`: 管理远程仓库。

2. **回滚操作：**
   - 如果你需要回滚到之前的提交状态，可以使用`git reset`命令。有三种主要的重置模式：
     - `git reset --soft`: 保留本地更改，并将HEAD指针移动到指定的提交，暂存区保持不变，可以重新提交。
     - `git reset --mixed`（默认模式）: 保留本地更改，但取消暂存区的更改，可以重新暂存和提交。
     - `git reset --hard`: 本地工作目录和暂存区都将回滚到指定的提交，慎用，可能会导致未保存的更改丢失。

   例如，如果要回滚到前一个提交：
   git reset HEAD~1

   如果要回滚到特定提交的SHA-1哈希值：
   git reset <commit-SHA>
```

### 设计模式

> 讲一下策略模式和工厂模式

> 工厂模式的使用场景

### 数据结构

> 哈希表的实现，怎们解决哈希冲突，如何优化（链表转红黑树，转换的阈值为8）

> 线性表是什么？在实际物理内存中是连续的吗？

线性表是一种抽象数据类型（ADT），用于存储一组具有线性关系的数据元素，这些元素通常按照一定的顺序排列。线性表可以包括顺序表和链表两种主要实现方式。

- **顺序表（Sequential List）：** 顺序表中的元素存储在物理内存中的连续位置。这意味着每个元素在内存中都有一个相对于前一个元素的固定偏移量。典型的顺序表包括数组，因此数组中的元素在内存中是连续的。

- **链表（Linked List）：** 链表中的元素以节点的形式存储，每个节点包含了数据元素和指向下一个节点的指针。链表的节点在物理内存中可以不是连续的，因为它们只需要存储指向下一个节点的引用。链表可以包括单链表、双链表和循环链表等不同类型。

尽管顺序表中的元素在内存中是连续存储的，但线性表本身的线性关系是指元素之间存在一个前后顺序，而不仅仅是物理内存上的连续性。链表中的元素虽然在物理内存上可能不连续，但它们在逻辑上仍然保持线性关系。

> 

### 其它

> gcc

1. **生成可执行文件：**
   - `-o <output>`：指定生成的可执行文件的名称。
2. **编译语言：**
   - `-x <language>`：指定要编译的源代码的语言，如 `-x c` 或 `-x c++`。
3. **编译模式：**
   - `-c`：只编译源文件而不进行链接，生成目标文件。
   - `-S`：只生成汇编代码
   - `-E`：只运行预处理器，生成预处理后的代码。
4. **优化选项：**
   - `-O0`, `-O1`, `-O2`, `-O3`：指定不同级别的优化。
   - `-Os`：优化以减小生成的可执行文件的大小。
5. **调试信息：**
   - `-g`：生成调试信息，以便用于调试器。
6. **头文件和库文件路径：**
   - `-I <dir>`：添加包含头文件的搜索路径。
   - `-L <dir>`：添加库文件的搜索路径。
   - `-l <library>`：链接指定的库。
7. **宏定义：**
   - `-D <macro>`：定义宏，如 `-DDEBUG`。
8. **警告和错误：**
   - `-Wall`：启用所有警告。
   - `-Werror`：将警告视为错误。
   - `-W<warning>`：启用指定的警告，如 `-Wunused-variable`。
9. **多线程支持：**
   - `-pthread`：启用 POSIX 线程库支持。
10. **编译器版本信息：**
    - `-v`：显示编译器的版本信息。
11. **帮助命令**
    - gcc --help

> Linux 常见的信号

- SIGINT: 终端信号，由用户按下 ctrl+c生成
- SIGALAM：定时器产生的信号
- SIGKILL：强制终止信号，不能被捕获，忽略
- SIGPIPE：管道破裂信号，向一个没有读端的管道写数据
- SIGIO：信号驱动 IO 模型安装一个信号处理函数，当 IO 事件就绪，进程会收到 SIGIO 信号
- SIGCHLD：子进程结束时，父进程会收到这个信号
- SIGSEGV：指示进程进行了无效内存访问(段错误)，终止进程并产生core文件

> git的一些命令

> shell的命令你一般用哪些？如果需要查近期访问你服务器的ip和次数你怎么用shell查？

## 手撕

- [885. 螺旋矩阵 III](https://leetcode.cn/problems/spiral-matrix-iii/description/)

- [300. 最长上升子序列](https://leetcode.cn/problems/longest-increasing-subsequence/)

- [53. 最大子数组和](https://leetcode.cn/problems/maximum-subarray/description/)
  
- [165. 比较版本号](https://leetcode.cn/problems/compare-version-numbers/description/)

- [232. 用栈实现队列](https://leetcode.cn/problems/implement-queue-using-stacks/) 

- [42. 接雨水](https://leetcode.cn/problems/trapping-rain-water/)

- [260. 只出现一次的数字 III](https://leetcode.cn/problems/single-number-iii/description/) 

- [137. 只出现一次的数字 II](https://leetcode.cn/problems/single-number-ii/description/) 

- [166. 分数到小数](https://leetcode.cn/problems/fraction-to-recurring-decimal/description/)

- [82. 删除排序链表中的重复元素 II](https://leetcode.cn/problems/remove-duplicates-from-sorted-list-ii/)

- [718. 最长重复子数组](https://leetcode.cn/problems/maximum-length-of-repeated-subarray/) 

- [19. 删除链表的倒数第 N 个结点](https://leetcode.cn/problems/remove-nth-node-from-end-of-list/) 

- [23. 合并 K 个升序链表](https://leetcode.cn/problems/merge-k-sorted-lists/) 

- [25. K 个一组翻转链表](https://leetcode.cn/problems/reverse-nodes-in-k-group/) 

- [31. 下一个排列](https://leetcode.cn/problems/next-permutation/)

- [51. N 皇后](https://leetcode.cn/problems/n-queens/)

- [72. 编辑距离](https://leetcode.cn/problems/edit-distance/)

- [131. 分割回文串](https://leetcode.cn/problems/palindrome-partitioning/)

- [215. 数组中的第K个最大元素](https://leetcode.cn/problems/kth-largest-element-in-an-array/description/)

- [146. LRU 缓存](https://leetcode.cn/problems/lru-cache/)

- [56. 合并区间](https://leetcode.cn/problems/merge-intervals/)

- [114. 二叉树展开为链表](https://leetcode.cn/problems/flatten-binary-tree-to-linked-list/)

- [134. 加油站](https://leetcode.cn/problems/gas-station/)

- [151. 反转字符串中的单词](https://leetcode.cn/problems/reverse-words-in-a-string/description/)

- 手撕生产者消费者

- 多个线程交替打印数字

```c++
#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>

std::mutex mtx;
std::condition_variable cv;
bool print_123 = true;

void printNumbers(const int num) {
    while (true) {
        std::unique_lock<std::mutex> lock(mtx);
        // 等待条件满足
        cv.wait(lock, [num] { return (num == 123 && print_123) || (num == 456 && !print_123); });
        // 打印数字
        std::cout << num << std::endl;
        // 更新条件变量状态
        print_123 = !print_123;
        // 通知另一个线程继续执行
        cv.notify_one();
    }
}

// 交替打印 123, 456
int main() {
    std::thread t1(printNumbers, 123);
    std::thread t2(printNumbers, 456);
    t1.join();
    t2.join();
    return 0;
}
```

> 红黑树的插入

左根右，根叶黑（叶为空节点），黑路同，不红红

- 先查找，确定插入位置（原理同二叉排序树）插入新结点
- 新结点是根——染为黑色
- 新结点非根——染为红色 （黑路同）（检查不红红）
  - 若插入新结点后依然满足红黑树定义，则插入结束
  - 若插入新结点后不满足红黑树定义，需要调整，使其重新满足红黑树定义
    - 黑叔：旋转+染色
      - LL型：右单旋，父换爷+染色（之前的父节点爷节点换颜色）
      - RR型：左单旋，父换爷+染色
      - LR型:左、右双旋，儿换爷+染色（之前的儿子和爷换颜色）
      - RL型：右、左双旋，儿换爷+染色
    - 红叔：染色+变新
      - 叔父爷染色，爷变为新结点（重新走上述逻辑）

## 场景题目

> 设计背包

> 100个球,两个人分别拿,至少拿一个最多拿5个,你先拿怎么保证你能拿到第100个

只要最后一轮剩下 6 个，无论对方拿几个，我都可以拿到最后一个球。因此只要保证剩余球的数目为 6 的倍数即可。所以第一次我拿 4 个，剩 96 个，之后无论对方 x 个，我都拿 6 - x 个确保最后剩 6 个

> 有一苹果两个人抛硬币来决定谁吃这个苹果，先抛到正面者吃。问先抛者吃到苹果的概率是多少？

假设先抛者赢的概率是p，后抛者赢的概率就是 1-p。那么A直接赢的概率为 1/2，否则就轮到 B 先抛了(1 / 2 的概率)，此时 A 就成为了后抛者，赢的概率为 1-p
因此 p = 1/2 + 1/2 * (1 - p)  --> p = 2 / 3

> 有25匹马，每次只能拿出5匹来进行比较，那么最少可以通过多少次的比较，找到最快的三匹马？

7 次
首先分五组进行比较，得到每组的第一名，5次
每组的第一名再进行比较，不妨设123组分别取得了123名，那么第一组的第一名一定是所有马匹中最快的，第一组的2, 3名可能是所有马匹中的2, 3名；第二组的第三名最好情况为所有马匹中的第 4 名，因此只考虑第二组的 1, 2 名；第三组的第 1 名最好情况为真正的第三名；因此仍需一次比较，1次
最后一次比完即可确定真正的前三名

> 一根木棒，截成三截，组成三角形的概率是多少

![](https://pic4.zhimg.com/80/v2-d076d463615b9ada6ce4a9e1f4d229ff_720w.webp)

> 已知有个 rand7() 的函数，返回 1 到 7 随机自然数，怎样利用这个 rand7() 构造 rand10()，随机 1 ~ 10

rand7() 返回 1 ~ 7 的自然数，构造新的函数 (rand7() - 1) * 7 + rand7()，这个函数会随机产生 1 到 49 的自然数。原因是 1 到 49 中的每个数只有唯一的第一个 rand7() 的值和第二个 rand7() 的值表示，于是它们出现的概率是相等

只要 1 - 40，那么 y = (x - 1) / 4 + 1

> 高楼扔鸡蛋

假设最优次数为 x 次，考虑第一次从第几层开始扔

**假设第一次扔在第x+1层：** 如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第1层开始一层一层扔，一直扔到第x层。这样一来，我们总共尝试了x+1次，和假设尝试x次相悖。由此可见，第一次扔的楼层必须小于x+1层。

**假设第一次扔在第x-1层：**如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第1层开始一层一层扔，一直扔到第x-2层。这样一来，我们总共尝试了x-2+1 = x-1次，虽然没有超出假设次数，但似乎有些过于保守。

**假设第一次扔在第x层：**如果第一个鸡蛋碎了，那么第二个鸡蛋只能从第1层开始一层一层扔，一直扔到第x-1层。这样一来，我们总共尝试了x-1+1 = x次，刚刚好没有超出假设次数。

因此，要想尽量楼层跨度大一些，又要保证不超过假设的尝试次数x，那么第一次扔鸡蛋的最优选择就是第x层。

那么算最坏情况，第二次你只剩下x-1次机会，按照上面的说法，你第二次尝试的位置必然是X+（X-1）；

以此类推我们可得：

x + (x-1) + (x-2) + ... + 1 = 100

左边的多项式是各次扔鸡蛋的楼层跨度之和。由于假设尝试x次，所以这个多项式共有x项。

即 (x+1)*x/2 = 100，最终x向上取整，得到 x = 14









