**计算机网络**

- [1、OSI 的七层模型分别是？各自的功能是什么？](#1osi-的七层模型分别是各自的功能是什么)
- [2、说一下一次完整的HTTP请求过程包括哪些内容？](#2说一下一次完整的http请求过程包括哪些内容)
- [3、你知道DNS是什么？](#3你知道dns是什么)
- [4、DNS的工作原理？](#4dns的工作原理)
- [5、为什么域名解析用UDP协议？](#5为什么域名解析用udp协议)
- [6、为什么区域传送用TCP协议？](#6为什么区域传送用tcp协议)
- [7、HTTP长连接和短连接的区别](#7http长连接和短连接的区别)
- [8、什么是TCP粘包/拆包？发生的原因？](#8什么是tcp粘包拆包发生的原因)
- [9、为什么服务器会有缓存这一项功能?如何实现的？](#9为什么服务器会有缓存这一项功能如何实现的)
- [10、HTTP请求方法你知道多少？](#10http请求方法你知道多少)
- [11、GET 和 POST 的区别，你知道哪些？](#11get-和-post-的区别你知道哪些)
- [12、一个TCP连接可以对应几个HTTP请求？](#12一个tcp连接可以对应几个http请求)
- [13、一个 TCP 连接中 HTTP 请求发送可以一起发送么（比如一起发三个请求，再三个响应一起接收）？](#13一个-tcp-连接中-http-请求发送可以一起发送么比如一起发三个请求再三个响应一起接收)
- [14、浏览器对同一 Host 建立 TCP 连接到的数量有没有限制？](#14浏览器对同一-host-建立-tcp-连接到的数量有没有限制)
- [15、在浏览器中输入url地址后显示主页的过程?](#15在浏览器中输入url地址后显示主页的过程)
- [16、在浏览器地址栏输入一个URL后回车，背后会进行哪些技术步骤？](#16在浏览器地址栏输入一个url后回车背后会进行哪些技术步骤)
- [17、谈谈DNS解析过程，具体一点](#17谈谈dns解析过程具体一点)
- [18、DNS负载均衡是什么策略？](#18dns负载均衡是什么策略)
- [19、HTTPS和HTTP的区别](#19https和http的区别)
- [20、什么是SSL/TLS ？](#20什么是ssltls-)
- [21、HTTPS 是如何保证数据传输的安全，整体的流程是什么？（SSL是怎么工作保证安全的）](#21https-是如何保证数据传输的安全整体的流程是什么ssl是怎么工作保证安全的)
- [22、如何保证公钥不被篡改？](#22如何保证公钥不被篡改)
- [23、HTTP 请求和响应报文有哪些主要字段？](#23http-请求和响应报文有哪些主要字段)
- [24、Cookie 是什么？](#24cookie-是什么)
- [25、Cookie有什么用途？](#25cookie有什么用途)
- [26、Session 知识大总结](#26session-知识大总结)
- [27、Session 的工作原理是什么？](#27session-的工作原理是什么)
- [28、Cookie与Session的对比](#28cookie与session的对比)
- [29、SQL注入攻击了解吗？](#29sql注入攻击了解吗)
- [30、网络的七层模型与各自的功能（图片版）](#30网络的七层模型与各自的功能图片版)
- [31、什么是RARP？工作原理](#31什么是rarp工作原理)
- [32、端口有效范围是多少到多少？](#32端口有效范围是多少到多少)
- [33、为何需要把 TCP/IP 协议栈分成 5 层（或7层）？开放式回答。](#33为何需要把-tcpip-协议栈分成-5-层或7层开放式回答)
- [34、DNS查询方式有哪些？](#34dns查询方式有哪些)
- [35、HTTP中缓存的私有和公有字段？知道吗？](#35http中缓存的私有和公有字段知道吗)
- [36、GET 方法参数写法是固定的吗？](#36get-方法参数写法是固定的吗)
- [37、GET 方法的长度限制是怎么回事？](#37get-方法的长度限制是怎么回事)
- [38、POST 方法比 GET 方法安全？](#38post-方法比-get-方法安全)
- [39、POST 方法会产生两个 TCP 数据包？你了解吗？](#39post-方法会产生两个-tcp-数据包你了解吗)
- [40、Session是什么？](#40session是什么)
- [41、使用 Session 的过程是怎样的？](#41使用-session-的过程是怎样的)
- [42、Session和cookie应该如何去选择（适用场景）？](#42session和cookie应该如何去选择适用场景)
- [43、Cookies和Session区别是什么？](#43cookies和session区别是什么)
- [44、DDos 攻击了解吗？](#44ddos-攻击了解吗)
- [45、MTU 和 MSS 分别是什么？](#45mtu-和-mss-分别是什么)
- [46、HTTP中有个缓存机制，但如何保证缓存是最新的呢？（缓存过期机制）](#46http中有个缓存机制但如何保证缓存是最新的呢缓存过期机制)
- [47、TCP头部中有哪些信息？](#47tcp头部中有哪些信息)
- [48、常见TCP的连接状态有哪些？](#48常见tcp的连接状态有哪些)
- [49、网络的七层/五层模型主要的协议有哪些？](#49网络的七层五层模型主要的协议有哪些)
- [50、TCP是什么？](#50tcp是什么)
- [51、TCP头部报文字段介绍几个？各自的功能？](#51tcp头部报文字段介绍几个各自的功能)
- [52、OSI 的七层模型的主要功能？](#52osi-的七层模型的主要功能)
- [53、应用层常见协议知道多少？了解几个？](#53应用层常见协议知道多少了解几个)
- [54、浏览器在与服务器建立了一个 TCP 连接后是否会在一个 HTTP 请求完成后断开？什么情况下会断开？](#54浏览器在与服务器建立了一个-tcp-连接后是否会在一个-http-请求完成后断开什么情况下会断开)
- [55、三次握手相关内容](#55三次握手相关内容)
- [56、为什么需要三次握手，两次不行吗？](#56为什么需要三次握手两次不行吗)
- [57、什么是半连接队列？](#57什么是半连接队列)
- [58、 ISN(Initial Sequence Number)是固定的吗？](#58-isninitial-sequence-number是固定的吗)
- [59、 三次握手过程中可以携带数据吗？](#59-三次握手过程中可以携带数据吗)
- [60、SYN攻击是什么？](#60syn攻击是什么)
- [61、 四次挥手相关内容](#61-四次挥手相关内容)
- [62、挥手为什么需要四次？](#62挥手为什么需要四次)
- [63、2MSL等待状态？](#632msl等待状态)
- [64、四次挥手释放连接时，等待2MSL的意义?](#64四次挥手释放连接时等待2msl的意义)
- [65、为什么TIME\_WAIT状态需要经过2MSL才能返回到CLOSE状态？](#65为什么time_wait状态需要经过2msl才能返回到close状态)
- [66、TCP粘包问题是什么？你会如何去解决它？](#66tcp粘包问题是什么你会如何去解决它)
- [67、OSI七层模型中表示层和会话层功能是什么？](#67osi七层模型中表示层和会话层功能是什么)
- [68、三次握手四次挥手的变迁图](#68三次握手四次挥手的变迁图)
- [69、对称密钥加密的优点缺点？](#69对称密钥加密的优点缺点)
- [70、非对称密钥加密你了解吗？优缺点？](#70非对称密钥加密你了解吗优缺点)
- [71、HTTPS 是什么？](#71https-是什么)
- [72、HTTP 的缺点有哪些？](#72http-的缺点有哪些)
- [73、HTTPS采用的加密方式有哪些？是对称还是非对称？](#73https采用的加密方式有哪些是对称还是非对称)
- [74、为什么有的时候刷新页面不需要重新建立 SSL 连接？](#74为什么有的时候刷新页面不需要重新建立-ssl-连接)
- [75、SSL中的认证中的证书是什么？了解过吗？](#75ssl中的认证中的证书是什么了解过吗)
- [76、HTTP如何禁用缓存？如何确认缓存？](#76http如何禁用缓存如何确认缓存)
- [77、GET与POST传递数据的最大长度能够达到多少呢？](#77get与post传递数据的最大长度能够达到多少呢)
- [78、网络层常见协议？可以说一下吗？](#78网络层常见协议可以说一下吗)
- [79、TCP四大拥塞控制算法总结？（极其重要）](#79tcp四大拥塞控制算法总结极其重要)
- [80、为何快速重传是选择3次ACK？](#80为何快速重传是选择3次ack)
- [81、对于 FIN\_WAIT\_2, CLOSE\_WAIT 状态和 TIME\_WAIT 状态？你知道多少?](#81对于-fin_wait_2-close_wait-状态和-time_wait-状态你知道多少)
- [82、你了解流量控制原理吗？](#82你了解流量控制原理吗)
- [83、建立TCP服务器的各个系统调用过程是怎样的？](#83建立tcp服务器的各个系统调用过程是怎样的)
- [84、TCP 协议如何保证可靠传输？](#84tcp-协议如何保证可靠传输)
- [85、UDP是什么？](#85udp是什么)
- [86、TCP 和 UDP 的区别](#86tcp-和-udp-的区别)
- [87、UDP的特点有哪些（附赠TCP的特点）？](#87udp的特点有哪些附赠tcp的特点)
- [88、TCP 对应的应用层协议](#88tcp-对应的应用层协议)
- [89、UDP 对应的应用层协议](#89udp-对应的应用层协议)
- [90、数据链路层常见协议？可以说一下吗？](#90数据链路层常见协议可以说一下吗)
- [91、Ping命令基于什么协议？原理是什么？](#91ping命令基于什么协议原理是什么)
- [92、在进行UDP编程的时候，一次发送多少bytes好?](#92在进行udp编程的时候一次发送多少bytes好)
- [93、TCP 利用滑动窗口实现流量控制的机制？](#93tcp-利用滑动窗口实现流量控制的机制)
- [94、可以解释一下RTO（Retransmission TimeOut），RTT（Round-Trip Time）和超时重传分别是什么吗？](#94可以解释一下rtoretransmission-timeoutrttround-trip-time和超时重传分别是什么吗)
- [95、XSS攻击是什么？（低频）](#95xss攻击是什么低频)
- [96、CSRF攻击？你知道吗？](#96csrf攻击你知道吗)
- [97、如何防范CSRF攻击](#97如何防范csrf攻击)
- [98、文件上传漏洞是如何发生的？你有经历过吗？](#98文件上传漏洞是如何发生的你有经历过吗)
- [99、如何防范文件上传漏洞](#99如何防范文件上传漏洞)
- [100、拥塞控制原理听说过吗？](#100拥塞控制原理听说过吗)
- [101、如何区分流量控制和拥塞控制？](#101如何区分流量控制和拥塞控制)
- [102、常见的HTTP状态码有哪些？](#102常见的http状态码有哪些)
- [103、服务器出现大量close\_wait的连接的原因是什么？有什么解决方法？](#103服务器出现大量close_wait的连接的原因是什么有什么解决方法)
- [104、一台机器能够使用的端口号上限是多少，是否可以修改？如果想要用的端口超过这个限制怎么办？](#104一台机器能够使用的端口号上限是多少是否可以修改如果想要用的端口超过这个限制怎么办)

## 1、OSI 的七层模型分别是？各自的功能是什么？

- **简要概括**

  *   物理层：底层数据传输，如网线；网卡标准。
  *   数据链路层：定义数据的基本格式，如何传输，如何标识；如网卡MAC地址。
  *   网络层：定义IP编址，定义路由功能；如不同设备的数据转发。
  *   传输层：端到端传输数据的基本功能；如 TCP、UDP。
  *   会话层：控制应用程序之间会话能力；如不同软件数据分发给不同软件。
  *   表示层：数据格式标识，基本压缩加密功能。
  *   应用层：各种应用软件，包括 Web 应用。
    
- **说明**

  *   在四层，既传输层数据被称作**tcp报文段或udp用户数据报**（Segments）；
  *   三层网络层数据被称做**包**（Packages）；
  *   二层数据链路层时数据被称为**帧**（Frames）；
  *   一层物理层时数据被称为**比特流**（Bits）。

- **总结**

  *   网络七层模型是一个标准，而非实现。
  *   网络四层模型是一个实现的应用模型。
  *   网络四层模型由七层模型简化合并而来。

---

## 2、说一下一次完整的HTTP请求过程包括哪些内容？

- **第一种回答**

  *   建立起客户机和服务器连接。
  *   建立连接后，客户机发送一个请求给服务器。
  *   服务器收到请求给予响应信息。
  *   客户端浏览器将返回的内容解析并呈现，断开连接。

- **第二种回答**

域名解析 --> 发起TCP的3次握手 --> 建立TCP连接后发起http请求 --> 服务器响应http请求，浏览器得到html代码 --> 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等） --> 浏览器对页面进行渲染呈现给用户。

---

## 3、你知道DNS是什么？

**官方解释**：DNS（Domain Name System，域名系统），因特网上作为**域名和IP地址相互映射**的一个**分布式数据库**，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。

通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。

**通俗的讲**，我们更习惯于记住一个网站的名字，比如www.baidu.com,而不是记住它的ip地址，比如：167.23.10.2。

---

## 4、DNS的工作原理？

**将主机域名转换为ip地址，属于应用层协议，使用UDP传输**。（DNS应用层协议，以前有个考官问过）

![](http://oss.interviewguide.cn/img/202205220036790.png) 

过程：浏览器缓存，系统缓存，路由器缓存，本地域名服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存。 

1.  当用户输入域名时，浏览器先检查自己的缓存中是否包含这个域名映射的ip地址，有解析结束。 2）若没命中，则检查操作系统缓存（如Windows的hosts）中有没有解析过的结果，有解析结束。 3）若无命中，则请求本地域名服务器解析（LDNS）。 4）若LDNS没有命中就直接跳到根域名服务器请求解析。根域名服务器返回给LDNS一个 顶级域名服务器（gTLD）地址。 5）此时LDNS再发送请求给上一步返回的顶级域名服务器， 接受请求的gTLD查找并返回这个域名对应的主域名服务器地址 6）主域名服务器根据映射关系表找到目标ip，返回给LDNS
2.  LDNS缓存这个域名和对应的ip， 把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束


一、主机向本地域名服务器的查询一般都是采用递归查询。 
二、本地域名服务器向根域名服务器的查询的迭代查询。

DNS 包含域名解析（域名转换为IP地址）和区域传送（DNS中用于主从域名服务器之间同步数据的过程）两大功能

---

## 5、为什么域名解析用UDP协议？

域名解析通常是一个简短的查询-响应过程，其中查询请求相对较小，响应也通常是短暂的

UDP快啊！UDP的DNS协议只要一个请求、一个应答就好了。适合用于这种简单的查询-响应场景

而使用基于TCP的DNS协议要三次握手、发送数据以及应答、四次挥手，但是UDP协议传输内容不能超过512字节。

不过客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。

---

## 6、为什么区域传送用TCP协议？

区域传送涉及到大量的数据传输，可能包含整个域名的数据

因为TCP协议可靠性好啊！（可以确保数据的完整性和有序性，适合用于这种大数据量的传输）

你要从主DNS上复制内容啊，你用不可靠的UDP？ 因为TCP协议传输的内容大啊，你用最大只能传512字节的UDP协议？万一同步的数据大于512字节，你怎么办？所以用TCP协议比较好！

---

## 7、HTTP长连接和短连接的区别

在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。

而从HTTP/1.1起，默认使用长连接，用以保持连接特性。

---

## 8、什么是TCP粘包/拆包？发生的原因？

TCP粘包和拆包是在网络通信中常见的问题，它们与TCP协议的数据传输方式有关。这些问题可能导致接收方收到的数据不完整或混乱，需要特殊的处理机制来解决。

**TCP粘包**是指发送方在发送数据时，多个数据包粘在一起，形成一个较大的数据块，而接收方在接收数据时，无法正确区分每个数据包，从而导致接收到的数据混乱。例如，发送方发送了两个小数据包A和B，但接收方可能会一次性接收到一个较大的数据块AB，无法准确分开

**TCP拆包**是指发送方在发送数据时，一个数据包被拆分成多个小数据块，而接收方在接收数据时，无法得知数据包的边界，导致无法正确重组数据包。例如，发送方发送了一个较大的数据包，但接收方可能会接收到多个小数据块，无法准确还原原始的数据包

- **原因**

  - 数据发送速度和接收速度不匹配：发送方可能连续发送多个小数据包，而接收方无法及时处理，导致多个数据包粘在一起形成粘包

  - 数据量较小：TCP是面向字节流的协议，在发送端传送的数据只是一个个的字节，接收方根据TCP协议栈的接收缓冲区进行数据的组装。当数据包较小时，几个数据包可能会被放在同一个TCP报文段中

  - TCP缓冲区设置：TCP有接收和发送缓冲区，在发送端，如果连续发送的数据小于缓冲区的大小，多个数据包可能被合并成一个TCP报文段，从而形成粘包

  - 应用程序写入数据的字节大小大于套接字发送缓冲区的大小.

  - 为了适应网络链路的最大传输单元（MTU），发送方会根据接收方的最大段大小（Maximum Segment Size，MSS）来进行**TCP分段** ( MSS是TCP报文段的最大有效载荷大小，即TCP报文段长度 - TCP首部长度)

  - 在以太网中，每个数据帧的有效载荷（payload）大小是有限的，由以太网的最大传输单元（MTU，以太网一般1500字节）决定，当IP 数据包的大小超过了以太网的 MTU时进行**IP分片**

MTU指：一种通信协议的某一层上面所能通过的最大数据包大小

TCP分段和IP分片有些相似，但是TCP分段是在应用层和传输层之间进行的，而IP分片是在网络层进行的。 TCP分段更灵活和可靠，因为它是在端到端的基础上进行的，而IP分片是在中间路由器上进行的，可能会导致片段丢失而无法重新组装。

- **解决方案**

  1. 消息定长，发送方在每个数据包中添加固定长度的头部信息，指明数据包的长度，接收方根据头部信息来正确拆分数据包

  2. 在包尾部增加回车或者空格符等特殊字符进行分割，接收方根据分隔符来区分数据包的边界

  3. 将消息分为消息头和消息尾，在每个数据包的头部添加一个消息头，包含数据包的长度信息，接收方根据消息头来解析数据包

  4. 使用其它复杂的协议，如RTMP协议等

---

## 9、为什么服务器会有缓存这一项功能?如何实现的？

**原因**

*   缓解服务器压力；
*   降低客户端获取资源的延迟：缓存通常位于内存中，读取缓存的速度更快。并且缓存服务器在地理位置上也有可能比源服务器来得近，例如浏览器缓存。

**实现方法**

*   让代理服务器进行缓存；
*   让客户端浏览器进行缓存。

---

## 10、HTTP请求方法你知道多少？

客户端发送的 **请求报文** 第一行为请求行，包含了方法字段。

根据 HTTP 标准，HTTP 请求可以使用多种请求方法。

HTTP1.0 定义了三种请求方法： GET, POST 和 HEAD方法。

HTTP1.1 新增了六种请求方法：OPTIONS、PUT、PATCH、DELETE、TRACE 和 CONNECT 方法。


| 序 号 | 方法 | 描述 |
| --- | --- | --- |
|1 |GET |请求指定的页面信息，并返回实体主体。 |
| 2 | HEAD |类似于 GET 请求，只不过返回的响应中没有具体的内容，用于获取报头 |
| 3 |POST |向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST 请求可能会导致新的资源的建立和/或已有资源的修改。 |
| 4 | PUT |从客户端向服务器传送的数据取代指定的文档的内容。 |
| 5 | DELETE |请求服务器删除指定的页面。 |
| 6 | CONNECT | |HTTP/1.1 协议中预留给能够将连接改为管道方式的代理服务器。 |
| 7 |OPTIONS |允许客户端查看服务器的性能。 |
| 8 |TRACE |回显服务器收到的请求，主要用于测试或诊断。 |
| 9 | PATCH |是对 PUT 方法的补充，用来对已知资源进行局部更新 。|

---

## 11、GET 和 POST 的区别，你知道哪些？

1.  get是获取数据，post是修改数据
    
2.  get把请求的数据放在url的查询字符串上， 以?分割URL和传输数据，参数之间以&相连，所以get不太安全。而post把数据放在HTTP的包体内（request body 相对安全）而不会显示在 URL 中，传输的数据相对安全一些
    
3.  get提交的数据最大是2k（ 限制实际上取决于浏览器）， post理论上没有限制。
    
4.  GET产生一个TCP数据包，浏览器会把http header和data一并发送出去，服务器响应200(返回数据); POST产生两个TCP数据包，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)。
    
5.  GET请求会被浏览器主动缓存，而POST不会，除非手动设置。
    
6.  本质区别：GET是幂等的，而POST不是幂等的
    
    > 这里的幂等性：幂等性是指一次和多次请求某一个资源应该具有同样的副作用。简单来说意味着对同一URL的多个请求应该返回同样的结果。
    
正因为它们有这样的区别，所以不应该且**不能用get请求做数据的增删改这些有副作用的操作**。因为get请求是幂等的，**在网络不好的隧道中会尝试重试**。如果用get请求增数据，会有**重复操作**的风险，而这种重复操作可能会导致副作用（浏览器和操作系统并不知道你会用get请求去做增操作）。

---

## 12、一个TCP连接可以对应几个HTTP请求？

如果维持连接，一个 TCP 连接是可以发送多个 HTTP 请求的。

---

## 13、一个 TCP 连接中 HTTP 请求发送可以一起发送么（比如一起发三个请求，再三个响应一起接收）？

HTTP/1.1 存在一个问题，单个 TCP 连接在同一时刻只能处理一个请求，意思是说：两个请求的生命周期不能重叠，任意两个 HTTP 请求从开始到结束的时间在同一个 TCP 连接里不能重叠。

在 HTTP/1.1 存在 Pipelining （流水线）技术可以完成这个多个请求同时发送，但是由于浏览器默认关闭，所以可以认为这是不可行的。在 HTTP2 中由于 Multiplexing （多路复用）特点的存在，多个 HTTP 请求可以在同一个 TCP 连接中并行进行。

那么在 HTTP/1.1 时代，浏览器是如何提高页面加载效率的呢？主要有下面两点：

*   维持和服务器已经建立的 TCP 连接，在同一连接上顺序处理多个请求。
*   和服务器建立多个 TCP 连接。

---

## 14、浏览器对同一 Host 建立 TCP 连接到的数量有没有限制？

假设我们还处在 HTTP/1.1 时代，那个时候没有多路传输，当浏览器拿到一个有几十张图片的网页该怎么办呢？肯定不能只开一个 TCP 连接顺序下载，那样用户肯定等的很难受，但是如果每个图片都开一个 TCP 连接发 HTTP 请求，那电脑或者服务器都可能受不了，要是有 1000 张图片的话总不能开 1000 个TCP 连接吧，你的电脑同意 NAT 也不一定会同意。

**有，Chrome 最多允许对同一个 Host 建立六个 TCP 连接。不同的浏览器有一些区别。**

如果图片都是 HTTPS 连接并且在同一个域名下，那么浏览器在 SSL 握手 (建立安全的加密通信连接, SSL（Secure Sockets Layer，安全套接字层）是早期的加密协议，现在已被 TLS（Transport Layer Security，传输层安全）协议所取代，但人们通常仍然称其为 SSL 握手) 之后会和服务器商量能不能用 HTTP2，如果能的话就使用 Multiplexing 功能在这个连接上进行多路传输。不过也未必会所有挂在这个域名的资源都会使用一个 TCP 连接去获取，但是可以确定的是 Multiplexing 很可能会被用到。

如果发现用不了 HTTP2 呢？或者用不了 HTTPS（现实中的 HTTP2 都是在 HTTPS 上实现的，所以也就是只能使用 HTTP/1.1）。那浏览器就会在一个 HOST 上建立多个 TCP 连接，连接数量的最大限制取决于浏览器设置，这些连接会在空闲的时候被浏览器用来发送新的请求，如果所有的连接都正在发送请求呢？那其他的请求就只能等等了。

---

## 15、在浏览器中输入url地址后显示主页的过程?

*   根据域名，进行DNS域名解析；
*   拿到解析的IP地址，建立TCP连接；
*   向IP地址，发送HTTP请求；
*   服务器处理请求；
*   返回响应结果；
*   关闭TCP连接；
*   浏览器解析HTML；
*   浏览器布局渲染；

---

## 16、在浏览器地址栏输入一个URL后回车，背后会进行哪些技术步骤？

- **第一种回答**

1、查浏览器缓存，看看有没有已经缓存好的，如果没有

2、检查本机hosts文件，

3、调用API，Linux下Socket函数 gethostbyname

4、向DNS服务器发送DNS请求，查询本地DNS服务器，这其中用的是UDP的协议

5、如果在一个子网内采用ARP地址解析协议进行ARP查询; 如果不在一个子网那就需要对默认网关进行DNS查询，如果还找不到会一直向上找根DNS服务器，直到最终拿到IP地址（全球400多个根DNS服务器，由13个不同的组织管理）

6、这个时候我们就有了服务器的IP地址 以及默认的端口号了，http默认是80 https是 443 端口号，会首先尝试http然后调用Socket建立TCP连接，

7、经过三次握手成功建立连接后，开始传送数据，如果正是http协议的话，就返回就完事了，

8、如果不是http协议，服务器会返回一个5开头的的重定向消息，告诉我们用的是https，那就是说IP没变，但是端口号从80变成443了，好了，再四次挥手，完事，

9、再来一遍，这次除了上述的端口号从80变成443之外，还会采用SSL的加密技术来保证传输数据的安全性，保证数据传输过程中不被修改或者替换之类的，

10、这次依然是三次握手，沟通好双方使用的认证算法，加密和检验算法，在此过程中也会检验对方的CA安全证书。

11、确认无误后，开始通信，然后服务器就会返回你所要访问的网址的一些数据，在此过程中会将界面进行渲染，牵涉到ajax技术之类的，直到最后我们看到色彩斑斓的网页


- **第二种回答**

浏览器检查域名是否在缓存当中（要查看 Chrome 当中的缓存， 打开 chrome://net-internals/#dns）。

如果缓存中没有，就去调用 `gethostbyname` 库函数（操作系统不同函数也不同）进行查询。

如果 `gethostbyname` 没有这个域名的缓存记录，也没有在 `hosts` 里找到，它将会向 DNS 服务器发送一条 DNS 查询请求。DNS 服务器是由网络通信栈提供的，通常是本地路由器或者 ISP 的缓存 DNS 服务器。

查询本地 DNS 服务器

如果 DNS 服务器和我们的主机在同一个子网内，系统会按照下面的 ARP 过程对 DNS 服务器进行 ARP查询

如果 DNS 服务器和我们的主机在不同的子网，系统会按照下面的 ARP 过程对默认网关进行查询

---

## 17、谈谈DNS解析过程，具体一点

![](http://oss.interviewguide.cn/img/202205220036692.png)

*   请求一旦发起，若是chrome浏览器，先在浏览器找之前**有没有缓存过的域名所对应的ip地址**，有的话，直接跳过dns解析了，若是没有，就会**找硬盘的hosts文件**，看看有没有，有的话，直接找到hosts文件里面的ip
*   如果本地的hosts文件没有能得到对应的ip地址，浏览器会发出一个**dns请求到本地dns服务器**，**本地dns服务器一般都是你的网络接入服务器商提供**，比如中国电信，中国移动等。
*   查询你输入的网址的DNS请求到达本地DNS服务器之后，**本地DNS服务器会首先查询它的缓存记录**，如果缓存中有此条记录，就可以直接返回结果，此过程是**递归的方式进行查询**。如果没有，本地DNS服务器还要向**DNS根服务器**进行查询。
*   本地DNS服务器继续向域服务器发出请求，在这个例子中，请求的对象是.com域服务器。.com域服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是告诉本地DNS服务器，你的域名的解析服务器的地址。
*   最后，本地DNS服务器向**域名的解析服务器**发出请求，这时就能收到一个域名和IP地址对应关系，本地DNS服务器不仅要把IP地址返回给用户电脑，还要把这个对应关系保存在缓存中，以备下次别的用户查询时，可以直接返回结果，加快网络访问。
  
---

## 18、DNS负载均衡是什么策略？

当一个网站有足够多的用户的时候，假如每次请求的资源都位于同一台机器上面，那么这台机器随时可能会崩掉。处理办法就是用DNS负载均衡技术，它的原理是在**DNS服务器中为同一个主机名配置多个IP地址,在应答DNS查询时,DNS服务器对每个查询将以DNS文件中主机记录的IP地址按顺序返回不同的解析结果,将客户端的访问引导到不同的机器上去,使得不同的客户端访问不同的服务器**,从而达到负载均衡的目的｡例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等。

---

## 19、HTTPS和HTTP的区别

1、HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全， HTTPS协议是由SSL+HTTP协议构建的**可进行加密传输、身份认证的网络协议**，要比http协议安全。

2、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。 

3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

---

## 20、什么是SSL/TLS ？

SSL代表安全套接字层。它是一种用于加密和验证应用程序（如浏览器）和Web服务器之间发送的数据的协议。 
身份验证， 加密Https的加密机制是一种共享密钥加密和公开密钥加密并用的混合加密机制。

SSL/TLS协议作用：认证用户和服务，加密数据，维护数据的完整性的应用层协议

加密和解密需要两个不同的密钥，故被称为非对称加密；加密和解密都使用同一个密钥的

对称加密：优点在于加密、解密效率通常比较高 ，HTTPS 是基于非对称加密的， 公钥是公开的，

---

## 21、HTTPS 是如何保证数据传输的安全，整体的流程是什么？（SSL是怎么工作保证安全的）

（1）客户端向服务器端发起SSL连接请求； 
（2）服务器把公钥发送给客户端，并且服务器端保存着唯一的私钥 
（3）客户端用公钥对双方通信的对称秘钥进行加密，并发送给服务器端 
（4）服务器利用自己唯一的私钥对客户端发来的对称秘钥进行解密， 
（5）进行数据传输，服务器和客户端双方用公有的相同的对称秘钥对数据进行加密解密，可以保证在数据收发过程中的安全，即是第三方获得数据包，也无法对其进行加密，解密和篡改。

SSL/TLS协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。

**补充**：SSL/TLS的四次握手，目前网上的主流答案都在重复阮一峰老师的博客，属于TLS 1.0版本的答案，使用RSA密钥交换算法。但是现在TLS 1.2已经成为主流，使用ECDHE算法，如果面试可以说出这个版本的答案，应该会更好。

---

## 22、如何保证公钥不被篡改？

数字签名、摘要是证书防伪非常关键的武器。 “摘要”就是对传输的内容通过hash算法计算出一段固定长度的串。然后，通过发送方的私钥对这段摘要进行加密，加密后得到的结果就是“数字签名”

将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。 公钥加密计算量太大，如何减少耗用的时间？ 每一次对话（session），客户端和服务器端都生成一个"对话密钥"（session key），用它来加密信息。由于"对话密钥"是对称加密，所以运算速度非常快，而服务器公钥只用于加密"对话密钥"本身，这样就减少了加密运算的消耗时间。 
（1） 客户端向服务器端索要并验证公钥。 
（2） 双方协商生成"对话密钥"。
（3） 双方采用"对话密钥"进行加密通信。上面过程的前两步，又称为"握手阶段"（handshake）。

---

## 23、HTTP 请求和响应报文有哪些主要字段？

- **请求报文**

  *   请求行：Request Line
  *   请求头：Request Headers
  *   请求体：Request Body

- **响应报文**

  *   状态行：Status Line
  *   响应头：Response Headers
  *   响应体：Response Body

## 24、Cookie 是什么？

HTTP 协议是**无状态**的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务，HTTP/1.1 引入 Cookie 来保存状态信息。

Cookie 是**服务器发送到用户浏览器并保存在本地的一小块数据**，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销（尤其是在移动环境下）

Cookie 曾一度用于客户端数据的存储，因为当时并没有其它合适的存储办法而作为唯一的存储手段，但现在随着现代浏览器开始支持各种各样的存储方式，Cookie 渐渐被淘汰。

新的浏览器 API 已经允许开发者直接将数据存储到本地，如使用 Web storage API（本地存储和会话存储）或 IndexedDB。

***cookie 的出现是因为 HTTP 是无状态的一种协议，换句话说，服务器记不住你，可能你每刷新一次网页，就要重新输入一次账号密码进行登录。这显然是让人无法接受的，cookie 的作用就好比服务器给你贴个标签，然后你每次向服务器再发请求时，服务器就能够 cookie 认出你***

抽象地概括一下：一个 cookie 可以认为是一个「变量」，形如 name=value，存储在浏览器；一个 session 可以理解为一种数据结构，多数情况是「映射」（键值对），存储在服务器上。

---

## 25、Cookie有什么用途？

*   会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息）
*   个性化设置（如用户自定义设置、主题等）
*   浏览器行为跟踪（如跟踪分析用户行为等）

---

## 26、Session 知识大总结

除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全

Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。

使用 Session 维护用户登录状态的过程如下：

1.  用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
2.  服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
3.  服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；
4.  客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。

> 注意：Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式

---

## 27、Session 的工作原理是什么？

session 的工作原理是客户端登录完成之后，服务器会创建对应的 session，session 创建完之后，会把 Session ID 发送给客户端，客户端再存储到浏览器中。这样客户端每次访问服务器时，都会带着 Session ID，服务器拿到 Session ID 之后，在内存找到与之对应的 session 这样就可以正常工作了。

---

## 28、Cookie与Session的对比

HTTP作为无状态协议，必然需要在某种方式保持连接状态。这里简要介绍一下 Cookie 和 Session

- **Cookie**
    
**Cookie是客户端保持状态的方法**
    
Cookie简单的理解就是存储由服务器发至客户端并由客户端保存的一段字符串。为了保持会话，服务器可以在响应客户端请求时将 Cookie 字符串放在 Set-Cookie 下，客户机收到Cookie之后保存这段字符串，之后再请求时候带上Cookie就可以被识别
    
除了上面提到的这些，Cookie在客户端的保存形式可以有两种，**一种是会话 Cookie 一种是持久Cookie，会话Cookie 就是将服务器返回的 Cookie 字符串保持在内存中，关闭浏览器之后自动销毁，持久 Cookie 则是存储在客户端磁盘上，其有效时间在服务器响应头中被指定**，在有效期内，客户端再次请求服务器时都可以直接从本地取出。需要说明的是，**存储在磁盘中的 Cookie 是可以被多个浏览器代理所共享的**
    
- **Session**
    
**Session是服务器保持状态的方法**
    
首先需要明确的是，Session保存在服务器上，可以保存在数据库、文件或内存中，每个Session文件中记录了用户的操作。我们可以理解为每个用户有一个独一无二的 Session ID 作为 Session文件的 Hash键，通过这个值可以锁定具体的Session结构的数据，这个Session结构中存储了用户操作行为。
    

**当服务器需要识别客户端时就需要结合 Cookie**。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是用Cookie来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在Cookie里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。**如果客户端的浏览器禁用了Cookie，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxx 这样的参数，服务端据此来识别用户，这样就可以帮用户完成诸如用户名等信息自动填入的操作了**

---

## 29、SQL注入攻击了解吗？

SQL注入攻击是一种常见的网络安全漏洞，它利用应用程序对用户输入数据的处理不当，导致恶意用户可以在应用程序的输入字段中插入恶意的SQL代码。当应用程序对这些恶意的SQL代码进行执行时，攻击者可以执行未经授权的数据库操作，获取敏感数据、修改数据，或者破坏数据库的完整性

SQL注入攻击的原理是：应用程序没有充分验证和过滤用户输入，导致恶意用户可以在输入字段中输入特殊字符或SQL关键字，从而改变应用程序原本预期的SQL查询语句，达到执行恶意SQL的目的

例如，一个简单的用户登录功能，假设登录的SQL查询如下：
```sql
SELECT * FROM users WHERE username='$username' AND password='$password';
```
如果应用程序没有对用户输入进行验证和过滤，攻击者可以在用户名和密码字段中输入类似以下的内容：用户名： `admin' --` 密码： `123456`。在这种情况下，SQL查询将变成：
```sql
SELECT * FROM users WHERE username='admin' -- ' AND password='123456';
```
在大多数数据库中，-- 表示注释，后面的内容将被忽略。这样，攻击者可以绕过密码验证，成功登录为管理员身份

**如何防范SQL注入攻击？**

- Web端 
  
1）有效性检验：对用户输入的数据进行有效性检验，包括验证输入是否符合预期的格式和范围。例如，对于用户名和密码，可以限制输入的长度和字符集，确保它们不包含特殊字符
2）限制字符串输入的长度：限制用户输入的字符串长度，以防止恶意用户输入过长的字符串导致溢出或拒绝服务

- 服务端 

1）使用参数化查询：不用拼接SQL字符串：避免将用户输入直接拼接到SQL查询中；而是使用参数化查询，将用户输入作为参数传递给查询。这样可以防止SQL注入攻击
2）使用预编译的 PrepareStatement：预编译的 PrepareStatement 可以将 SQL 查询和用户输入分开处理，防止恶意用户的输入影响到SQL查询语句
3）有效性检验：就像在 Web 端一样，服务端也需要对用户输入的数据进行有效性检验，以确保输入符合预期格式和范围 (为什么服务端还要做有效性检验？第一准则，外部都是不可信的，防止攻击者绕过Web端请求) 
4）过滤SQL需要的参数中的特殊字符。比如单引号、双引号

---

## 30、网络的七层模型与各自的功能（图片版）

![](http://oss.interviewguide.cn/img/202205072300304.png)

![](http://oss.interviewguide.cn/img/202205072300887.png)

---

## 31、什么是RARP？工作原理

**反向地址转换协议 (Reverse Address Resolution Protocol，RARP)是一个网络层协议**，与地址解析协议（ARP）的工作方式相反, 它允许只知道自己硬件地址（MAC地址）的主机能够通过网络找到自己的IP地址

在一个局域网中，每个主机都有一个唯一的MAC地址和IP地址。当一个主机启动时，它通常只知道自己的MAC地址，但不知道自己的IP地址。为了获得自己的IP地址，主机可以使用RARP协议。RARP的工作方式如下：

(1) 主机从网卡上读取MAC地址，广播一个RARP请求帧，其中包含自己的MAC地址，请求RARP服务器回复该主机的IP地址。

(2) RARP服务器收到了RARP请求数据包，为其分配IP地址，并将其封装在一个RARP应答帧中

(3) RARP服务器向请求的主机单播发送RARP应答帧，应答帧中包含主机所需的IP地址

(4) 主机接收到RARP应答帧后，就知道了自己的IP地址，可以开始正常地进行网络通信

---

## 32、端口有效范围是多少到多少？

16位 (0-65535), 0-1023为知名端口号，比如其中 HTTP 是 80，FTP是 20（数据端口）、21（控制端口）

UDP 和 TCP 报头使用两个字节存放端口号，动态端口的范围是从1024到65535

---

## 33、为何需要把 TCP/IP 协议栈分成 5 层（或7层）？开放式回答。

ARPANET 的研制经验表明，**对于复杂的计算机网络协议，其结构应该是层次式的**

分层的好处：

① 各层之间是独立的

② 灵活性好

③ 结构上可以分隔开

④ 易于实现和维护

⑤ 能促进标准化工作

---

## 34、DNS查询方式有哪些？

![](http://oss.interviewguide.cn/img/202205220036692.png)

- **递归解析**

当局部DNS服务器自己不能回答客户机的DNS查询时，它就需要向其他DNS服务器进行查询。此时有两种方式。**局部DNS服务器自己负责向其他DNS服务器进行查询，一般是先向该域名的根域服务器查询，再由根域名服务器一级级向下查询**。最后得到的查询结果返回给局部DNS服务器，再由局部DNS服务器返回给客户端。

- **迭代解析**

当局部DNS服务器自己不能回答客户机的DNS查询时，也可以通过迭代查询的方式进行解析。局部DNS服务器不是自己向其他DNS服务器进行查询，**而是把能解析该域名的其他DNS服务器的IP地址返回给客户端DNS程序**，客户端DNS程序再继续向这些DNS服务器进行查询，直到得到查询结果为止。也就是说，迭代解析只是帮你找到相关的服务器而已，而不会帮你去查。比如说：baidu.com的服务器ip地址在192.168.4.5这里，你自己去查吧，本人比较忙，只能帮你到这里了。

---

## 35、HTTP中缓存的私有和公有字段？知道吗？

private 指令规定了将资源作为私有缓存，只能被单独用户使用，一般存储在用户浏览器中

> Cache-Control: private
    
public 指令规定了将资源作为公共缓存，可以被多个用户使用，一般存储在代理服务器中

> Cache-Control: public
    
---

## 36、GET 方法参数写法是固定的吗？

**在约定中，我们的参数是写在 ? 后面，用 & 分割**

我们知道，解析报文的过程是通过获取 TCP 数据，用正则等工具从数据中获取 Header 和 Body，从而提取参数。

比如header请求头中添加token，来验证用户是否登录等权限问题。

也就是说，我们可以自己约定参数的写法，只要服务端能够解释出来就行，万变不离其宗。

---

## 37、GET 方法的长度限制是怎么回事？

GET方法的长度限制是指在HTTP请求中使用GET方法时，所能发送的URL长度的限制。网络上都会提到浏览器地址栏输入的参数是有限的。

首先说明一点，HTTP 协议没有 Body 和 URL 的长度限制，对 URL 限制的大多是浏览器和服务器的原因。

浏览器原因就不说了，服务器是因为处理长 URL 要消耗比较多的资源，为了性能和安全（防止恶意构造长 URL 来攻击）考虑，会给 URL 长度加限制

对于超过URL长度限制的请求，不同浏览器和服务器的处理方式可能不同。一些浏览器可能会截断过长的URL，而一些服务器可能会拒绝处理过长的URL请求

---

## 38、POST 方法比 GET 方法安全？

有人说POST 比 GET 安全，因为数据在地址栏上不可见。

然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。

要想安全传输，就只有加密，也就是 HTTPS

---

## 39、POST 方法会产生两个 TCP 数据包？你了解吗？

有些文章中提到，POST 会将 header 和 body 分开发送，先发送 header，服务端返回 100 状态码再发送 body。

HTTP 协议中没有明确说明 POST 会产生两个 TCP 数据包，而且实际测试(Chrome)发现，header 和 body 不会分开发送。

所以，header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。

---

## 40、Session是什么？

除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。

Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。

---

## 41、使用 Session 的过程是怎样的？

过程如下：

*   用户进行登录时，用户提交包含用户名和密码的表单，放入 HTTP 请求报文中；
*   服务器验证该用户名和密码，如果正确则把用户信息存储到 Redis 中，它在 Redis 中的 Key 称为 Session ID；
*   服务器返回的响应报文的 Set-Cookie 首部字段包含了这个 Session ID，客户端收到响应报文之后将该 Cookie 值存入浏览器中；
*   客户端之后对同一个服务器进行请求时会包含该 Cookie 值，服务器收到之后提取出 Session ID，从 Redis 中取出用户信息，继续之前的业务操作。

**注意**：Session ID 的安全性问题，不能让它被恶意攻击者轻易获取，那么就不能产生一个容易被猜到的 Session ID 值。此外，还需要经常重新生成 Session ID。在对安全性要求极高的场景下，例如转账等操作，除了使用 Session 管理用户状态之外，还需要对用户进行重新验证，比如重新输入密码，或者使用短信验证码等方式。

---

## 42、Session和cookie应该如何去选择（适用场景）？

*   Cookie 只能存储 ASCII 码字符串，而 Session 则可以存储任何类型的数据，因此在考虑数据复杂性时首选 Session；
*   Cookie 存储在浏览器中，容易被恶意查看。如果非要将一些隐私数据存在 Cookie 中，可以将 Cookie 值进行加密，然后在服务器进行解密；
*   对于大型网站，如果用户所有的信息都存储在 Session 中，那么开销是非常大的，因此不建议将所有的用户信息都存储到 Session 中。

---

## 43、Cookies和Session区别是什么？

Cookie和Session都是客户端与服务器之间保持状态的解决方案。但它们有以下区别：

**1，存储的位置不同**

cookie：存放在客户端; session：存放在服务端。Session存储的数据比较安全 

**2，存储的数据类型不同**

两者都是key-value的结构，但针对value的类型是有差异的 
cookie：value只能是字符串类型，
session：value可以是Object类型，因为数据存储在服务器端，不受浏览器限制

**3，存储的数据大小限制不同** 

cookie：大小受浏览器的限制，很多是是4K的大小， 
session：理论上受服务器内存的限制，可以存储更多的数据。 

**4，生命周期的控制** 

cookie：可以设置一个过期时间，可以在浏览器关闭后仍然保留（持久性Cookies）或在浏览器关闭后自动删除（会话性Cookies）
Session：会话性的，它的生命周期通常由用户会话控制。当用户关闭浏览器或超过一段时间没有活动时，会话会过期，服务器会清除Session数据

总的来说，Cookies 和 Session 都是用于在客户端与服务器之间传递和保持状态信息的方法。Cookies存储在客户端，可以设置生命周期，适合在客户端存储少量的信息；而Session存储在服务端，可以存储更多的信息，生命周期由服务器控制，适合保持较大的状态信息。根据实际需求和数据大小，选择合适的方案来保持状态信息

---

## 44、DDos 攻击了解吗？

DDoS（分布式拒绝服务）攻击是一种恶意行为，攻击者通过向目标服务器发送大量的请求或数据包，使服务器无法正常处理合法请求，从而导致服务不可用。

如客户端向服务端发送请求链接数据包，服务端向客户端发送确认数据包，客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认（TCP SYN Flood攻击） 没有彻底根治的办法，除非不使用TCP 

DDos 预防： 
1）限制半连接数和缩短超时时间：可以限制同时打开的SYN半链接数和缩短SYN半链接的Time out 时间来减轻 SYN Flood 攻击的影响
2）关闭不必要的服务
3）流量限制： 可以设置流量限制来限制单个IP地址或IP地址段发送的请求数量，从而减缓攻击流量
4）增加防火墙规则： 可以使用防火墙来过滤恶意流量，拦截来自已知攻击来源的数据包
5）增加防火墙规则： 可以使用防火墙来过滤恶意流量，拦截来自已知攻击来源的数据包

---

## 45、MTU 和 MSS 分别是什么？

MTU：maximum transmission unit，最大传输单元，由硬件规定，如以太网的 MTU 为 1500 字节

MSS：maximum segment size，最大分节大小，为TCP数据包每次传输的最大数据分段大小，一般由发送端向对端TCP通知对端在每个分节中能发送的最大TCP数据。MSS值为MTU值减去IPv4 Header（20 Byte）和TCP header（20 Byte）得到

---

## 46、HTTP中有个缓存机制，但如何保证缓存是最新的呢？（缓存过期机制）

缓存过期机制是 HTTP 中常用的一种方式，通过设置 `max-age` 和 `Expires` 字段来告知缓存服务器缓存资源的有效期限。具体来说：

`max-age` 指令： `max-age` 出现在响应报文的 `Cache-Control` 字段中，表示缓存资源在缓存服务器中保存的时间，单位为秒。例如，`"Cache-Control: max-age = 31536000"` 表示该资源在缓存服务器中被保存一年的时间。在HTTP/1.1中，max-age指令优先处理，即使在HTTP/1.0中也会被遵循。

`Expires` 字段： `Expires` 出现在响应报文的 `Expires` 字段中，表示缓存资源的过期时间。它是一个绝对时间，表示资源在何时会过期。例如，`"Expires: Wed, 04 Jul 2012 08:26:05 GMT"` 表示该资源在指定的时间过期。在 HTTP/1.1中，`max-age` 指令优先处理，但 `Expires` 字段仍然被支持，但如果同时出现，`max-age` 优先。

通过设置这些字段，缓存服务器可以知道资源的有效期限，**当请求再次到达时 (请求报文)，缓存服务器会检查是否在有效期内。如果缓存资源的缓存时间小于 `max-age` 指定的时间或者未过期（Expires字段所表示的时间在当前时间之后），缓存服务器就可以直接返回缓存的资源，避免再次向原始服务器请求资源，提高了请求的响应速度和减轻了服务器的负担**

---

## 47、TCP头部中有哪些信息？

*   序号（32bit）：传输方向上字节流的字节编号。初始时序号会被设置一个随机的初始值（ISN），之后每次发送数据时，序号值 = ISN + 数据在整个字节流中的偏移。假设A -> B且ISN = 1024，第一段数据512字节已经到B，则第二段数据发送时序号为1024 + 512。用于解决网络包乱序问题。
    
*   确认号（32bit）：接收方对发送方TCP报文段的响应，其值是收到的序号值 + 1。
    
*   首部长（4bit）：标识首部有多少个4字节 * 首部长，最大为15，即60字节。
    
*   标志位（6bit）：
    
    *   URG：标志紧急指针是否有效。
        
    *   ACK：标志确认号是否有效（确认报文段）。用于解决丢包问题。
        
    *   PSH：提示接收端立即从缓冲读走数据。
        
    *   RST：表示要求对方重新建立连接（复位报文段）。
        
    *   SYN：表示请求建立一个连接（连接报文段）。
        
    *   FIN：表示关闭连接（断开报文段）。
        
*   窗口（16bit）：接收窗口。用于告知对方（发送方）本方的缓冲还能接收多少字节数据。用于解决流控。
    
*   校验和（16bit）：接收端用CRC检验整个报文段有无损坏。

---

## 48、常见TCP的连接状态有哪些？

*   `CLOSED`：初始状态。
*   `LISTEN`：服务器处于监听状态。
*   `SYN_SEND`：客户端socket执行CONNECT连接，发送SYN包，进入此状态。
*   `SYN_RECV`：服务端收到SYN包并发送服务端SYN包，进入此状态。
*   `ESTABLISH`：表示连接建立。客户端发送了最后一个ACK包后进入此状态，服务端接收到ACK包后进入此状态。
*   `FIN_WAIT_1`：终止连接的一方（通常是客户机）发送了FIN报文后进入。等待对方FIN。
*   `CLOSE_WAIT`：（假设服务器）接收到客户机FIN包之后等待关闭的阶段。在接收到对方的FIN包之后，自然是需要立即回复ACK包的，表示已经知道断开请求。但是本方是否立即断开连接（发送FIN包）取决于是否还有数据需要发送给客户端，若有，则在发送FIN包之前均为此状态。
*   `FIN_WAIT_2`：此时是半连接状态，即有一方要求关闭连接，等待另一方关闭。客户端接收到服务器的ACK包，但并没有立即接收到服务端的FIN包，进入FIN_WAIT_2状态。
*   `LAST_ACK`：服务端发动最后的FIN包，等待最后的客户端ACK响应，进入此状态。
*   `TIME_WAIT`：客户端收到服务端的FIN包，并立即发出ACK包做最后的确认，在此之后的2MSL时间称为TIME_WAIT状态。

![](https://github.com/casey-li/Notes/blob/main/webserver/pic/%E7%AC%AC%E5%9B%9B%E7%AB%A0%E3%80%81Linux%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/TCP%E7%8A%B6%E6%80%81%E8%BD%AC%E5%8F%98.png?raw=true)

---

## 49、网络的七层/五层模型主要的协议有哪些？

![](http://oss.interviewguide.cn/img/202205072300758.png)

---

## 50、TCP是什么？

TCP（Transmission Control Protocol 传输控制协议）是一种**面向连接的、可靠的、基于字节流**的传输层通信协议。

---

## 51、TCP头部报文字段介绍几个？各自的功能？

source port 和 destination port

> 两者分别为「源端口号」和「目的端口号」。源端口号就是指本地端口，目的端口就是远程端口。

可以这么理解，我们有很多软件，每个软件都对应一个端口，假如，你想和我数据交互，咱们得互相知道你我的端口号。

再来一个很官方的：

> 扩展：应用程序的端口号和应用程序所在主机的 IP 地址统称为 socket（套接字），IP:端口号, 在互联网上 socket 唯一标识每一个应用程序，源端口+源IP+目的端口+目的IP称为 套接字对，一对套接字就是一个连接，一个客户端与服务器之间的连接。

Sequence Number

> 称为「序列号」。用于 TCP 通信过程中某一传输方向上字节流的每个字节的编号，为了确保数据通信的有序性，避免网络中乱序的问题。接收端根据这个编号进行确认，保证分割的数据段在原始数据包的位置。初始序列号由自己定，而后绪的序列号由对端的 ACK 决定：SN_x = ACK_y (x 的序列号 = y 发给 x 的 ACK)。

说白了，类似于身份证一样，而且还得发送此时此刻的所在的位置，就相当于身份证上的地址一样。

Acknowledge Number

> 称为「确认序列号」。确认序列号是接收确认端所**期望收到的下一序列号**。确认序号应当是上次已成功收到数据字节序号加1，只有当标志位中的 ACK 标志为 1 时该确认序列号的字段才有效。主要用来解决不丢包的问题。

TCP Flag

`TCP` 首部中有 6 个标志比特，它们中的多个可同时被设置为 `1`，主要是用于操控 `TCP` 的状态机的，依次为`URG，ACK，PSH，RST，SYN，FIN`。

当然只介绍三个：

1.  **ACK**：这个标识可以理解为发送端发送数据到接收端，发送的时候 ACK 为 0，标识接收端还未应答，一旦接收端接收数据之后，就将 ACK 置为 1，发送端接收到之后，就知道了接收端已经接收了数据。
   
2.  **SYN**：表示「同步序列号」，是 TCP 握手的发送的第一个数据包。用来建立 TCP 的连接。SYN 标志位和 ACK 标志位搭配使用，当连接请求的时候，SYN=1，ACK=0连接被响应的时候，SYN=1，ACK=1；这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有 SYN 的数据包，如果对方主机响应了一个数据包回来 ，就表明这台主机存在这个端口。
   
3.  **FIN**：表示发送端已经达到数据末尾，也就是说双方的数据传送完成，没有数据可以传送了，发送FIN标志位的 TCP 数据包后，连接将被断开。这个标志的数据包也经常被用于进行端口扫描。发送端只剩最后的一段数据了，同时要告诉接收端后边没有数据可以接受了，所以用FIN标识一下，接收端看到这个FIN之后，哦！这是接受的最后的数据，接受完就关闭了；**TCP四次分手必然问**

Window size

> 称为滑动窗口大小。所说的滑动窗口，用来进行流量控制。

---

## 52、OSI 的七层模型的主要功能？

![](http://oss.interviewguide.cn/img/202205072300329.png)

- **物理层**：利用传输介质为数据链路层提供物理连接，实现比特流的透明传输

- **数据链路层**：接收来自物理层的位流形式的数据，并封装成帧，传送到上一层
 
- **网络层**：将网络地址翻译成对应的物理地址，并通过路由选择算法为分组通过通信子网选择最适当的路径。

- **传输层**：在源端与目的端之间提供可靠的透明数据传输 

- **会话层**：负责在网络中的两节点之间建立、维持和终止通信 

- **表示层**：处理用户信息的表示问题，数据的编码，压缩和解压缩，数据的加密和解密 

- **应用层**：为用户的应用进程提供网络通信服务

---

## 53、应用层常见协议知道多少？了解几个？

|协议|名称|默认端口|底层协议|
|---|---|---|---|
|HTTP|超文本传输协议|80|TCP|
|HTTPS|超文本传输安全协议|443|TCP|
|Telnet|远程登录服务的标准协议|23|TCP|
|FTP|文件传输协议|20传输和21连接|TCP|
|TFTP|简单文件传输协议|69|UDP|
|SMTP|简单邮件传输协议（发送用）|25|TCP|
|POP|邮局协议（接收用）|110|TCP|
|DNS|域名解析服务|53|服务器间进行域传输的时候用TCP, 客户端查询DNS服务器时用 UDP|

---

## 54、浏览器在与服务器建立了一个 TCP 连接后是否会在一个 HTTP 请求完成后断开？什么情况下会断开？

在 HTTP/1.0 中，一个服务器在发送完一个 HTTP 响应后，会断开 TCP 链接。但是这样每次请求都会重新建立和断开 TCP 连接，代价过大。所以虽然标准中没有设定，**某些服务器对 `Connection: keep-alive` 的 Header 进行了支持**。意思是说，完成这个 HTTP 请求之后，不要断开 HTTP 请求使用的 TCP 连接。这样的好处是连接可以被重新使用，之后发送 HTTP 请求的时候不需要重新建立 TCP 连接，以及如果维持连接，那么 SSL 的开销也可以避免。

**持久连接**：既然维持 TCP 连接好处这么多，HTTP/1.1 就把 Connection 头写进标准，并且**默认开启持久连接**，除非请求中写明 `Connection: close`，那么浏览器和服务器之间是会维持一段时间的 TCP 连接，不会一个请求结束就断掉。

默认情况下建立 TCP 连接不会断开，只有在请求报头中声明 `Connection: close` 才会在请求完成后关闭连接。

---

## 55、三次握手相关内容

![](http://oss.interviewguide.cn/img/202205072301822.png)

三次握手（Three-way Handshake）其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。**进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备**。实质上其实就是连接服务器指定端口，建立TCP连接，并同步连接双方的序列号和确认号，交换`TCP窗口大小`信息。

- **第一种回答**

刚开始客户端处于 Closed 的状态，服务端处于 Listen 状态，进行三次握手：

*   第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN(c)。此时客户端处于 `SYN_SEND` 状态。
    
> 首部的同步位SYN=1，初始序号seq=x，SYN=1的报文段**不能携带数据，但要消耗掉一个序号**
    
*   第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)。同时会把客户端的 ISN + 1 作为ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 `SYN_RCVD` 的状态。
    
> 在确认报文段中SYN=1，ACK=1，确认号ack=x+1，初始序号seq=y。
    
*   第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 `ESTABLISHED` 状态。服务器收到 ACK 报文之后，也处于 `ESTABLISHED` 状态，此时，双方已建立起了连接。
    
> 确认报文段ACK=1，确认号ack=y+1，序号seq=x+1（初始为seq=x，第二个报文段所以要+1），**ACK报文段可以携带数据，不携带数据则不消耗序号**
    

发送第一个SYN的一端将执行主动打开（active open），接收这个SYN并发回下一个SYN的另一端执行被动打开（passive open）。

**在socket编程中，客户端执行connect()时，将触发三次握手**

- **第二种回答**

*   **初始状态**：客户端处于 `closed(关闭)`状态，服务器处于 `listen(监听)` 状态。
*   **第一次握手**：客户端发送请求报文将 `SYN = 1`同步序列号和初始化序列号`seq = x`发送给服务端，发送完之后客户端处于`SYN_Send`状态。（验证了客户端的发送能力和服务端的接收能力）
*   **第二次握手**：服务端受到 `SYN` 请求报文之后，如果同意连接，会以自己的同步序列号`SYN(服务端) = 1`、初始化序列号 `seq = y`和确认序列号（期望下次收到的数据包）`ack = x+ 1` 以及确认号`ACK = 1`报文作为应答，服务器为`SYN_Receive`状态。（问题来了，两次握手之后，站在客户端角度上思考：我发送和接收都ok，服务端的发送和接收也都ok。但是站在服务端的角度思考：哎呀，我服务端接收ok，但是我不清楚我的发送ok不ok呀，而且我还不知道你接受能力如何呢？所以老哥，你需要给我三次握手来传个话告诉我一声。你要是不告诉我，万一我认为你跑了，然后我可能出于安全性的考虑继续给你发一次，看看你回不回我。）
*   **第三次握手**： 客户端接收到服务端的 `SYN + ACK`之后，知道可以下次可以发送了下一序列的数据包了，然后发送同步序列号 `ack = y + 1`和数据包的序列号 `seq = x + 1`以及确认号`ACK = 1`确认包作为应答，客户端转为`established`状态。（分别站在双方的角度上思考，各自ok）

---

## 56、为什么需要三次握手，两次不行吗？

弄清这个问题，我们需要先弄明白三次握手的目的是什么，能不能只用两次握手来达到同样的目的。**进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备**

*   第一次握手：客户端发送网络包，服务端收到了。 这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。

*   第二次握手：服务端发包，客户端收到了。 这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认自己的发送能力和客户端的接收能力是否正常
  
*   第三次握手：客户端发包，服务端收到了。 这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。

因此，需要三次握手才能确认双方的接收与发送能力是否正常。

试想如果是用两次握手，则会出现下面这种情况：

> 如客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在**某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端**，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一致等待客户端发送数据，浪费资源。

---

## 57、什么是半连接队列？

服务器第一次收到客户端的 SYN 之后，就会处于 `SYN_RCVD` 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个**队列**里，我们把这种队列称之为**半连接队列**。

当然还有一个**全连接队列**，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。

这里再补充一点关于**SYN-ACK 重传次数**的问题： 服务器发送完SYN-ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传。如果重传次数超过系统规定的最大重传次数，系统将该连接信息从半连接队列中删除。 注意，每次重传等待的时间不一定相同，一般会是指数增长，例如间隔时间为 1s，2s，4s，8s......

---

## 58、 ISN(Initial Sequence Number)是固定的吗？

当一端为建立连接而发送它的SYN时，它为连接选择一个初始序号。ISN 随时间而变化，因此每个连接都将具有不同的ISN，ISN是一个有可以看作是一个32比特的计数器，但并不是简单的计数器，大概每4ms加1 。

> ISN = M + F(localhost, localport, remotehost, remoteport)(M为计数器)，ISN应该由这个公式确定，F为哈希算法，不是一个简单计数器。

这样选择序号的目的在于**防止在网络中被延迟的分组在以后又被传送，而导致某个连接的一方对它做错误的解释**

**三次握手的其中一个重要功能是客户端和服务端交换 ISN(Initial Sequence Number)，以便让对方知道接下来接收数据的时候如何按序列号组装数据。如果 ISN 是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的**

---

## 59、 三次握手过程中可以携带数据吗？

其实第三次握手的时候，是可以携带数据的。但是，**第一次、第二次握手不可以携带数据**, 只要确认了双方的收发能力均正常就可以携带数据

为什么这样呢?大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据。因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。

也就是说，**第一次握手不可以放数据，其中一个简单的原因就是会让服务器更加容易受到攻击了。而对于第三次的话，此时客户端已经处于 ESTABLISHED 状态。对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据也没啥毛病。**

---

## 60、SYN攻击是什么？

**服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的**，所以服务器容易受到SYN洪泛攻击。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。

检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。在 Linux/Unix 上可以使用系统自带的 netstats 命令来检测 SYN 攻击。

> netstat -n -p TCP | grep SYN_RECV

常见的防御 SYN 攻击的方法有如下几种：

*   缩短超时（SYN Timeout）时间
*   增加最大半连接数
*   过滤网关防护
*   SYN cookies技术

---

## 61、 四次挥手相关内容

![](http://oss.interviewguide.cn/img/202205220036404.png)

建立一个连接需要三次握手，而终止一个连接要经过四次挥手（也有将四次挥手叫做四次握手的）。这由TCP的**半关闭**（half-close）造成的。所谓的半关闭，其实就是TCP提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力

TCP 的连接的拆除需要发送四个包，因此称为四次挥手(Four-way handshake)，客户端或服务器均可主动发起挥手动作

- **第一种回答**

刚开始双方都处于 ESTABLISHED 状态，假如是客户端先发起关闭请求。四次挥手的过程如下：

*   第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于 `FIN_WAIT1` 状态。 即发出**连接释放报文段**（FIN=1，序号seq=u），并停止再发送数据，主动关闭TCP连接，进入`FIN_WAIT1`（终止等待1）状态，等待服务端的确认

*   第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 +1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 `CLOSE_WAIT` 状态。 即服务端收到连接释放报文段后即发出**确认报文段**（ACK=1，确认号ack=u+1，序号seq=v），服务端进入`CLOSE_WAIT`（关闭等待）状态，**此时的TCP处于半关闭状态，客户端到服务端的连接释放**。客户端收到服务端的确认后，进入`FIN_WAIT2`（终止等待2）状态，等待服务端发出的连接释放报文段

*   第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 `LAST_ACK` 的状态。 即服务端没有要向客户端发出的数据，服务端发出**连接释放报文段**（FIN=1，ACK=1，序号seq=w，确认号ack=u+1），服务端进入`LAST_ACK`（最后确认）状态，等待客户端的确认

*   第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 +1 作为自己 ACK 报文的确认号值，此时客户端处于 `TIME_WAIT` 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态，服务端收到 ACK 报文之后，就处于关闭连接了，处于 `CLOSED` 状态。 即客户端收到服务端的连接释放报文段后，对此发出**确认报文段**（ACK=1，seq=u+1，ack=w+1），客户端进入`TIME_WAIT`（时间等待）状态。**此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL后，客户端才进入CLOSED状态**

收到一个FIN只意味着在这一方向上没有数据流动。**客户端执行主动关闭并进入`TIME_WAIT` 是正常的，服务端通常执行被动关闭，不会进入 `TIME_WAIT` 状态。**

**在socket编程中，任何一方执行close()操作即可产生挥手操作**

**FIN 报文同 SYN 报文一样需要消耗一个序号**

- **第二种回答**

*   **初始化状态**：客户端和服务端都在连接状态，接下来开始进行四次挥手断开连接操作。
*   **第一次挥手**：第一次挥手无论是客户端还是服务端都可以发起，因为 TCP 是全双工的。

> 假如客户端发送的数据已经发送完毕，发送FIN = 1 **告诉服务端，客户端所有数据已经全发完了，服务端你可以关闭接收了**，但是如果你们服务端有数据要发给客户端，客户端照样可以接收的。此时客户端处于 `FIN_WAIT_1` 等待服务端确认释放连接状态

*   **第二次挥手**：服务端接收到客户端的释放请求连接之后，**知道客户端没有数据要发给自己了，然后服务端发送ACK = 1告诉客户端收到你发给我的信息**，此时服务端处于 `CLOSE_WAIT` 等待关闭状态。（服务端先回应给客户端一声，我知道了，但服务端的发送数据能力即将等待关闭，于是接下来第三次就来了）
  
*   **第三次挥手**：此时服务端向客户端把所有的数据发送完了，然后发送一个FIN = 1，**用于告诉客户端，服务端的所有数据发送完毕，客户端你也可以关闭接收数据连接了**。此时服务端状态处于 `LAST_ACK` 状态，来等待确认客户端是否收到了自己的请求。（服务端等客户端回复是否收到呢，不收到的话，服务端不知道客户端是不是挂掉了还是咋回事呢，所以服务端不敢关闭自己的接收能力，于是第四次就来了）
  
*   **第四次挥手**：此时如果客户端收到了服务端发送完的信息之后，就发送ACK = 1，告诉服务端，客户端已经收到了你的信息。**有一个 2 MSL 的延迟等待**。

---

## 62、挥手为什么需要四次？

- **第一种回答**

因为当服务端收到客户端的SYN连接请求报文后，可以**直接发送SYN+ACK报文**。其中**ACK报文是用来应答的，SYN报文是用来同步的**。但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，"你发的FIN报文我收到了"。只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手。

- **第二种回答**

任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。

---

## 63、2MSL等待状态？

`TIME_WAIT` 状态也称为 2MSL 等待状态。每个具体TCP实现必须选择一个报文段最大生存时间 MSL（Maximum Segment Lifetime），**它是任何报文段被丢弃前在网络内的最长时间**。这个时间是有限的，因为TCP报文段以IP数据报在网络内传输，而IP数据报则有限制其生存时间的TTL字段

对一个具体实现所给定的MSL值，处理的原则是：**当TCP执行一个主动关闭，并发回最后一个ACK，该连接必须在 `TIME_WAIT` 状态停留的时间为2倍的MSL。这样可让TCP再次发送最后的ACK以防这个ACK丢失（另一端超时并重发最后的FIN）**

这种 2MSL 等待的另一个结果是这个 TCP 连接在 2MSL 等待期间，定义这个连接的插口（客户的IP地址和端口号，服务器的IP地址和端口号）不能再被使用。这个连接只能在2MSL结束后才能再被使用

---

## 64、四次挥手释放连接时，等待2MSL的意义?

> **MSL**是Maximum Segment Lifetime的英文缩写，可译为“最长报文段寿命”，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

为了保证客户端发送的最后一个ACK报文段能够到达服务器。因为这个ACK有可能丢失，从而导致处在LAST-ACK状态的服务器收不到对FIN-ACK的确认报文。服务器会超时重传这个FIN-ACK，接着客户端再重传一次确认，重新启动时间等待计时器。最后客户端和服务器都能正常的关闭。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭连接状态。

当客户端发送最后一个ACK报文段后，连接处于TIME_WAIT状态，并等待2MSL时间。这样做的原因有以下几点

1.  **确保对方接收到最后一个ACK**：发送的最后一个ACK报文段有可能丢失，使得处于 `LAST_ACK` 状态的B收不到对已发送的FIN+ACK报文段的确认，服务端超时重传FIN+ACK报文段，而客户端能在2MSL时间内收到这个重传的FIN+ACK报文段，接着客户端重传一次确认，重新启动2MSL计时器，最后客户端和服务端都进入到CLOSED状态，若客户端在TIME-WAIT状态不等待一段时间，而是发送完ACK报文段后立即释放连接，则无法收到服务端重传的FIN+ACK报文段，所以不会再发送一次确认报文段，则服务端无法正常进入到CLOSED状态
  
2.  **防止旧连接报文干扰**：客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段
   
3.  **确保端口复用**： 等待2MSL时间可以确保在该连接关闭后的一段时间内，该端口不会被其他新连接复用。这可以防止新连接接收到之前连接的遗留数据

---

## 65、为什么TIME_WAIT状态需要经过2MSL才能返回到CLOSE状态？

- **第一种回答**

理论上，四个报文都发送完毕，就可以直接进入CLOSE状态了，但是**可能网络是不可靠的**，有可能最后一个ACK丢失。所以**TIME_WAIT状态就是用来重发可能丢失的ACK报文**

- **第二种回答**

对应这样一种情况，最后客户端发送的ACK = 1给服务端的**过程中丢失**了，服务端没收到，服务端怎么认为的？我已经发送完数据了，怎么客户端没回应我？是不是中途丢失了？然后服务端再次发起断开连接的请求，一个来回就是2MSL。

客户端给服务端发送的ACK = 1丢失，**服务端等待 1MSL没收到，然后重新发送消息需要1MSL**。如果再次接收到服务端的消息，则**重启2MSL计时器，发送确认请求**。客户端只需等待2MSL，如果没有再次收到服务端的消息，就说明服务端已经接收到自己确认消息；此时双方都关闭的连接，TCP 四次分手完毕

---

## 66、TCP粘包问题是什么？你会如何去解决它？

**TCP粘包**是指在TCP协议中，发送方发送的若干个数据包在接收方接收时被粘合成一个大的数据包，从接收缓冲区的角度来看，后一个数据包的头紧接着前一个数据包的尾部，导致数据的解析和处理出现混乱或错误

**TCP粘包问题通常由以下几个原因造成：**

- **Nagle算法**： TCP默认启用了Nagle算法，该算法的目的是为了减少小数据包的发送，提高网络传输效率。Nagle算法会将多个小的数据块合并成一个较大的数据包进行发送，从而导致多个数据包在接收方接收时被粘合在一起

- **数据包过大**： 如果发送的数据包过大，超过TCP的最大传输单元（MTU），则TCP会将大的数据包拆分成多个小的数据包进行传输，接收方可能会一次性接收到多个小的数据包，造成粘包

- **接收方不及时读取数据**： TCP是面向字节流的协议，接收方将接收到的数据放入接收缓冲区，如果接收方不及时读取数据，多个数据包就会在缓冲区中粘合在一起。

- **网络传输延迟**： 在高负载或拥塞的网络环境下，网络传输可能会出现延迟，导致多个数据包在接收方接收时连续到达
  
- **并发发送**： 如果在短时间内有多个数据包同时发送，由于TCP是基于字节流的协议，接收方可能无法及时分辨数据包的边界，导致粘包问题

**解决TCP粘包问题的方法有多种：**

- **消息边界标识**： 在传输的消息中加入特殊的标识符，如换行符、回车符等，用于表示消息的边界，接收方根据边界标识来切分消息。

- **消息长度标识**： 在TCP报文的头部加上表示消息长度的字段，接收方根据该字段的值来正确解析数据。

- **固定长度消息**： 应用层在发送数据时将数据按照固定长度进行切分和发送，接收方根据固定长度来正确处理数据。

- **关闭Nagle算法**： 如果应用场景对实时性要求较高，可以考虑关闭Nagle算法，让数据尽快发送，避免粘包问题。

- **应用层缓冲**： 在接收方使用应用层缓冲区，接收所有数据后再进行处理，以确保数据的完整性。

---

## 67、OSI七层模型中表示层和会话层功能是什么？

*   表示层：图像、视频编码解，数据加密。
    
*   会话层：建立会话，如 session 认证、断点续传。

---

## 68、三次握手四次挥手的变迁图

《TCP/IP详解 卷1:协议》有一张TCP状态变迁图，很具有代表性，有助于大家理解三次握手和四次挥手的状态变化。如下图所示，粗的实线箭头表示正常的客户端状态变迁，粗的虚线箭头表示正常的服务器状态变迁。

![](http://oss.interviewguide.cn/img/202205220036408.png)

---

## 69、对称密钥加密的优点缺点？

对称密钥加密（Symmetric-Key Encryption），加密和解密使用同一密钥。

**优点：**

- **高效快速**： 对称密钥加密算法运算速度通常较快，适合对大量数据进行加密和解密操作

- **资源消耗较低**： 由于算法简单，加密和解密的计算量相对较小，对系统资源的消耗较低

- **适用于大规模数据传输**： 由于高效快速的特性，对称密钥加密适用于大规模数据的传输和存储，比如加密文件、数据库等

- **可逆性**： 加密和解密使用相同的密钥，可以实现数据的可逆加密和解密

**缺点：**

- **密钥管理问题**： 对称密钥加密需要将密钥安全地传输给通信方，但密钥的传输和管理是一个挑战，特别是在分布式环境中

- **密钥分发困难**： 在密钥分发过程中，可能会遭受中间人攻击（Man-in-the-Middle Attack），导致密钥泄露或被篡改

- **密钥数量增长**： 在点对点通信场景中，每对通信方都需要一个独立的密钥，密钥的数量会随着通信方的增加而增加，密钥管理变得复杂

- **不适合公钥加密**： 对称密钥加密算法不适用于公钥加密，因为加密和解密使用相同的密钥，无法实现公钥的加密和私钥的解密

综上所述，对称密钥加密算法在一些特定的场景中表现优秀，但密钥管理和分发问题限制了它在一些其他场景中的应用。为了克服对称密钥加密的缺点，公钥加密算法（非对称密钥加密）被提出，并与对称密钥加密相结合形成了混合加密体系，从而更好地满足不同场景下的安全需求。

---

## 70、非对称密钥加密你了解吗？优缺点？

非对称密钥加密，又称公开密钥加密（Public-Key Encryption），加密和解密使用不同的密钥

公开密钥所有人都可以获得，**通信发送方获得接收方的公开密钥之后，就可以使用公开密钥进行加密，接收方收到通信内容后使用私有密钥解密**

非对称密钥除了用来加密，还可以用来进行签名。因为私有密钥无法被其他人获取，因此通信发送方使用其私有密钥进行签名，通信接收方使用发送方的公开密钥对签名进行解密，就能判断这个签名是否正确

**优点：**

- **安全性高**： 非对称密钥加密具有较高的安全性，因为加密和解密使用不同的密钥，私钥只有通信接收方拥有，公钥可以公开给所有人，不必担心密钥传输问题

- **密钥分发方便**： 通信接收方只需要将公钥公开给所有人即可，无需单独分发密钥，简化了密钥管理的问题

- **数字签名**： 非对称密钥加密不仅可以用于加密通信，还可以用于数字签名，用私钥进行签名，用公钥进行验签，实现数据的完整性和真实性验证

**缺点：**

- **运算速度慢**： 非对称密钥加密算法的运算速度相对较慢，特别是与对称密钥加密相比，会消耗更多的计算资源

- **密钥长度较长**： 为了保证足够的安全性，非对称密钥的长度通常较长，导致加密的数据量也会增大

- **不适合大规模数据加密**： 由于运算速度慢和密钥长度较长的特性，非对称密钥加密不适合对大规模数据进行加密，适用于少量关键信息的加密和数字签名

综上所述，非对称密钥加密算法在保证安全性和密钥分发方便方面具有优势，但由于运算速度慢和密钥长度较长的限制，其在大规模数据加密场景中不如对称密钥加密高效。因此，在实际应用中，通常会将非对称密钥加密与对称密钥加密相结合，形成混合加密体系，以兼顾安全性和效率。

---

## 71、HTTPS 是什么？

HTTPS 是一种用于安全通信的网络协议。它是在传输层上**对 HTTP 协议的加密和认证扩展（HTTPS 使用了隧道进行通信）**，通过使用 SSL/TLS（Secure Socket Layer/Transport Layer Security）协议来保护数据传输的安全性。HTTPS 具有了加密（防窃听）、认证（防伪装）和完整性保护（防篡改）

**在 HTTPS 中，客户端和服务器之间的通信会经过以下步骤：**

1. **客户端发起 HTTPS 请求**：客户端发送一个 HTTPS 请求给服务器，请求连接到服务器的安全端口，默认为443端口。

2. **服务器响应证书**：服务器收到请求后，会将自己的数字证书（包含公钥）发送给客户端。

3. **客户端验证证书**：客户端收到服务器的证书后，会验证证书的有效性。验证包括检查证书的颁发机构是否可信、证书是否在有效期内以及证书中的域名是否与服务器的域名匹配等。

4. **协商加密算法和密钥**：客户端和服务器之间通过 SSL/TLS 协议协商加密算法和密钥。这些加密算法和密钥用于对数据进行加密和解密，确保数据在传输过程中的机密性。

5. **建立安全连接**：客户端和服务器都通过 SSL/TLS 协议建立了一个安全的加密连接。在这个连接上进行的数据传输都是经过加密的，防止被窃听和篡改。

6. **安全通信**：客户端和服务器之间的数据传输在建立的安全连接上进行，确保数据的保密性和完整性。

|协议|名称|默认端口|底层协议|
|---|---|---|---|
|HTTP|超文本传输协议|80|TCP|
|HTTPS|超文本传输安全协议|443|TCP|

---

## 72、HTTP 的缺点有哪些？

- **缺乏加密**：HTTP通信使用明文传输数据，因此容易被窃听和截取敏感信息。这使得用户的隐私和数据安全容易受到威胁，尤其在不安全的公共网络上使用时更为明显。

- **缺乏数据完整性保护**：HTTP没有提供对传输数据完整性的验证机制，因此在传输过程中可能会被篡改。没有验证数据完整性的保护，可能导致信息损坏或数据不准确。

- **缺乏身份验证**：HTTP没有内置的身份验证机制，任何人都可以伪装成服务器或客户端进行通信。这使得 HTTP 面临身份伪造和冒充的风险。

- **性能较低**：由于 HTTP 协议是无状态的，每次请求都需要重新建立连接，对于频繁的请求和响应，会增加连接建立的开销，影响性能。

- **不支持并发请求**：HTTP/1.1 协议是串行处理请求和响应的，一个连接只能处理一个请求，如果有多个请求需要同时处理，就需要建立多个连接，增加了服务器和客户端的负担。

- **不适合传输大量数据**：HTTP 在传输大量数据时效率较低，因为它没有压缩数据的能力，导致传输时间较长

---

## 73、HTTPS采用的加密方式有哪些？是对称还是非对称？

HTTPS 采用混合的加密机制，使用**非对称密钥加密来传输对称密钥，然后使用对称密钥加密来进行通信，同时使用消息摘要算法来验证数据的完整性**。这种混合的加密方式保证了通信的安全性和高效性

![](http://oss.interviewguide.cn/img/202205220036403.png)

确保传输安全过程（其实就是rsa原理）：

1.  Client给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法。
2.  Server确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数（Server random）。
3.  Client确认数字证书有效，然后生成一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给Server。
4.  Server使用自己的私钥，获取Client发来的随机数（Premaster secret）。
5.  Client和Server根据约定的加密方法，使用前面的三个随机数，生成”对话密钥”（session key），用来加密接下来的整个对话过程。

---

## 74、为什么有的时候刷新页面不需要重新建立 SSL 连接？

SSL/TLS依赖于底层的TCP连接, SSL/TLS握手过程将在已经建立的TCP连接中进行。TCP 连接有的时候会被浏览器和服务端维持一段时间，TCP 不需要重新建立，SSL 自然也会用之前的。

1. SSL/TLS 握手过程只在连接建立时进行：SSL/TLS 握手是建立安全连接所必需的过程，它发生在客户端和服务器之间建立连接的初始阶段。一旦握手成功，双方就拥有了共享的密钥，之后的通信都会使用这个密钥进行加密和解密

2. TCP 连接的保持：通常情况下，HTTP/HTTPS 使用 TCP 协议进行数据传输。TCP 是一种可靠的连接协议，它可以保持持久连接，直到连接被显式地关闭或者发生错误。因此，即使在刷新页面时，底层的 TCP 连接仍然保持活动状态 (2MSL)，SSL/TLS 握手不会被重复执行

3. 会话复用：现代浏览器和服务器都支持 TLS 会话复用。会话复用是一种优化技术，它允许在同一个客户端和服务器之间建立多个安全连接时重用之前的密钥材料，从而避免重新执行完整的握手过程。这样，刷新页面时可以复用之前的会话，加速连接建立过程
  
---

## 75、SSL中的认证中的证书是什么？了解过吗？

通过使用 **证书** 来对通信方进行认证。

数字证书认证机构（CA，Certificate Authority）是客户端与服务器双方都可信赖的第三方机构。

服务器的运营人员向 CA 提出公开密钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公开密钥证书后绑定在一起。

进行 HTTPS 通信时，服务器会把证书发送给客户端。客户端取得其中的公开密钥之后，先使用数字签名进行验证，如果验证通过，就可以开始通信了。

---

## 76、HTTP如何禁用缓存？如何确认缓存？

HTTP/1.1 通过 `Cache-Control` 首部字段来控制缓存。

**禁止进行缓存**

> Cache-Control: no-store

`no-store` 指令规定不能对请求或响应的任何一部分进行缓存。每次请求都需要向服务器重新获取数据，确保数据的实时性和安全性

    
**强制确认缓存**

> Cache-Control: no-cache

这个指令告诉缓存服务器在使用缓存之前，必须先向源服务器验证缓存资源的有效性。如果缓存资源有效（未过期），则可以使用该缓存对客户端的请求进行响应。如果缓存资源无效（已过期或被修改），则缓存服务器必须重新向源服务器请求最新的资源

---

## 77、GET与POST传递数据的最大长度能够达到多少呢？

**get 是通过URL提交数据，因此GET可提交的数据量就跟URL所能达到的最大长度有直接关系**

很多文章都说GET方式提交的数据最多只能是1024字节，而实际上，URL不存在参数上限的问题，HTTP协议规范也没有对URL长度进行限制。

这个限制是特定的浏览器及服务器对它的限制，比如IE对URL长度的限制是2083字节(2K+35字节)。对于其他浏览器，如FireFox，Netscape等，则没有长度限制，这个时候其限制取决于服务器的操作系统；即如果url太长，服务器可能会因为安全方面的设置从而拒绝请求或者发生不完整的数据请求。

**post 理论上讲是没有大小限制的，HTTP协议规范也没有进行大小限制，但实际上post所能传递的数据量大小取决于服务器的设置和内存大小**

因为我们一般post的数据量很少超过MB的，所以我们很少能感觉的到post的数据量限制，但实际中如果你上传文件的过程中可能会发现这样一个问题，即上传个头比较大的文件到服务器时候，可能上传不上去。

---

## 78、网络层常见协议？可以说一下吗？

|协议|名称|作用|
|---|---|---|
|IP|网际协议|IP协议不但定义了数据传输时的基本单元和格式, 还定义了数据报的递交方法和路由选择|
|ICMP|Internet控制报文协议|ICMP就是一个“错误侦测与回报机制”, 其目的就是让我们能够检测网路的连线状况, 也能确保连线的准确性, 是ping和traceroute的工作协议|
|RIP|路由信息协议|使用“跳数”(即metric)来衡量到达目标地址的路由距离|
|IGMP|Internet组管理协议|用于实现组播、广播等通信|

---

## 79、TCP四大拥塞控制算法总结？（极其重要）

**四大算法**

**拥塞控制主要是四个算法：1）慢启动，2）拥塞避免，3）拥塞发生，4）快速恢复**。这四个算法不是一天都搞出来的，这个四算法的发展经历了很多时间，到今天都还在优化中。

![](http://oss.interviewguide.cn/img/202205220036635.png)

- **一、慢启动算法 – Slow Start**

所谓慢启动，也就是TCP连接刚建立，一点一点地提速，试探一下网络的承受能力，以免直接扰乱了网络通道的秩序。慢启动算法是TCP拥塞控制的一种基本机制，它在连接建立和拥塞恢复时起到重要作用

1. 在TCP连接刚建立时，初始化拥塞窗口 cwnd 大小为1个MSS（最大报文段长度），表明可以传输一个MSS大小的数据

2. 每当成功收到一个确认 ACK，cwnd 大小增加1个MSS，呈线性上升。这意味着每个往返时间内，可以发送的数据量就增加了一个MSS大小

3. 每当过了一个往返延迟时间 RTT（Round-Trip Time），cwnd 大小直接翻倍，乘以2，呈指数增长。这样在连续的往返时间内，发送的数据量将呈指数级增加，加快了拥塞窗口的增长速度。假设窗口长度为d，收到一个确认就加1，正好收到了d个确认，所以一共加d，正好是翻倍，直到达到阀值ssthresh

4. 存在一个慢启动阈值 ssthresh（slow start threshold），当 cwnd >= ssthresh 时，就会进入“拥塞避免算法”阶段，即TCP进入拥塞避免状态。在拥塞避免状态中，cwnd 不再呈指数增长，而是以更为缓慢的线性方式增加。

5. 如果发生拥塞，即网络出现拥堵或丢包等情况，TCP会根据一定的拥塞控制算法，将 ssthresh 设置为当前 cwnd 的一半，并将 cwnd 设置为1，然后重新执行慢启动算法，从新的 cwnd 大小开始恢复传输。

通过慢启动算法，TCP连接在初始阶段能够快速适应当前网络的带宽和延迟情况，从而达到更高的传输效率。当网络出现拥塞时，慢启动算法能够控制数据的发送速率，防止过多的数据堆积在网络中，从而维持网络的稳定性和公平性

- **二、拥塞避免算法 – Congestion Avoidance**

当拥塞窗口大小 cwnd 大于等于慢启动阈值ssthresh后，就进入拥塞避免算法。在拥塞避免算法中，cwnd 增长速度变化，以避免窗口增长过快导致网络拥塞

1. 当每次收到一个ACK确认时，cwnd 的增长方式变为线性增加，即每个往返时间内，cwnd 的大小增加1个MSS。

2. 每当过了一个往返延迟时间 RTT，cwnd 大小加一，呈线性增长。这样使得cwnd 增长缓慢，避免在网络中发送过多的数据，从而保持网络的稳定性

拥塞避免算法中，当 cwnd 大于等于慢启动阈值时，cwnd 的增长速度从指数级转变为线性增加，每收到一个确认ACK，cwnd 增加1个MSS，每过一个往返延迟时间 RTT，cwnd 大小加一。这样的调整使得 TCP 连接可以在网络中均衡和稳定地传输数据，避免造成网络拥塞，而是缓慢的增加调整到网络的最佳值

- **三、拥塞发生状态时的算法**

一般来说，TCP拥塞控制默认认为网络丢包是由于网络拥塞导致的，所以一般的TCP拥塞控制算法以丢包为网络进入拥塞状态的信号。因此会根据不同的丢包情况进行拥塞控制(超时重传, 快速重传)

**超时重传（Retransmission Timeout，RTO）**

超时重传是TCP协议保证数据可靠性的一个重要机制，其原理是在发送一个数据以后就开启一个计时器，当超过了重传定时器设定的时间（RTO），发送端还没有收到确认ACK，TCP会认为数据包丢失，触发超时重传，直到发送成功为止。超时重传是一种比较**悲观的拥塞控制机制**，因为它默认认为网络丢包是由于网络拥塞造成的

- 当发生超时重传时，TCP会执行慢启动算法：

  - 将慢启动阈值 ssthresh 设置为当前 cwnd 的一半，即 ssthresh = cwnd / 2

  - 将 cwnd 重置为1，表明重新初始化**慢启动**过程


最为早期的TCP Tahoe算法就只使用上述处理办法，但是由于一丢包就一切重来，导致cwnd又重置为1，十分不利于网络数据的稳定传递。所以，TCP Reno算法进行了优化。当收到三个重复确认ACK时，TCP开启快速重传Fast Retransmit算法，而不用等到RTO超时再进行重传

**快速重传（Fast Retransmit）**

快速重传是指在收到三个或更多的重复确认ACK时，这个机制不需要等到重传定时器超时，而直接进行重传。这是一种**乐观的拥塞控制机制**，因为它认为出现丢包可能是网络中只有少数数据包丢失，并不一定是网络拥塞的结果。快速重传后没有使用慢启动算法，而是拥塞避免算法，所以这又叫做快速恢复算法

- 当收到三个或更多的重复确认ACK时，TCP开启快速重传算法，触发快速恢复算法：

  - 将 cwnd 大小缩小为当前的一半，即 cwnd = cwnd / 2

  - 将 ssthresh 设置为缩小后的 cwnd 大小，即 ssthresh = cwnd

  - 然后进入**快速恢复**状态，其中 cwnd 的增长方式变为线性增加，即每个收到的确认ACK，cwnd 增加1个MSS

快速恢复状态与慢启动状态不同，快速恢复状态不会重置 cwnd 为1，而是将 cwnd 缩小为当前的一半，并且通过线性增加的方式逐渐恢复发送速率，这样避免了慢启动阶段重新初始化时的大幅度窗口减小

总结起来，TCP的拥塞控制算法会根据超时重传和快速重传来调整拥塞窗口大小 cwnd 和慢启动阈值 ssthresh，以适应网络的拥塞状态，保持网络的稳定和可靠传输

![](http://oss.interviewguide.cn/img/202205220036573.png)

- **四、快速恢复算法 – Fast Recovery**

TCP Tahoe是早期的算法，所以没有快速恢复算法，而 TCP Reno 算法有。在进入快速恢复之前，cwnd和ssthresh已经被更改为原有cwnd的一半。快速恢复算法的逻辑如下：

*   `cwnd = cwnd + 3 * MSS`，加 `3 * MSS` 的原因是因为收到3个重复的ACK。
    
*   重传DACKs (重复的ACK) 指定的数据包。
    
*   如果再收到DACKs，那么cwnd大小增加一
    
*   如果收到新的ACK，表明重传的包成功了，那么退出快速恢复算法。将cwnd设置为ssthresh，然后进入拥塞避免算法
    
![](http://oss.interviewguide.cn/img/202205220036984.png)
    

如图所示，第五个包发生了丢失，所以导致接收方接收到三次重复ACK，也就是ACK5。所以将ssthresh设置当当时cwnd的一半，也就是6/2 = 3，cwnd设置为3 + 3 = 6。然后重传第五个包。当收到新的ACK时，也就是ACK11，则退出快速恢复阶段，将cwnd重新设置为当前的ssthresh，也就是3，然后进入拥塞避免算法阶段。

总结起来，快速恢复算法是TCP Reno拥塞控制中的一部分，在发生快速重传的情况下，通过增加拥塞窗口大小和恢复丢失的数据包，使得TCP连接能够更快速地适应网络拥塞状态，提高数据传输的效率和可靠性

---

## 80、为何快速重传是选择3次ACK？

主要的考虑还是要**区分包的丢失是由于链路故障还是乱序等其他因素引发**

两次 duplicated ACK 时很可能是乱序造成的！三次 duplicated ACK 时很可能是丢包造成的！四次duplicated ACK 更更更可能是丢包造成的，但是这样的响应策略太慢。**丢包肯定会造成三次 duplicated ACK! 综上是选择收到三个重复确认时窗口减半效果最好，这是实践经验**

包的丢失原因

- 包校验和出错： 在传输过程中，数据包的校验和计算出错，接收方无法正确验证数据的完整性，因此丢弃该数据包。

- 网络拥塞： 当网络中的流量过多，导致路由器和网络设备无法及时处理所有数据包时，可能会出现网络拥塞，导致一些数据包被丢弃。

- 网络断连： 当网络中的连接中断或路由重收敛时，数据包可能会因为无法传送而被丢弃。

快速重传算法的目的是在发生数据包丢失时更快地进行重传，提高传输效率。在该算法中，TCP会根据收到的确认ACK的情况进行判断（因为还可以接收到ACK，可以认为网络并没有断，否则也接收不到ACK）

- 如果收到两个或更少的重复确认ACK（即接收到一个确认ACK和一个重复确认ACK），TCP会认为数据包丢失是由于网络乱序等原因造成的，而不是由于网络拥塞。此时，TCP不会立即重传数据包，而是等待超时重传。

- 如果收到三个或三个以上的重复确认ACK（即接收到三个或更多的重复确认ACK），TCP会认为数据包丢失是由于网络拥塞造成的。此时，TCP会立即进行快速重传，重传丢失的数据包，并根据快速恢复算法调整拥塞窗口大小。

快速重传算法的优势在于它能够更快地恢复数据包丢失的情况，而不需要等待超时定时器。通过在网络拥塞时快速进行重传和适当降低发送速率，TCP可以更好地适应网络状况，提高传输的效率和可靠性

---

## 81、对于 FIN_WAIT_2, CLOSE_WAIT 状态和 TIME_WAIT 状态？你知道多少?

*   `FIN_WAIT_2` 状态：
    
    *   半关闭状态
        
    *   发送断开请求一方还有接收数据能力，但已经没有发送数据能力
        
*   `CLOSE_WAIT` 状态：
    
    *   被动关闭连接一方接收到 FIN 包会立即回应 ACK 包表示已接收到断开请求
        
    *   被动关闭连接一方如果还有剩余数据要发送就会进入 `CLOSE_WAIT` 状态
        
*   `TIME_WAIT` 状态：
    
    *   又叫 2MSL 等待状态
  
    *   如果客户端直接进入 CLOSED 状态，如果服务端没有接收到最后一次 ACK 包会在超时之后重新再发FIN包，此时因为客户端已经 CLOSED，所以服务端就不会收到 ACK 而是收到 RST。所以 `TIME_WAIT` 状态目的是防止最后一次握手数据没有到达对方而触发重传 FIN 准备的
  
    *   在 2MSL 时间内，同一个 socket 不能再被使用，否则有可能会和旧连接数据混淆（如果新连接和旧连接的socket相同的话）
    
---

## 82、你了解流量控制原理吗？

流量控制是TCP协议中的一种机制，用于管理两个通信对等体之间的数据传输速率。它的主要目的是防止发送方发送速率过快导致接收方无法处理和存储接收到的数据。流量控制采用基于窗口的流量控制机制。

- **流量控制是点对点控制**： 流量控制确保数据传输的发送速率适合接收方的处理能力。TCP连接是端到端（点对点）的，因此流量控制是由接收方向发送方发送控制信号来实现的。

- **发送窗和接收窗**： 发送方和接收方都维护一个窗口，这是一个动态的缓冲区。发送窗口用来限制发送方未被确认的数据量，而接收窗口用来标记接收方能够接收的数据大小。发送窗 = 已发送未确认部分 + 未发但可发送部分; 接收窗 = 未接收但准备接收部分

- **TCP是双工协议**： TCP连接允许双方同时通信，即双向传输数据，所以双方都需要维护自己的发送窗和接收窗。

- **发送窗口的大小**： 接收方通过TCP头中的窗口字段告知发送方它的接收缓冲区大小。发送方根据这个信息来决定发送多少数据，以确保不会超过接收方的处理能力。

- **发送和接收数据流的分段**： TCP是流数据，发送出去的数据流可以被划分为四个部分 (已发送且被确认部分 | 已发送未被确认部分 | 未发送但可发送部分 | 不可发送部分)，其中发送窗包含未被确认的部分和可发送的部分。接收到的数据流可以划分为三个部分 (已接收 | 未接收但准备接收 | 未接收不准备接收), 其中接收窗为未接收但准备接收部分

- **发送窗和接收窗的移动**： 发送窗内的数据只有在接收到接收方对发送数据的确认（ACK）时才会移动，左边缘会紧贴刚被确认的数据。接收窗也只有在接收到连续的数据时才会移动

---

## 83、建立TCP服务器的各个系统调用过程是怎样的？

![](http://oss.interviewguide.cn/img/202205220023934.png)

![](http://oss.interviewguide.cn/img/202205220023348.png)

*   服务器：
    
    *   创建 socket -> `int socket(int domain, int type, int protocol);`
        
        *   domain：协议域，决定了socket的地址类型，IPv4为 `AF_INET`
            
        *   type：指定 socket 类型，`SOCK_STREAM` 为TCP连接
            
        *   protocol：指定协议。`IPPROTO_TCP` 表示TCP协议，为0时自动选择 type 默认协议
            
    *   绑定socket和端口号 -> `int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);`
        
        *   sockfd：socket 返回的套接字描述符，类似于文件描述符fd
            
        *   addr：有个sockaddr类型数据的指针，指向的是被绑定结构变量。
            
        ```c++
        // IPv4的sockaddr地址结构
        struct sockaddr_in {
            sa_family_t sin_family;    // 协议类型，AF_INET
            in_port_t sin_port;    // 端口号
            struct in_addr sin_addr;    // IP地址
        };
        struct in_addr {
            uint32_t s_addr;
        }
        ```
        
        *   addrlen：地址长度
  
    *   监听端口号 -> `int listen(int sockfd, int backlog);`
            
        *   backlog：socket可以排队的最大连接数。
            
    *   接收用户请求 -> `int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);`
        
        *   addr：指向地址结构指针。
            
        *   addrlen：协议地址长度。
            
        *   注：一旦accept某个客户机请求成功将返回一个全新的描述符用于标识具体客户的TCP连接。
            
    *   从socket中读取字符 -> `ssize_t read(int fd, void *buf, size_t count);`
         
        *   buf：缓冲区buf。
            
        *   count：缓冲区长度。
            
        *   注：大于0表示读取的字节数，返回0表示文件读取结束，小于0表示发生错误。
            
    *   关闭socket -> `int close(int fd);`
        
        *   fd：accept返回的连接描述字，每个连接有一个，生命周期为连接周期。
            
        *   注：sockfd是监听描述字，一个服务器只有一个，用于监听是否有连接；fd是连接描述字，用于每个连接的操作。
            
*   客户机：
    
    *   创建socket -> `int socket(int domain, int type, int protocol);`
        
    *   连接指定计算机 -> `int connect(int sockfd, struct sockaddr* addr, socklen_t addrlen);`
        
        *   sockfd客户端的sock描述字
            
        *   addr：服务器的地址。
            
        *   addrlen：socket地址长度。
            
    *   向socket写入信息 -> `ssize_t write(int fd, const void *buf, size_t count);`
        
        *   fd、buf、count：同read中意义。
            
        *   大于0表示写了部分或全部数据，小于0表示出错。
            
    *   关闭oscket -> `int close(int fd);`
        
        *   fd：同服务器端fd

---

## 84、TCP 协议如何保证可靠传输？

**第一种回答**

*   **确认和重传**：接收方收到报文就会确认，发送方发送一段时间后没有收到确认就会重传。

*   **数据校验**：TCP报文头有校验和，用于校验报文是否损坏。

*   **数据合理分片和排序**：tcp会按最大传输单元(MTU)合理分片，接收方会缓存未按序到达的数据，重新排序后交给应用层。而UDP：IP数据报大于1500字节，大于MTU。这个时候发送方的IP层就需要分片，把数据报分成若干片，是的每一片都小于MTU。而接收方IP层则需要进行数据报的重组。由于UDP的特性，某一片数据丢失时，接收方便无法重组数据报，导致丢弃整个UDP数据报。

*   **流量控制**：当接收方来不及处理发送方的数据，能通过滑动窗口，提示发送方降低发送的速率，防止包丢失。

*   **拥塞控制**：当网络拥塞时，通过拥塞窗口，减少数据的发送，防止包丢失。

**第二种回答**

*   建立连接（标志位）：通信前确认通信实体存在。
    
*   序号机制（序号、确认号）：确保了数据是按序、完整到达。
    
*   数据校验（校验和）：CRC校验全部数据。
    
*   超时重传（定时器）：保证因链路故障未能到达数据能够被多次重发。
    
*   窗口机制（窗口）：提供流量控制，避免过量发送。
    
*   拥塞控制：同上。
    

**第三种回答**

**首部校验** 这个校验机制能够确保数据传输不会出错吗？ 答案是不能。

**原因**

TCP协议中规定，TCP的首部字段中有一个字段是校验和，发送方将伪首部、TCP首部、TCP数据使用累加和校验的方式计算出一个数字，然后存放在首部的校验和字段里，接收者收到TCP包后重复这个过程，然后将计算出的校验和和接收到的首部中的校验和比较，如果不一致则说明数据在传输过程中出错。

这就是TCP的数据校验机制。 但是这个机制能够保证检查出一切错误吗？**显然不能**。

因为这种校验方式是累加和，也就是将一系列的数字（TCP协议规定的是数据中的每16个比特位数据作为一个数字）求和后取末位。 但是小学生都知道A+B=B+A，假如在传输的过程中有前后两个16比特位的数据前后颠倒了（至于为什么这么巧合？我不知道，也许路由器有bug？也许是宇宙中的高能粒子击中了电缆？反正这个事情的概率不为零，就有可能会发生），那么校验和的计算结果和颠倒之前是一样的，那么接收端肯定无法检查出这是错误的数据。

**解决方案**

传输之前先使用MD5加密数据获得摘要，跟数据一起发送到服务端，服务端接收之后对数据也进行MD5加密，如果加密结果和摘要一致，则认为没有问题

---

## 85、UDP是什么？

UDP（User Datagram Protocol）是一种传输层协议，用于在计算机网络中提供无连接的、尽最大努力的数据传输服务。与TCP相比，UDP不提供数据传输的可靠性和流量控制

主要特点包括：

- **无连接性**： UDP是无连接的，这意味着在发送数据之前不需要建立连接。发送方只需将数据包发送到目标IP地址和端口，而不需要像TCP一样进行三次握手等连接建立过程。

- **尽最大努力交付**： UDP提供的服务是“尽最大努力交付”，这意味着UDP在传输数据时不对数据包的顺序、完整性或重复性做出任何保证。数据包可能会因为网络拥塞、丢包或其他原因而丢失，也可能以不同的顺序到达接收方。

- **不保证可靠性**： 由于UDP不提供数据传输的可靠性保证，应用程序需要自行处理数据传输的可靠性问题。如果应用程序需要确保数据的完整性和有序性，必须由应用层自行实现这些功能，例如通过校验和、重传机制等。

- **低延迟**： 由于UDP没有连接建立和数据确认的开销，它通常具有较低的传输延迟。这使得UDP在某些实时应用中非常有用，如音频和视频流传输。

UDP适用于一些特定的应用场景，例如实时游戏、流媒体传输、DNS查询等，这些应用对传输延迟较为敏感，而对数据的可靠性要求相对较低。但对于需要可靠数据传输和流量控制的应用，TCP通常是更合适的选择。

## 86、TCP 和 UDP 的区别

- **连接性**： TCP是面向连接的，需要先建立连接才能传输数据，类似于打电话要先拨号建立连接；而UDP是无连接的，发送数据之前不需要建立连接，类似于寄信。

- **可靠性**： TCP提供可靠的数据传输，保证数据无差错、不丢失、不重复，并按序到达目的地；UDP则尽最大努力交付，不保证数据传输的可靠性，可能会出现丢包或乱序。

- **数据传输方式**： TCP是面向字节流的，把上面应用层交下来的数据看成无结构的字节流；UDP是面向报文的，对应用层交下来的报文，不合并，不拆分，只是在其上面加上首部后就交给了下面的网络层

- **拥塞控制**： TCP具有拥塞控制机制，当网络出现拥塞时，TCP会降低发送速率以避免进一步加重网络拥塞；UDP没有拥塞控制，适合用于实时应用，如IP电话和实时视频会议。

- **通信模式**： TCP连接是点对点的，即每个TCP连接只有一个发送方和一个接收方；UDP支持一对一、一对多、多对一和多对多的通信模式。

- **首部开销**： TCP的首部开销较大，占用20个字节；UDP的首部开销较小，只有8个字节。

- **信道类型**： TCP提供的逻辑通信信道是全双工的可靠信道；UDP则是不可靠信道，不保证可靠传输。

总体上，TCP适用于需要可靠数据传输和顺序控制的应用，如网页浏览、文件传输等；而UDP适用于实时性要求较高，对可靠性要求较低的应用，如流媒体传输、在线游戏等。选择TCP还是UDP取决于应用的特点和需求。

- **补充题：封包和拆包你听说过吗？它是基于TCP还是UDP的？**

封包和拆包都是在TCP通信中使用的概念，目的是确保数据在发送和接收过程中不发生粘包（多个数据包粘在一起）或者拆包（一个数据包被拆成多个片段）的问题。

在TCP中，数据是以字节流的形式进行传输的，而没有明确的消息边界。因此，发送方在发送数据时需要将数据进行封包，即在数据前面添加一个包头，包头包含了数据的长度等信息。接收方在接收数据时根据包头中的长度信息来拆解数据包，确保每个数据包都被正确处理。

**封包和拆包操作由应用层来实现，不是TCP协议本身提供的特性。应用层在发送数据时，会将数据按照一定规则进行封包，并在接收端按照相同的规则进行拆包，以保证数据的完整性和准确性**

UDP在传输数据时是面向报文的，每个UDP数据包都有自己的边界，不会发生粘包或拆包问题，因此在UDP通信中不需要像TCP那样进行封包和拆包的处理

---

## 87、UDP的特点有哪些（附赠TCP的特点）？

**UDP的特点：**

- **无连接**：UDP是无连接的，发送数据之前不需要建立连接，类似于寄信。

- **尽最大努力交付**：UDP尽最大努力交付数据，不保证可靠传输，可能会出现丢包或乱序。

- **面向报文**：UDP是面向报文的，传输的数据报文保持原样，不合并也不拆分。

- **没有拥塞控制**：UDP没有拥塞控制机制，适合用于实时应用，如IP电话和实时视频会议。

- **支持一对一、一对多、多对一和多对多的交互通信**：UDP可以在多个主机之间进行多种通信模式。

- **首部开销小**：UDP的首部只有8个字节，相比TCP的20个字节要更小。

**TCP的特点：**

- **面向连接**：TCP是面向连接的，需要先建立连接才能传输数据，类似于打电话要先拨号建立连接。

- **点对点通信**：每一条TCP连接只能有两个端点，是一对一的通信。

- **可靠传输**：TCP提供可靠的数据传输，保证数据无差错、不丢失、不重复，并按序到达目的地。

- **全双工通信**：TCP允许通信双方的应用进程在任何时候都能发送数据，支持全双工通信。

- **面向字节流**：TCP将应用程序交下来的数据看作一连串无结构的字节流进行传输。

总体上，UDP适用于实时性要求较高，对可靠性要求较低的应用场景，而TCP适用于对数据可靠性和顺序控制有较高要求的应用场景。选择使用哪种协议取决于应用的需求和特点。

---

## 88、TCP 对应的应用层协议

| 协议   | 描述                                 | 端口  |
|--------|-------------------------------------|------|
| FTP    | 文件传输协议                        | 21   |
| Telnet | 远程登录                            | 23   |
| SMTP   | 简单邮件传送协议                    | 25   |
| POP3   | 邮局协议第3版 (接收邮件)             | 110  |
| HTTP   | 超文本传输协议                      | 80   |
| HTTPS  | HTTP安全版（SSL/TLS加密的HTTP）    | 443  |

---

## 89、UDP 对应的应用层协议

| 协议   | 描述                           | 端口  |
|--------|-------------------------------|------|
| DNS    | 域名解析服务                  | 53   |
| SNMP   | 简单网络管理协议              | 161  |
| TFTP   | 简单文件传输协议              | 69   |

---

## 90、数据链路层常见协议？可以说一下吗？

| 协议   | 名称                   | 作用                              |
|--------|-----------------------|----------------------------------|
| ARP    | 地址解析协议          | 根据IP地址获取物理地址          |
| RARP   | 反向地址转换协议      | 根据物理地址获取IP地址          |
| PPP    | 点对点协议            | 通过拨号或专线方式建立点对点连接，发送数据 |

---

## 91、Ping命令基于什么协议？原理是什么？

Ping 命令是基于网络层的 ICMP（Internet Control Message Protocol）协议实现的。ICMP 是用于在 IP 网络中传递错误消息和操作消息的协议。Ping 命令使用 ICMP 来测试两台主机之间的连通性和延迟

Ping 命令的原理是发送一个 **ICMP回送请求报文** 到目标主机，如果目标主机是可达的，它会接收到该报文，并响应一个 **ICMP回送回答报文**。通过测量从发送请求到接收响应的时间来计算往返时间（RTT），从而估计主机之间的延迟

扩展：ICMP报文的介绍。ICMP报文分为两个种类：

- ICMP差错报告报文，常见的有
    1.  终点不可达
    2.  时间超过
    3.  参数问题
    4.  改变路由
- ICMP询问报文
    1.  回送请求和回答：向特定主机发出**回送请求报文**，收到回送请求报文的主机响应**回送回答报文**。
    2.  时间戳请求和回答：询问对方当前的时间，返回的是一个32位的时间戳。

---

## 92、在进行UDP编程的时候，一次发送多少bytes好?

    当然,这个没有唯一答案，相对于不同的系统,不同的要求,其得到的答案是不一样的。

    我这里仅对像ICQ一类的发送聊天消息的情况作分析，对于其他情况，你或许也能得到一点帮助:首先,我们知道,TCP/IP通常被认为是一个四层协议系统,包括链路层,网络层,运输层,应用层.UDP属于运输层,

    下面我们由下至上一步一步来看:以太网(Ethernet)数据帧的长度必须在46-1500字节之间,这是由以太网的物理特性决定的.这个1500字节被称为链路层的MTU(最大传输单元).但这并不是指链路层的长度被限制在1500字节,其实这这个MTU指的是链路层的数据区.并不包括链路层的首部和尾部的18个字节.

    所以,事实上,这个1500字节就是网络层IP数据报的长度限制。因为IP数据报的首部为20字节,所以IP数据报的数据区长度最大为1480字节.而这个1480字节就是用来放TCP传来的TCP报文段或UDP传来的UDP数据报的.又因为UDP数据报的首部8字节,所以UDP数据报的数据区最大长度为1472字节.这个1472字节就是我们可以使用的字节数。

    当我们发送的UDP数据大于1472的时候会怎样呢？ 这也就是说IP数据报大于1500字节,大于MTU.这个时候发送方IP层就需要分片(fragmentation). 把数据报分成若干片,使每一片都小于MTU.而接收方IP层则需要进行数据报的重组. 这样就会多做许多事情,而更严重的是,由于UDP的特性,当某一片数据传送中丢失时,接收方便 无法重组数据报.将导致丢弃整个UDP数据报。

    因此,在普通的局域网环境下，我建议将UDP的数据控制在1472字节以下为好.

    进行Internet编程时则不同,因为Internet上的路由器可能会将MTU设为不同的值. 如果我们假定MTU为1500来发送数据的,而途经的某个网络的MTU值小于1500字节,那么系统将会使用一系列的机 制来调整MTU值,使数据报能够顺利到达目的地,这样就会做许多不必要的操作.

    鉴于Internet上的标准MTU值为576字节,所以我建议在进行Internet的UDP编程时. 最好将UDP的数据长度控件在548字节(576-8-20)以内

**总结**

UDP数据包大小的选择确实受到多方面的因素影响，如网络环境、数据内容、传输性能等。总结一下通常情况下 UDP 数据包大小的选择建议：

- 在局域网环境下，建议将UDP数据控制在1472字节以下。这是因为在以太网中，MTU通常为1500字节，而UDP数据报的最大有效负载为1472字节（MTU - IP头部20字节 - UDP头部8字节）。

- 在进行Internet编程时，特别是涉及到经过Internet上的路由器传输的情况，建议将UDP数据长度控制在548字节（标准MTU值为576字节 - IP头部20字节 - UDP头部8字节）以内。

保持UDP数据包大小合适可以避免分片和重组操作，提高数据传输效率和可靠性。但需要注意的是，实际使用时还应考虑具体的应用场景和网络环境，以选择合适的数据包大小

---

## 93、TCP 利用滑动窗口实现流量控制的机制？

TCP 利用滑动窗口机制来进行流量控制，确保发送方不会发送过多的数据导致接收方来不及处理。**流量控制是一种防止数据拥塞和丢失的机制**，它通过动态调整滑动窗口的大小来限制发送方发送数据的速率

在TCP中，接收方维护一个滑动窗口，其大小表示接收方的缓冲区能够容纳的未确认数据的最大量。接收方在接收到数据后会发送一个确认（ACK）给发送方，确认接收到的数据和接收方当前的滑动窗口大小。发送方根据接收方返回的滑动窗口大小来控制发送的数据量，确保不超过接收方缓冲区的可用空间

具体的流程如下：

- 发送方发送数据给接收方，并开始计时等待接收方的确认

- 接收方收到数据后，将数据存入缓冲区，并返回一个ACK确认给发送方

- 发送方收到ACK后，根据接收方返回的滑动窗口大小，更新自己的滑动窗口大小

- 发送方根据滑动窗口的大小决定下一次发送数据的数量，并继续发送数据

- 如果接收方的缓冲区已满，滑动窗口为0，发送方将暂停发送数据，直到接收方的滑动窗口再次打开
  
这样，TCP通过不断调整滑动窗口大小来实现动态的流量控制，使得发送方的发送速率与接收方的处理能力相匹配，保证数据传输的可靠性和稳定性。

注意：当滑动窗口为0时，发送方一般不能再发送数据报，因为接收方的缓冲区已满，无法接收更多的数据。但是，TCP协议允许两种特殊情况下发送方继续发送数据：

- **发送紧急数据**： TCP支持发送紧急数据，这是一种特殊类型的数据，用于在紧急情况下向接收方发送重要的信息。紧急数据会绕过滑动窗口机制，直接发送给接收方，即使滑动窗口为0，也可以发送紧急数据。

- **发送窗口探测数据**： 当发送方的滑动窗口为0时，发送方可以发送一个1字节的数据报，这被称为"窗口探测数据"。这个数据报的目的是通知接收方重新声明它希望接收的下一字节序号，并告知发送方当前的滑动窗口大小。接收方收到窗口探测数据后，会重新发送ACK确认，并返回新的滑动窗口大小，使得发送方可以继续发送数据。

---

## 94、可以解释一下RTO（Retransmission TimeOut），RTT（Round-Trip Time）和超时重传分别是什么吗？

**RTO (重传间隔时间)：**

从上一次发送数据开始，到下一次重发该数据报之间的时间间隔。RTO的计量单位通常是 RTT（往返时间），即数据报从发送到接收到对方ACK响应之间的时间间隔。RTO的计算是根据网络的延迟和抖动等因素来调整的。
    
- 通常情况下，RTO会根据重传次数指数增加，例如1RTT, 2RTT, 4RTT ,8RTT, ...

- 重传次数到达上限之后停止重传
        
**RTT (往返时间)：**

数据从发送端发送到接收端并返回ACK响应的往返时间。它表示数据报在网络中传输一个往返所花费的时间，包括数据在网络中传输的时间和接收端处理数据的时间。RTT的大小是不稳定的，会受到网络延迟和拥塞等因素的影响

**超时重传：**

发送端在发送数据后，会启动一个定时器，如果在规定的时间内（即RTO）没有收到对应的ACK响应，就会触发超时重传的机制。超时重传是TCP协议保证可靠性的一部分，确保数据能够在网络中正确传递。可能有以下几种情况：
    
- 发送的数据没能到达接收端，所以对方没有响应
    
- 接收端接收到数据，但是ACK报文在返回过程中丢失
    
- 接收端拒绝或丢弃数据
  
**它们之间的关系**

- RTT决定RTO： RTO的值通常是根据最近一段时间内的RTT计算得出的。发送方通过测量多个数据包的RTT，并考虑网络的抖动和延迟等因素，计算出一个合适的RTO值

- RTO触发超时重传： 发送方在发送数据报后会启动一个定时器，设置为RTO的时间间隔。如果在RTO时间内未收到对应的ACK确认响应，发送方会认为数据在传输过程中丢失，于是触发超时重传机制，重新发送相同的数据。

- 超时重传影响RTT的测量： 当发生超时重传时，发送方会重新发送数据，接收方会返回新的ACK响应。这会导致RTT的测量值受到重传数据包的影响。为了准确测量RTT，TCP通常使用平滑的方法来计算RTT，避免异常情况对RTT测量结果的影响。

综上所述，**RTT决定了RTO的值，RTO用于触发超时重传，而超时重传又会影响RTT的测量**。这三者之间相互关联，是TCP协议中实现可靠数据传输的重要机制。通过合理设置RTO值和处理超时重传，TCP能够在不可靠的网络环境下确保数据的可靠传输。

---

## 95、XSS攻击是什么？（低频）

XSS（Cross-Site Scripting）跨站点脚本攻击是一种常见的网络安全漏洞，攻击者通过在网页中插入恶意脚本代码，当用户访问该网页时，恶意脚本就会在用户的浏览器中执行，从而使攻击者能够窃取用户的敏感信息、劫持用户的会话，或者进行其他恶意操作。

为了防范XSS攻击，可以采取以下措施：

- 前端过滤： 在前端对用户输入的数据进行过滤和验证，限制输入的长度和格式，防止恶意脚本被插入。可以使用合适的输入校验库或正则表达式来验证用户输入。

- 服务端过滤： 在服务端对接收到的用户输入进行严格的过滤和转义处理，确保用户输入的内容不会被当作脚本执行。可以使用安全的输出编码函数将特殊字符转义，如将"<"转义为"<"，">"转义为">"等。

- 内容安全策略（CSP）： 使用内容安全策略来限制浏览器加载和执行外部资源的权限，防止恶意脚本的注入。CSP可以通过设置HTTP头或在HTML页面中添加meta标签来实现。

- HttpOnly标志： 在设置Cookie时，使用HttpOnly标志，这样可以防止JavaScript脚本访问Cookie，从而减少会话劫持的风险。

- 输入验证和输出编码： 不仅要过滤用户输入，还要在展示用户输入内容时进行输出编码，确保输出到页面的内容不会执行恶意脚本。

---

## 96、CSRF攻击？你知道吗？

CSRF（Cross-Site Request Forgery）跨站点请求伪造是一种常见的网络安全漏洞，攻击者利用用户已登录的身份，在用户不知情的情况下，通过构造恶意请求来执行非法操作。攻击者可以利用这种漏洞盗用用户的身份，以用户的名义发送恶意请求给第三方网站，从而实施各种恶意活动。

CSRF攻击的原理是利用网站对用户请求的信任。当用户已经登录某个网站时，浏览器在发送请求时会自动携带对应网站的Cookie信息，因此攻击者可以构造包含恶意操作的请求，欺骗用户浏览器发送请求到目标网站。如果目标网站没有采取适当的防御措施，就会以用户的身份执行这些恶意请求

可以这么理解CSRF攻击：攻击者盗用你的身份，以你的名义向第三方网站发送恶意请求。CRSF能做的事情包括利用你的身份发邮件，发短信，进行交易转账，甚至盗取账号信息

---

## 97、如何防范CSRF攻击

- 安全框架： 使用安全框架，如Spring Security，来处理CSRF攻击。这些框架提供了内置的CSRF防护机制，可以自动为每个请求生成并验证CSRF令牌。

- Token机制： 在HTTP请求中使用token验证，比如将CSRF令牌嵌入到表单中或者放在请求头中，服务器验证请求中的token是否正确，以防止CSRF攻击。

- 验证码： 对于敏感操作或者需要高安全性的请求，可以使用验证码进行额外的身份验证，防止CSRF攻击。

- Referer识别： 对于非敏感操作，可以通过检查HTTP请求头中的Referer字段来验证请求的来源地址，如果Referer不是同一站点的地址，可以拒绝该请求，但要注意Referer不是绝对可信，因为它可能被篡改或者被浏览器禁用。

- 验证请求来源地址： 在后端服务器验证请求的来源地址是否是合法的，可以通过检查Origin或者Referer等字段来判断请求的来源。

- 关键操作添加验证码： 对于执行重要操作的请求，比如修改密码、支付等，可以要求用户输入验证码进行二次确认。

- 请求地址添加Token并验证： 对于GET请求，可以将CSRF令牌添加到URL参数中或者作为请求头，对于POST请求，可以将令牌放在表单中，服务器端进行验证。

---

## 98、文件上传漏洞是如何发生的？你有经历过吗？

文件上传漏洞是一种常见的Web应用程序漏洞，它通常发生在用户上传文件的功能上。攻击者利用这个漏洞，上传恶意的文件（例如可执行的脚本文件或木马程序），从而执行远程代码或在服务器上执行任意命令。

漏洞产生的原因通常是由于服务器端对用户上传的文件没有进行充分的验证和过滤。攻击者可以通过构造特殊的文件名或伪造文件类型等方式绕过服务器端的上传检查，上传恶意文件到服务器上。

---

## 99、如何防范文件上传漏洞

- 不可执行目录： 确保上传文件存储的目录设置为不可执行，避免攻击者直接执行上传的文件。

- 文件类型检查： 在服务器端对上传的文件类型进行检查，使用MIME Type和后缀检查等方式来验证文件类型，只允许上传可靠的文件类型，拒绝上传可执行文件或其他危险文件。

- 白名单校验： 对上传的文件类型进行白名单校验，只允许上传预期的文件类型，防止攻击者上传不安全的文件。

- 重新命名文件： 上传的文件应该进行重新命名，避免使用原始文件名作为存储名称，以防止攻击者猜测访问路径。

- 限制文件大小： 对上传的文件进行大小限制，防止上传过大的文件导致服务器资源耗尽。

- 独立域名： 将文件上传到单独的文件服务器域名上，避免和主站混在一起，从而降低攻击的影响范围。

- 访问控制： 对上传功能进行访问控制，只允许授权用户使用上传功能，限制上传权限。

---

## 100、拥塞控制原理听说过吗？

拥塞控制是计算机网络中的一种重要机制，用于防止网络过载，保持网络的稳定性和性能。TCP协议通过拥塞控制算法来动态调整数据发送速率，以适应当前网络的拥塞程度。

TCP拥塞控制算法主要包括以下几个步骤：

- 慢开始： 在连接刚开始时，发送方先试探网络的拥塞程度，以较小的速率逐渐增加发送窗口大小（即拥塞窗口），从而增加数据发送量。假设窗口长度为d，收到一个确认就加1，正好收到了d个确认，所以一共加d，正好是翻倍，直到达到阀值ssthresh

- 拥塞避免： 一旦发送窗口大小达到阀值（ssthresh），每次发送一个MSS（最大报文段长度）的数据，而不是翻倍增加。这样防止过快增加导致网络拥塞。

- 快速重传和快速恢复： 如果接收方收到一个失序的数据报，会立即发送重复确认，而不是等待超时。发送方收到3个重复确认后，认为出现了拥塞，立即减少拥塞窗口大小，并进行快速恢复操作，将阀值减半，然后继续进行拥塞避免。

- 稳定状态： 在网络运行一段时间后，拥塞窗口大小会收敛于稳定值，即网络能够承受的最佳数据发送速率。

通过这些拥塞控制算法，TCP协议可以根据网络的实际情况动态调整数据发送速率，避免过载和拥塞，并保持网络的稳定性和可靠性。拥塞控制是TCP协议的一个重要特性，使得TCP能够在不同网络环境下都能表现出良好的性能

---

## 101、如何区分流量控制和拥塞控制？

- **控制范围**： 流量控制属于通信双方协商的范畴，是点对点的控制；而拥塞控制涉及通信链路全局，是全局控制。

- **窗口大小设置**： 在流量控制中，通信双方各自维护一个发送窗和接收窗。发送窗大小由接收方返回的TCP报文段中的窗口字段确定，接收窗大小由自身决定。而拥塞控制中，拥塞窗口的大小是根据网络拥塞情况动态调整的，通过试探性发送一定数据量来探查网络状况，并自适应调整拥塞窗口的大小。

- **最终发送窗口大小**： 实际最终发送窗口 = min{流控发送窗口，拥塞窗口}。这是为了避免过度注入数据导致网络拥塞。

通过流量控制和拥塞控制的合理协作，TCP协议能够在网络中实现高效的数据传输，并保证网络的稳定性和可靠性

---

## 102、常见的HTTP状态码有哪些？


| 状态码 | 类别                   | 含义                           |
| ------ | ---------------------- | ------------------------------ |
| 1XX    | Informational（信息性状态码） | 接收的请求正在处理               |
| 2XX    | Success（成功状态码）       | 请求正常处理完毕               |
| 3XX    | Redirection（重定向状态码） | 需要进行附加操作以完成请求       |
| 4XX    | Client Error（客户端错误状态码） | 服务器无法处理请求               |
| 5XX    | Server Error（服务器错误状态码） | 服务器处理请求出现错误           |


- **1xx 信息性状态码**： 表示请求已经成功被服务器接收、理解和处理

  - **100 Continue**：请求者应该继续发送请求。
  - **101 Switching Protocols**：服务器将遵从客户的请求转换到另外一种协议

- **2xx 成功状态码**： 表示请求已经成功被服务器接收、理解和处理

  - **200 OK**：请求成功，服务器正常处理
  - **201 Created**：请求成功，并且服务器创建了新的资源。
  - **204 No Content** ：请求成功，但响应报文不含实体数据，浏览器不更新页面内容

- **3xx 重定向状态码**： 表示需要进行附加操作以完成请求

  - **301 Moved Permanently** ：永久性重定向，请求的资源已被永久移动到新位置
  - **302 Found** ：临时性重定向，请求的资源临时从不同的 URL 响应请求
  - **304 Not Modified** ：资源未修改，可以直接使用缓存的版本

- **4xx 客户端错误状态码**：表示客户端发送的请求有误

  - **400 Bad Request** ：请求报文中存在语法错误。
  - **401 Unauthorized** ：该状态码表示发送的请求需要有认证信息（BASIC 认证、DIGEST 认证）。如果之前已进行过一次请求，则表示用户认证失败。
  - **403 Forbidden** ：服务器拒绝请求
  - **404 Not Found** ：请求的资源不存在

- **5xx 服务器错误状态码**：表示服务器在处理请求的过程中发生了错误

  - **500 Internal Server Error** ：服务器正在执行请求时发生错误。
  - **503 Service Unavailable** ：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。

---

## 103、服务器出现大量close_wait的连接的原因是什么？有什么解决方法？

close_wait 状态是在TCP四次挥手过程中的一种状态，它表示服务器已经接收到客户端发送的FIN（用于关闭连接），但服务器还未发送自己的FIN。这种状态通常由以下两种原因导致：

- **服务器业务处理较慢**： 当服务器在处理业务逻辑时耗费了较多时间，无法及时发送自己的FIN，导致连接处于close_wait状态。这可能是因为服务器内部业务繁忙、处理速度慢，或者出现了阻塞等问题

- **子进程未及时处理连接**： 在多进程或多线程的服务器中，如果子进程或子线程继承了父进程或父线程的套接字（socket），而子进程没有及时处理连接，导致父进程仍然保持连接而无法发送自己的FIN，从而产生close_wait状态

解决方法：

- 优化服务器业务逻辑： 确保服务器的业务逻辑高效、稳定，尽量避免出现阻塞和处理延迟，以减少close_wait状态的产生。

- 正确关闭连接： 确保服务器正确地关闭连接，即在业务处理完毕后及时发送FIN，而不是一直保持连接不释放。

- 优化服务器架构： 对于多进程或多线程的服务器，确保子进程或子线程正确处理连接，并在处理完毕后及时关闭连接。

- 使用连接池： 对于高并发服务器，可以考虑使用连接池管理连接，避免频繁创建和销毁连接，提高连接的复用率。

- 使用Keep-Alive： 如果客户端支持，可以使用HTTP Keep-Alive特性，在一个连接上处理多个HTTP请求，减少连接的建立和关闭次数。

- 使用TCP Keep-Alive机制： TCP协议本身提供了Keep-Alive机制，可以在一定时间内发送探测报文，检测连接是否还处于活动状态。

---

## 104、一台机器能够使用的端口号上限是多少，是否可以修改？如果想要用的端口超过这个限制怎么办？

实际上，一台机器能够使用的端口号上限是由操作系统和网络协议栈决定的，一般情况下是65536个端口号（从0到65535）。这是因为在TCP和UDP协议中，端口号使用16位来表示，所以最多可以有2^16=65536个不同的端口号。

在这65536个端口号中，0到1023被称为"知名端口"或"系统端口"，是留给一些常用的网络服务使用的，如HTTP使用的80端口，HTTPS使用的443端口，SSH使用的22端口等。剩余的端口号（从1024到65535）被称为"动态端口"或"私有端口"，通常由客户端程序在需要时动态分配。对于服务器来说，可以开放的端口号是受限于操作系统的资源，其中包括：

- MaxUserPort（或称MaxUserPortRange）： 这是Windows操作系统的一个参数，用于限制用户级别的端口号范围，默认是65534，即从1024到65534。可以通过更改注册表来修改此值，但需要谨慎处理。

- ulimit： 这是Linux/Unix操作系统中用来限制用户进程资源的参数，包括文件句柄数、进程数和端口范围等。可以通过修改ulimit参数来增加可打开的文件数，从而间接增加可使用的端口数。

如果想要用的端口超过操作系统的默认限制，可以考虑进行以下操作：

- 增加MaxUserPort的值： 在Windows系统中，可以通过修改注册表来增加MaxUserPort的值，但要注意修改注册表可能会影响系统的稳定性和安全性。

- 修改ulimit参数： 在Linux/Unix系统中，可以通过修改ulimit参数来增加可打开的文件数，从而增加可使用的端口数。

- 使用多台机器： 如果单台机器的端口数不足以满足需求，可以考虑使用多台机器来分担负载，每台机器使用一部分端口。

无论如何，对于开放端口的修改和调整都需要谨慎处理，确保不会对系统的稳定性和安全性造成影响。同时，还需要考虑网络环境和硬件资源等因素，合理规划端口的使用
